{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(random_seed)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(random_seed)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(random_seed)\n",
    " \n",
    "# Set a random seed for PyTorch (for GPU as well)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pan21_functions as p21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pan21_functions' from 'c:\\\\Users\\\\thoma\\\\Documents\\\\croatia\\\\masters\\\\semester2\\\\text_analysis\\\\tar_project\\\\pan21_functions.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib; importlib.reload(p21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading problem and ground truth files: 11200it [00:01, 8323.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 295 problems had more than 15 paragraphs and were truncated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading problem and ground truth files: 2400it [00:00, 9665.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 62 problems had more than 15 paragraphs and were truncated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import itertools\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pan21_functions as p21\n",
    "from evaluation.evaluator import read_ground_truth_files\n",
    "\n",
    "class ParagraphDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path, paragraphs_per_doc=10):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.paragraphs_per_doc = paragraphs_per_doc\n",
    "\n",
    "        num_large_problems = 0\n",
    "        \n",
    "        files = natsorted(Path(x_path).glob('problem-*.txt'))\n",
    "        gt = read_ground_truth_files(y_path)\n",
    "        for problem_num, problem_file in tqdm(enumerate(files), desc=\"Loading problem and ground truth files\"):\n",
    "            # print(f\"{problem_file=}\")\n",
    "            # number = problem_file.name[len(\"problem-\") : -len(\".txt\")]\n",
    "            solutions = gt[f\"problem-{problem_num+1}\"][\"paragraph-authors\"]\n",
    "            with open(problem_file, 'r', encoding=\"utf8\") as fh:\n",
    "                paragraphs = fh.readlines()\n",
    "\n",
    "            if len(paragraphs) < self.paragraphs_per_doc:\n",
    "                pad_num = self.paragraphs_per_doc - len(paragraphs)\n",
    "                paragraphs += [\"\"]*pad_num\n",
    "                solutions += [0]*pad_num\n",
    "            else:\n",
    "                paragraphs = paragraphs[:self.paragraphs_per_doc]\n",
    "                solutions = solutions[:self.paragraphs_per_doc]\n",
    "                num_large_problems += 1\n",
    "\n",
    "            # print(f\"{solutions=}\")\n",
    "            solutions = [[0]*(s-1) + [1] + [0]*(4-s) if s != 0 else [0]*4 for s in solutions]\n",
    "            # print(f\"{solutions=}\")\n",
    "\n",
    "            self.x.append(paragraphs)\n",
    "            self.y.append(torch.tensor(solutions, dtype=torch.int64, device=DEVICE))\n",
    "\n",
    "        if num_large_problems > 0:\n",
    "            print(f\"Warning: {num_large_problems} problems had more than {self.paragraphs_per_doc} paragraphs and were truncated\")\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Example data\n",
    "paragraphs = [\n",
    "    \"This is the first paragraph.\",\n",
    "    \"Here is another paragraph.\",\n",
    "    # Add more paragraphs\n",
    "]\n",
    "labels = [0, 1]  # Corresponding labels for the paragraphs\n",
    "\n",
    "paragraphs_per_doc = 15\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = ParagraphDataset(\"pan21/train\", \"pan21/train\", paragraphs_per_doc=paragraphs_per_doc)\n",
    "val_dataset = ParagraphDataset(\"pan21/validation\", \"pan21/validation\", paragraphs_per_doc=paragraphs_per_doc)\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_paragraph = 256  # Fixed number of tokens per paragraph\n",
    "embedding_dim = 768         # Dimension of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class ParagraphLabelingModelWithBERT(nn.Module):\n",
    "    def __init__(self, bert_model_name, tokens_per_paragraph, output_dim):\n",
    "        hidden_dim = tokens_per_paragraph\n",
    "        super(ParagraphLabelingModelWithBERT, self).__init__()\n",
    "        # Initialize the BERT tokenizer and model\n",
    "        self.tokens_per_paragraph = tokens_per_paragraph\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model_name).to(DEVICE)\n",
    "        self.fc1 = nn.Linear(self.bert_model.config.hidden_size, hidden_dim).to(DEVICE)\n",
    "        self.relu = nn.ReLU().to(DEVICE)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim).to(DEVICE)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1).to(DEVICE)\n",
    "\n",
    "    def forward(self, paragraphs):\n",
    "        # Tokenize paragraphs\n",
    "        # print(paragraphs)\n",
    "        encoded_input = [self.tokenizer(p, padding='max_length', truncation=True, return_tensors='pt', max_length=self.tokens_per_paragraph).to(DEVICE) for p in paragraphs]\n",
    "        input_ids = [e['input_ids'] for e in encoded_input]\n",
    "        attention_mask = [e['attention_mask'] for e in encoded_input]\n",
    "        \n",
    "        # Get BERT embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = [self.bert_model(i, attention_mask=a) for i, a in zip(input_ids,attention_mask)]\n",
    "            embeddings = [o.last_hidden_state for o in outputs]  # shape: (batch_size, max_length, hidden_dim)\n",
    "        \n",
    "        embeddings = torch.squeeze(torch.stack(embeddings, dim=1))\n",
    "        # print(f\"{embeddings.shape=}\")\n",
    "\n",
    "        x = self.fc1(embeddings)\n",
    "        # print(f\"{x.shape=}\")\n",
    "        x = self.relu(x)\n",
    "        # print(f\"{x.shape=}\")\n",
    "        x = self.fc2(x)\n",
    "        # print(f\"{x.shape=}\")\n",
    "        x = self.softmax(x)\n",
    "        # print(f\"{x.shape=}\")\n",
    "        return x\n",
    "\n",
    "# Model parameters\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "output_dim = 4    # Number of classes\n",
    "\n",
    "model = ParagraphLabelingModelWithBERT(bert_model_name, tokens_per_paragraph, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11200/11200 [28:33<00:00,  6.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.5812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11200/11200 [25:57<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 1.5789\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for paragraphs, labels in tqdm(train_dataset):\n",
    "        # paragraphs, labels = batch\n",
    "        # print(f\"{type(paragraphs[0])} {paragraphs=}\")\n",
    "        # print(f\"{labels=}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(paragraphs)\n",
    "        # print(f\"{outputs.shape=}\")\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "torch.save(model.state_dict(), Path(f\"{datetime.datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')}.torch\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Once you turn on Flip Ahead, you can swipe through content spread across multiple pages to go to the next page within the same article, post or thread. When browsing sequenced content, such as blogs or news sites, and whenever you've reached the end of your multi-page content, flip ahead will suggest an appropriate next article, post or thread to continue your exploration. Using Flip Ahead requires end user opt-in, and sends your browsing history to Microsoft to improve the quality of the experience.\\n\", 'It\\'s a new feature for navigating IE pages. A good description from this page - Windows 8 Release Preview detailed impressions, under the \"Web browsing\" section: \\n', 'Enhanced touch browsing: In the Release Preview, IE10’s Metro style experience offers a new way of browsing multi-page and sequenced content. Flip ahead enables you to navigate your favorite sites like you read a magazine by replacing the need to click on links with a more natural forward swipe gesture on touch-centric devices (and forward button with mouse). Imagine flipping through a multi-page New York Times article, through product listings on Amazon or eBay, or quickly catching up on the latest news by flipping through CNN.com, all by simply swiping forward without hunting for the \"Next\" link on the page.\\n', '\"Flip ahead\" feature only works in Metro IE. It allows you to quickly and easily go to next page in a website which you are browsing by either swiping across the screen or clicking on forward button which is shown in the middle-right area of screen.    \\n', 'Flip Ahead is a new feature that allows you to use a gesture (a swipe across the screen) to flip between articles or web pages using either data sourced from other users browsing or based on support built into a website (via a <link rel=\"next\" href=\"example.html\" /> meta tag).', '', '', '', '', '', '', '', '', '', '']\n",
      "tensor([[[[-1.0871e-04, -9.7043e+00, -1.0860e+01, -1.0466e+01],\n",
      "          [-2.6226e-05, -1.0770e+01, -1.2895e+01, -1.2827e+01],\n",
      "          [ 0.0000e+00, -2.1403e+01, -2.2793e+01, -2.3688e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.2403e+01, -3.3796e+01, -3.5925e+01],\n",
      "          [ 0.0000e+00, -3.6016e+01, -3.8227e+01, -3.9588e+01],\n",
      "          [ 0.0000e+00, -4.0553e+01, -4.3378e+01, -4.5187e+01]],\n",
      "\n",
      "         [[-1.2099e-04, -9.8238e+00, -1.0559e+01, -1.0106e+01],\n",
      "          [-2.5749e-05, -1.0865e+01, -1.2641e+01, -1.2591e+01],\n",
      "          [ 0.0000e+00, -5.6336e+01, -6.0172e+01, -6.1023e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -5.5324e+01, -5.9481e+01, -6.0825e+01],\n",
      "          [ 0.0000e+00, -5.2120e+01, -5.6262e+01, -5.8189e+01],\n",
      "          [ 0.0000e+00, -4.0748e+01, -4.4043e+01, -4.3950e+01]],\n",
      "\n",
      "         [[-8.5827e-05, -1.0025e+01, -1.1101e+01, -1.0543e+01],\n",
      "          [-2.4080e-05, -1.0979e+01, -1.2304e+01, -1.2897e+01],\n",
      "          [ 0.0000e+00, -1.9110e+01, -2.0301e+01, -2.0939e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -5.3028e+01, -5.6398e+01, -5.5350e+01],\n",
      "          [ 0.0000e+00, -5.2782e+01, -5.6274e+01, -5.5260e+01],\n",
      "          [ 0.0000e+00, -3.7738e+01, -4.0879e+01, -4.2066e+01]],\n",
      "\n",
      "         [[-1.1360e-04, -9.9915e+00, -1.0510e+01, -1.0114e+01],\n",
      "          [-2.6941e-05, -1.0786e+01, -1.2510e+01, -1.2892e+01],\n",
      "          [ 0.0000e+00, -2.0374e+01, -2.3245e+01, -2.3405e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -4.3869e+01, -4.6675e+01, -4.7783e+01],\n",
      "          [ 0.0000e+00, -4.1688e+01, -4.4104e+01, -4.4770e+01],\n",
      "          [ 0.0000e+00, -4.7941e+01, -5.0634e+01, -5.1797e+01]],\n",
      "\n",
      "         [[-1.3851e-04, -9.6767e+00, -1.0356e+01, -1.0032e+01],\n",
      "          [-2.1934e-05, -1.0897e+01, -1.3150e+01, -1.3372e+01],\n",
      "          [ 0.0000e+00, -2.1928e+01, -2.3886e+01, -2.5533e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.4887e+01, -3.7283e+01, -3.6725e+01],\n",
      "          [ 0.0000e+00, -3.5200e+01, -3.7747e+01, -3.6998e+01],\n",
      "          [ 0.0000e+00, -4.7285e+01, -4.9552e+01, -4.9669e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0108e-04, -9.8522e+00, -1.0776e+01, -1.0497e+01],\n",
      "          [-2.3126e-05, -1.0914e+01, -1.2827e+01, -1.3031e+01],\n",
      "          [ 0.0000e+00, -5.2397e+01, -5.6660e+01, -5.6491e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.2434e+01, -3.5478e+01, -3.5574e+01],\n",
      "          [ 0.0000e+00, -3.5419e+01, -3.8561e+01, -3.9056e+01],\n",
      "          [ 0.0000e+00, -3.0221e+01, -3.2284e+01, -3.2826e+01]],\n",
      "\n",
      "         [[-9.4767e-05, -9.8885e+00, -1.1066e+01, -1.0471e+01],\n",
      "          [-2.4199e-05, -1.0852e+01, -1.2961e+01, -1.2926e+01],\n",
      "          [ 0.0000e+00, -2.5578e+01, -2.6893e+01, -2.9569e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -2.9700e+01, -3.2831e+01, -3.3367e+01],\n",
      "          [ 0.0000e+00, -3.2947e+01, -3.6188e+01, -3.6064e+01],\n",
      "          [ 0.0000e+00, -3.7066e+01, -4.0896e+01, -4.1299e+01]],\n",
      "\n",
      "         [[-8.7734e-05, -9.9585e+00, -1.1153e+01, -1.0552e+01],\n",
      "          [-3.0636e-05, -1.0726e+01, -1.2412e+01, -1.2296e+01],\n",
      "          [ 0.0000e+00, -2.9897e+01, -3.5206e+01, -3.5236e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.0353e+01, -3.3142e+01, -3.4046e+01],\n",
      "          [ 0.0000e+00, -3.0491e+01, -3.3372e+01, -3.4014e+01],\n",
      "          [ 0.0000e+00, -2.7143e+01, -3.0146e+01, -3.0245e+01]],\n",
      "\n",
      "         [[-1.0728e-04, -9.7853e+00, -1.0853e+01, -1.0359e+01],\n",
      "          [-1.9908e-05, -1.0959e+01, -1.3722e+01, -1.3427e+01],\n",
      "          [-3.5763e-07, -1.5077e+01, -1.6758e+01, -1.6991e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -4.2647e+01, -4.5640e+01, -4.7553e+01],\n",
      "          [ 0.0000e+00, -5.5134e+01, -5.8506e+01, -5.8336e+01],\n",
      "          [ 0.0000e+00, -5.3283e+01, -5.6797e+01, -5.7864e+01]],\n",
      "\n",
      "         [[-2.2242e-04, -9.4698e+00, -9.7657e+00, -9.3402e+00],\n",
      "          [-1.7524e-05, -1.1163e+01, -1.2772e+01, -1.4521e+01],\n",
      "          [ 0.0000e+00, -1.9538e+01, -2.0816e+01, -2.1096e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -4.4287e+01, -4.6799e+01, -4.7276e+01],\n",
      "          [ 0.0000e+00, -4.5825e+01, -4.9106e+01, -5.0823e+01],\n",
      "          [ 0.0000e+00, -3.4501e+01, -3.7756e+01, -3.8066e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0633e-04, -9.7378e+00, -1.0926e+01, -1.0438e+01],\n",
      "          [-1.7285e-05, -1.1165e+01, -1.3043e+01, -1.3791e+01],\n",
      "          [ 0.0000e+00, -2.3979e+01, -2.6913e+01, -2.9031e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -4.4396e+01, -4.7328e+01, -4.8971e+01],\n",
      "          [ 0.0000e+00, -4.1255e+01, -4.4111e+01, -4.5699e+01],\n",
      "          [ 0.0000e+00, -4.3084e+01, -4.5722e+01, -4.6864e+01]],\n",
      "\n",
      "         [[-1.0299e-04, -9.8178e+00, -1.0884e+01, -1.0421e+01],\n",
      "          [-1.8716e-05, -1.1129e+01, -1.2954e+01, -1.3333e+01],\n",
      "          [ 0.0000e+00, -2.2462e+01, -2.3208e+01, -2.4655e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -4.2096e+01, -4.5611e+01, -4.6724e+01],\n",
      "          [ 0.0000e+00, -3.4529e+01, -3.7306e+01, -3.8298e+01],\n",
      "          [ 0.0000e+00, -3.7420e+01, -4.0323e+01, -4.2131e+01]],\n",
      "\n",
      "         [[-1.1300e-04, -9.8817e+00, -1.0813e+01, -1.0083e+01],\n",
      "          [-2.0504e-05, -1.1128e+01, -1.2620e+01, -1.2909e+01],\n",
      "          [ 0.0000e+00, -3.9822e+01, -4.1054e+01, -4.3440e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.2393e+01, -3.4755e+01, -3.6644e+01],\n",
      "          [ 0.0000e+00, -4.1523e+01, -4.4930e+01, -4.7186e+01],\n",
      "          [ 0.0000e+00, -4.1688e+01, -4.4002e+01, -4.4619e+01]],\n",
      "\n",
      "         [[-1.0347e-04, -9.9187e+00, -1.0948e+01, -1.0215e+01],\n",
      "          [-1.8120e-05, -1.1203e+01, -1.2944e+01, -1.3078e+01],\n",
      "          [-1.1921e-07, -1.6729e+01, -1.9364e+01, -1.9003e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.2259e+01, -6.4641e+01, -6.3940e+01],\n",
      "          [ 0.0000e+00, -6.7681e+01, -7.1098e+01, -7.0704e+01],\n",
      "          [ 0.0000e+00, -7.0769e+01, -7.4245e+01, -7.4307e+01]],\n",
      "\n",
      "         [[-1.8273e-04, -9.5509e+00, -9.9858e+00, -9.6316e+00],\n",
      "          [-2.0623e-05, -1.1038e+01, -1.2686e+01, -1.3464e+01],\n",
      "          [ 0.0000e+00, -2.2787e+01, -2.4075e+01, -2.4753e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -4.0145e+01, -4.3136e+01, -4.3384e+01],\n",
      "          [ 0.0000e+00, -3.8865e+01, -4.1320e+01, -4.1340e+01],\n",
      "          [ 0.0000e+00, -3.8650e+01, -4.1556e+01, -4.1633e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]],\n",
      "\n",
      "         [[-2.7418e-06, -1.3280e+01, -1.4522e+01, -1.4333e+01],\n",
      "          [ 0.0000e+00, -6.8196e+01, -7.2504e+01, -7.4186e+01],\n",
      "          [ 0.0000e+00, -7.0320e+01, -7.3471e+01, -7.5836e+01],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -6.9363e+01, -7.2842e+01, -7.4558e+01],\n",
      "          [ 0.0000e+00, -7.2286e+01, -7.5671e+01, -7.7784e+01],\n",
      "          [ 0.0000e+00, -7.3947e+01, -7.7097e+01, -7.9399e+01]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m val_outputs \u001b[38;5;241m=\u001b[39m model(val_input)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(val_outputs)\n\u001b[1;32m----> 7\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m criterion(val_outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output_dim), \u001b[43mval_Y\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_Y' is not defined"
     ]
    }
   ],
   "source": [
    "val_input = [v[0] for v in val_dataset][:5]\n",
    "print(val_input[0])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = model(val_input)\n",
    "    print(val_outputs)\n",
    "    val_loss = criterion(val_outputs.view(-1, output_dim), val_Y.view(-1))\n",
    "\n",
    "    print(f'Validation Loss: {val_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_json(predictions, gt, threshold=0.5):\n",
    "    adjusted_predictions = [p.index(max(p)) for p in predictions]\n",
    "\n",
    "    true_num_paragraphs = len(gt[\"paragraph-authors\"])\n",
    "    \n",
    "    # Construct the JSON object\n",
    "    data = {\n",
    "        \"authors\": max(adjusted_predictions),\n",
    "        \"structure\": [999],  # Placeholder or specific requirement\n",
    "        \"site\": \"googole.com\",\n",
    "        \"multi-author\": max(adjusted_predictions) > 1,\n",
    "        \"changes\": [int(adjusted_predictions[i] != adjusted_predictions[i + 1]) for i in range(len(adjusted_predictions) - 1)][:true_num_paragraphs],\n",
    "        \"paragraph-authors\": adjusted_predictions[:true_num_paragraphs]\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluator import compute_score_single_predictions, compute_score_multiple_predictions\n",
    "dict_of_jsons_result = [predictions_to_json(p) for p in val_outputs]\n",
    "\n",
    "truth = read_ground_truth_files(\"pan21/validation\")\n",
    "\n",
    "task1_result = compute_score_single_predictions(truth, dict_of_jsons_result, 'multi-author')\n",
    "task2_result = compute_score_multiple_predictions(truth, dict_of_jsons_result, 'changes', labels=[0, 1])\n",
    "task3_result = compute_score_multiple_predictions(truth, dict_of_jsons_result, 'paragraph-authors', labels=[1, 2, 3, 4])\n",
    "\n",
    "print(\n",
    "    # f'Model: {model_path.stem}\\n' +\n",
    "    f'\\tTask 1 Score: {task1_result}\\n'+\n",
    "    f'\\tTask 2 Score: {task2_result}\\n'+\n",
    "    f'\\tTask 3 Score: {task3_result}\\n'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
