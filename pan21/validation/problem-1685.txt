Chapter 5 of Recurrent Neural Networks for Prediction: Learning Algorithms, Architectures and Stability by Mandic and Chambers 
My apologies if the question is a tad vague—I did try to search the literature for more, but didn't find anything (the similarity between the keywords "Takens" and "taken" on Google may be partly to blame).
The same paper by Wan trains a neural network to predict the sum of Henon iterations. Of course, the predicted and actual iterates diverge, but the attractor is nonetheless replicated by the neural network, realizing Takens's theorem. So, Howon's observation rings true: while the dynamics of certain non-linear functions can be captured with finite delay, their values cannot be so captured perfectly.
Theoretically, Takens's theorem implies that a deterministic system attractor of finite dimension $D$ can be reconstructed by a finite number of time delays $k$ if
My question is: has this theorem, or some version of it, been applied or explored in the context of computational learning? If so, where can I find references of it? If not, is there a reason why—e.g., "it does not apply in the usual settings we consider because [...]"?
This implies that the dynamics of eligible non-linear functions can be replicated by a non-linear autoregressive model of $k$ delays. Such a model can, and has been, realized with neural networks (See Eric A. Wan's Modeling Nonlinear Dynamics with Neural Networks: Examples in Time Series Prediction). 
If I understood correctly the Wikipedia page on Takens' theorem, and some discussions I had with people in applied (physics-related) fields that mentioned it to me, Taken's theorem essentially states that 