In python sklearn, there are multiple algorithms (e.g. regression, random forest ... etc.) that have the class_weight parameter to handle unbalanced data.
However, I do not find such parameter for the MLLib algorithms. Is there a plan of implementing class_weight for some MLLib algorithm? Or is there any approach in MLLib for unbalanced data? Or we actually have to handle all the up/downsampling ourselves in MLLib?
At last , you only have to weight the loss value for every minor labeled instance during your iteration process if you want to implement it . 
Algorithms in MLLib are always used as baseline in production scenario , and they indeed can not handle some industrial problems , such as label imbalance . So if you want to use them , you have to balance your instances . 
1. Merging the class that appear least frequently to other classes. Obviously you should use some kind of domain knowledge instead of merging them randomly
2. Use resampling techniques like oversampling, undersampling, SMOTE, ADASYN. I don't recommend using these techniques because they don't actually represent the actual data. But in any case you can certainly take a look at them
Besides , mechanism of BSP in Spark , you can simply see as data parallel ,  might be the main reason why Spark does not cover that problem . It might be hard for Spark to dispatch instances to all nodes in cluster , while the partial instances of each node share the same label distribution as the whole . 
In addition to the last post, you could take a look at the imblearn library (https://imbalanced-learn.readthedocs.io/en/stable/index.html) which allows you to do various types of over/ undersampling as well as SMOTE / SMOTENEC