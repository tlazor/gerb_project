That is very hard to say without knowing how many and which indices you have. But again a rule of thumb jumps in: With MongoDB, there is no such thing as too much RAM. With 1TB payload, MongoDB could utilize 1TB+ to keep not only the indices, but the data, too in in RAM for fast reads.
In order to be able to create backups in a proper way, you should have at least have a RAID10 (the suggested RAID level for MongoDB) with a payload of around 2.5TB. Let me explain why:
Without knowing how much data is send per query, it is impossible to calculate this. If you plan to set up a replica set (which you almost always should), you should not go below 1Gb internal bandwidth on write heavy applications. If you really have a lot of load, you might even want to bond two interfaces.
That would be 128GB in your case. But it may well be that you get along with just 64 or even 32GB. My suggestion would be to start with 32GB and upgrade if you see a lot of page faults in MMS.
Hard to say what computing power you need, but as a rule of thumb you should buy fewer, but more powerful cores.
The amount of RAM you need is hard to calculate. I usually would roughly calculate 10% to be on the safe side for optimal performance, since additional RAM never hurts. Especially when using spinning disks instead of SSDs.
The closest would be a RAID 10 with 6 disk of 1TB each giving you a payload of 3TB. That should give you the best balance between redundancy, performance and required payload. Please use 15k SAS disks at least. SSDs give an performance boost of about an an order of magnitude right out of the box, but that does not seem to be an issue with your requirements.
Disclaimer: These are only rules of thumb, based on the very limited information of the original question. Depending on your application, system administration skills and environment, your actual needs may vary.
I am new to MongoDb, I have 1 TB of Data in JSON format, what should be the processor speed, RAM, disc space required, network bandwidth for maximum of 10 concurrent users for production environment.
You don't want to have 100% utilization of your disk space, so we add a reasonable security margin of 20% to give you enough time to take measures.
Then, you want to be able to create backups using LVM snapshots. You need to allocate some space for changes which occur during the lifetime of the snapshot. This is hard to calculate without information, but to be on the safe side, we assume it is about 50% during the time of the backup, so we add another 500GB. Then, you would need some space to compress the backup to. To be on the safe side again, we add another 500GB. Since you don't want a utilization of 100% of the backup space, too, the above calculation for the space needed for backup applies again! effectively doubling the space.