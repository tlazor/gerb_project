There are multiple culling algorithms used in video games.  The most notable is the one used to determine what should be drawn on the screen and to what level of detail.  This culling is purely render engine driven and shouldn't live outside the render system at all.  
There is nothing wrong with inter-system dependencies in a game.  What you do want to minimize is the component-to-component dependencies.  This way you avoid what can often be expensive lookups during the subsystem's update loop, destroying your cache coherency.
For example, provide a collision sphere around an entity to represent it's sensory area to detecting other entities, notably players.  If an entity enters that collision area, it gets added to a list of collided players associated to that NPC.  For every collided player, the NPC attempts a ray-cast to find them.  But if obstacles block their view of those collided players, it cannot react.  Once I move to where I'm no longer obstructed by a wall, the NPC can enter it's attack state and move toward me because all it's behavior validation succeeded.
Another is what is considered within the purview of an entity to react upon.  For example, once you get close enough to a specific entity that is considered hostile, maybe it will attack you, but only if it can actually see you with it's eyes.  If a corner blocks it's vision despite how close you are, maybe it cannot sense you.  This type of culling happens with the AI subsystem by exploiting functionality provided by other subsystems.  