I need to find out how much disk space is being occupied by each user on the network. I am aware of df and du commands: I could list the entire filesystem and AWK the output, but I wonder if there is a more standard command.
If you wanted to be even more efficient, you could pipe the output to script that handles it as it runs, but that would be a little more work, and you would have to get it right the first time.
You can replace the \0 with something that might be a little bit easier to work with, like tabs or newlines, but that would be less safe if you have funky file names. 
ThorstenS's method seems like more work then is needed to me because it runs find multiple times. For a one off,  I would just do 1 find command, and output the owner and size of each file, and then do some sort magic on that file.
What we do in many places is use the quota system, but set absurdly high quotas. This way you get the benefit of fast reporting. At one site, each user has 1 TB of "quota" space. 
Is this a one time thing, or is this information you want to be able to extract regularly? In case it is the later then one option is to apply quotas on your filesystem. Doing that the system continuously keeps track of the amount of data used by each user. That way the information is merely a query to the quota database away.
We periodically bump the quota higher as serviceable disk grows -- initially it was 30GB per user, something that was absurdly high at the time.
The find would be something like which returns username (or id number of no username) and space used in bytes, in a null-byte delimited file: