In the age of Super VGA, we pimped out at 132 column mode.  Rows could be 25, 50, 60, or other values.  However, there was some compatibility issues.
In the age of VGA, 80x50 became widely supported and used by some.  However, on the pitiful 14 inch monitors of the day, some people found it hard to read.
My console has a whopping, wait for it, 80x25 characters and 16 ANSI colors. It's stuck in the seventies. Even though my graphics card has 4GB RAM, 10bit color and whatnot, the console doesn't make any use of it.
As a general rule desinging and debugging hardware is expensive, so it will only happen if there is a genunine demand for it. The legacy text modes are kept around for backwards compatibility reasons but there is no drive to introduce new ones when the requirement for high resoloution text is handled fine by software.
Consoles usually do support 256 colors, although you may have to change some settings to enable it everywhere, see e.g. http://www.robmeerman.co.uk/unix/256colours
In the days when memory was expensive and processors were slow, hardware text modes made sense as they were faster and less memory hungry. Nowadays computers are powerful enough and have enough memory that the costs of having a simple framebuffer and implementing the text display in software are negligable.
I think the point of a "text mode" is that the graphics card can load up a pre-defined font, and then display certain graphics (which we call "characters") using a small amount of memory, instead of repeatedly specifying the same combinations of pixels using a larger amount of memory.  What's happened is that we've just had less reason to worry about such memory savings.  Hardware acceleration standards have allowed us to use different techniques to optimize things for speed.  Video cards have enough memory that they don't need to use a special video mode that is designed to try to load a bunch of pixels arranged in formats that we call fonts.
Yes, I can start X11 or use a frame buffer console. But why do I have to? What is the insurmountable problem of providing a better console with say, a modest 256 colors? We have left some other standards behind, burnt some bridges (ISA? Real Mode? Turbo button? IBM compatible?), why not finally pimp the VGA console?
How far have we come in the past 30 to 40 years. Gigs of RAM. Terabytes of disk space. Gigahertz processors. 4K and 5K flat displays.
Eventually, GRUB started to support graphics, though, so some people have tinkered with some increases.  In general, such things have been a novelty.  If you really want more rows and columns, there's little reason why to ask the video card to use a video mode that it calls "text", instead of using a video mode that it calls "graphics".  And, over the years, we have had increases in graphics capabilities.  Things like 256 color terminals, or higher colors, and even things like transparencies, do exist.  We just call them "graphics" modes.
Now, a lot of hardware could support that.  Yet you find yourself using 80x25.  Why?  Because you're using default settings.  And the default settings is that very few people have cared.
And the 80x25 limit should go away if you just resize your terminal window, allowing you to fill your 30" screen with more characters than is comfortable to read.