Now onto the question itself, you have easy creation, resizing and deletion of volumes (aka partitions), and another nice feature (depending on your situation) is the ability to create snapshots of a volume.
You can use LVM to do a lot of things with disks. The main benefit is the ability to grow filesystems on the fly. Suppose you are setting up a log server, and you know in the future you'll have a ton of data. Ext3 supports a maximum of 16TB (more depending on your kernel and version of EL). But what if you know in 2 years you'll need 1PB of storage? Well, this creates some problems. First, your boss will look at you with deer in headlights eyes when you tell him the price of that storage hardware. This leads to another problem - you need to start with a small solution that you can scale upwards. LVM gives you that option. You start with a few disks. Then you add more, turn them into a logical group, add them to the first logical volume, increase the size of the volume, and finally grow the filesystem. Voila, you've got a nice scaling filesystem.
Edit: I should also note that if you're dealing with 1PB, you're not going to want to use Ext3... probably XFS.
You should have provided more info about the situation you are going to apply this in, that way we can give targeted answers rather than broad possibly unrelated answers (I can't comment else I would've said this in a comment).
Most LVM tasks, providing the hardware supports it, can be done online, without rebooting the machine. If you can hot swap disks on a system, you can add new disks and subsequently remove old (maybe smaller) disks to increase system storage requirements.
There are a number of indirect benefits of LVM. The main thing LVM does is abstract the physical disks away from the operating system. The main benefit of this is simply flexibility. Most of the benefits of LVM are only realised when you have a filesystem that supports being resized on the fly. The basic thing LVM does is described below:
The naive may advocate the use of a single large partition, but you may become undone when you need to introduce quotas, or isolate rogue processes filling up parts of your system (e.g. /var/log, /tmp etc.)
One of the main issues with LVM volumes is as they approach capacity, fragmentation can become an issue in my experience. Volumes >90%, and really >95% can mean you can end up with bad fragmentation on disk depending on your disk usage and file types. It's rarely something to overly concern yourself about, that's the case with any kind of volume / partition management, but it's fragmentation on the volume layer as opposed to on the partition that's the concern here.
This saves you from having to move the data off of the device, reformat the LUN's, and then moving everything back to perform an upgrade. Sorry for the brevity, hope that makes sense.
Adding storage is generally trivial. If you're using hardware or software RAID and you add more disks, you may often have to fiddle around with symlinks to rebuild the RAID array in order to have Linux make your new storage available in the locations you want. 
Take the example of a large /home directory which is getting full. That exists on an existing two disk RAID 1 volume. You want to add two more disks. You set those up in a hardware RAID 1 configuration. Without LVM, you have a couple of options:
With LVM, you can simply add the new RAID 1 volume group to the additional pool of storage, resize the filesystem (providing it supports it) and voila, /home is now suddenly larger. You don't need to symlink anything or do maintenance on potentially moving data from /home to /home1 or vice versa. Rinse, wash, repeat for future disk upgrades.
Without LVM, Linux uses the partitions located physically on the disk. The partitions are direct device names. The partition table resides in the MBR and normally (in the case of logical extended partitions) in the extended boot record (which allows you to create a larger number of partitions). Partitions define a size and type among other attributes (more specifically, they define a start and end cylinder which essentially defines the size). Because they are so closely tied to the disk, setting up a "correct" partitioning scheme upon install is important. If suddenly, a machine function changes or if you're a novice and you've not understood the implications of partitioning, or if you're underestimated disk usage somewhere, or logs of a particular application, changing that partitioning can be cumbersome. There are tools for doing it, but you generally need to move data off the partition to change it. Obviously, if you've got four partitions, changing the second partition end cylinder effects the third and fourth partitions start cylinders and so you get into a messy situation.