I have a Medium server on EC2. I don't know that much about Apache or Tomcat - they are up and running, but other than that I don't have advanced knowledge of how to tinker. I know that I can set the min/max JVM size for the Tomcat Server, and that I can set how many threads Apache can fork off, but I don't know what "reasonable" values for these parameters are. 
Heap, I would set ms=mx=1GB intially. 1.5 if you're app is memory hungry. I've never seen any point (or gain) in having a variable heap size in a server environment.
If your application has a lot of synchronized sections (shared caches, external resources/integrations with only serial access and whatnot), worker threads have a diminishing return as the more they are, the more time they will spend just waiting for each other. With your specs, and knowing nothing about your app, I'll say 50 as a starting point in terms of thread pool sizing. You'll need to run some performance benchmarks to tweak this properly. Use jmeter, for instance, and create a test script the emulates one or a few of the primary use-cases on your site. Use 2 or 3 temporary EC2 instances as load-generators (you'll only need them for a short period) where you run the jmeter-server application.
Run test scenarios with permutations of, for example, 60, 120, 180 and 240 jmeter request threads and 30, 50, 70 and 90 tomcat worker threads. Compare response times and CPU and memory usage on your server. For basic CPU/memory information, you can use the standard jconsole or visualvm information out of your JVM. You can also run your tomcat JVM with verbose garbage collection (GC logging) and study the memory and GC behavior with something like tagtraums GC viewer.
I'd suggest you then profile your app - based on the peak load and observe memory utilization using LambdaProbe or similar and see what you need to change