Short Stroking a single drive on a PC serves no purpose other than to only use a portion of what you paid for in reality.
Short-stroking is basically what you found. You specifically use only the last few tracks on each platter of your hard disk. I have heard of this, but haven't looked at it in a while. 
At first when I read about it, for some reason I understood that it was some way of splitting the bytes across the platters of the disk, which sounded like a good idea and obviously doesn't make sense, because that wouldn't cut disk size in half (and disk are probably already splitting bytes across platters)...
Could anyone here explain to me what is implied by this term? (I've seen the same thing mentioned with the 3 terms).
A 7200 RPM drive I can expect ~ 75 iops, for a 15K rpm SAS drive I can expect ~ 175 iops. Now that is just the "Average" iops expected per disk. Block size, sequential vs random access, and response time all come into play as well, but for the sake of simplicity let's just limit the conversation to IOPS.
If I create a RAID group of 3 15K disks, they then act in unison and, again, just keeping it simple, I now have a disk "unit" capable of performing 525 IOPS (175x3).
The reason to short stroke is for performance purposes. Every drive weather SATA, FC, SAS has a limited number of operations it can perform called IOPS (Input/Output Operations Per second). IOPs is like a highway. If I have a 1 lane road I can expected x amount of cars/hour before we see traffic (higher response time), however If I have a 3 lane highway I can now handle an increased amount of work and have less traffic. Notice I did not say 3x the amount of work because the workload does not increase lineally. Also to complete the analogy if the number of lanes is the IOPS, then the amount of cars I can put through those lanes would be the throughput.
Looking at new articles, as well as from memory, the details about this are a mixed bag, mainly bad from my perspective.
I have previously recommended against ideas like this, as just buying larger, faster disks is cheaper in the long run, unless you don't pay for your electricity. The time savings may help in a database server with very little memory, but I can think of no other situation.
The best I've come to understand is that basically instead of creating one partition for the whole size of the disk, you create 2 partitions, and use only one of them, either the one in the "center" or the one in the "rim" of the platters, and since one of the two is faster (people didn't seem to agree on which one was faster), that makes everything better.
So extrapolating that out to high end storage arrays like NetApp, EMC, IBM and others, short stroking is a performance enhancement technique that allows for higher IOPS, and lower response time (because I am only writing to the fastest part of the internal disks) and now my storage arrays are capable of reading/writing data very fast.
In general reading from the outside sectors of the platters is faster, as more sectors pass under the heads per second at 7500 RPM (or whatever) than towards the middle. Also, the heads rest on the outside of the drive when resting so, making a partition only near the center of the drive could actually give you worse seek speeds.
Short Stroking is only using the outer 1/3rdish part of each platter in the drive in total. That's it. so on a 1TB drive you would theoretically have 300GB or so of usable capacity.
Now If I only write to 1/3 of those 3 disks platters,  because my goals was to have higher iops capability, I have achieved that but at the cost of useable capacity.
When you Partition a 1 TB drive say into 2 500GB partitions that means that every track on every platter has the ability to be written to by the Operating System. albeit in 2 different "buckets"