I would like to know what is the best way to classify a data set composed of mixed types of attributes, for example, textual and numerical. I know I can convert textual to boolean, but the vocabulary is diverse and data become too sparse. I also tried to classify the types of attributes separately and combine the results through meta-learning techniques, but it did not work well.
It is hard to answer this question without knowing more about the data.  That said, I would offer the following advice:
Most machine learning techniques can handle mixed-type data.  Tree based methods (such as AdaBoost and Random Forests) do well with this type of data.  The more important issue is actually the dimensionality, about which you are correct to be concerned.
I would suggest that you do something to reduce that dimensionality.  For example, look for the words or phrases that separate the data the best and discard the other words (note: tree based methods do this automatically).
Also if you use a dimensionality reduction technique you end up getting a slightly more robust format for your feature vector (they generally end up being straight numerical vectors instead of mixed data types), which might let you leverage different methods. You could also look into hand engineering features. With properly hand engineered features Random Forest will get you very close to state of the art on most tasks.
Christopher's answers seem very reasonable. In particular tree based methods do well with this sort of data because they branch on discriminative features. It's a little hard to say without knowing your specific application, but in general if you think that some of your features might be significantly more discriminative than others, you could try some dimensionality reduction techniques to clean this up a bit.