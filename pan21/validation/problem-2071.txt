Power factor and conversion efficiency should be considered. Generally speaking, power supplies lacking the 110/220 red tab on the back are higher quality. Supplies with an 80+ certification, better still.
Testing isn't really practical when you're talking about power supply lifetimes. Documenting the power supplies make/model/wattage and power on load/average load and keeping track of their failures would be an awesome study to undertake.  And would give you data that is accurate for your environment/datacenter.
Unless you're running right at the edge of capacity all the time and bumping up over it on occasion no.  A better made power supply will last longer than a poorly made one but upping the wattage available shouldn't do anything to improve longevity.  (it may by way of being a better power supply from a different vendor)
For example i have some $30K+ Sun gear from 1994 that runs strong to this day. The unit is powered by a single phase 30A 240V PSU. There are enough disk arrays and CPU boards in it to draw a near constant 23A when under decent CPU load, but it has yet to have any issues.
In other words, in order to get a cheap power supply to last longer, you generally have to oversize it.
A larger power supply is only likely to outlast a smaller one, assuming they are both used within their load rating, if there is a quality difference between the two.
For example, say I have a system where the typical load is 200 W and the max load is 350 W during startup.   I want to get the most reliable (ie. long-life) power supply possible.  Is an 800 W power supply likely to last longer than a 400 W supply?  Or does it not really matter since both the 400 and 800 are more than the anticipated maximum load of 350?
On the other hand i also have some older Dell PowerEdge 1950's that run around 40% load from dual PSU's and i have replaced 3 PSU's in the last 5 years. That's spread across 12 servers, so 24 PSU's in total. Unfortunately the power where i have these located is known to fluctuate which probably attributes quite a bit to their failure rates.
If you pay less for a larger wattage p/s, the extra wattage increases the possible damage it can do.
So a high quality power conditioner can also help keep PSU's alive, the built in one in most UPS's is decent, but they cant touch a good standalone unit.
It is a complex subject, but generally speaking, if you pay more for a quality power supply that is 80+ bronze or better, you are getting a better, longer lasting, more efficient P/S.
Is a larger-capacity power supply likely to live longer than a lower-capacity supply, even if they both have plenty of capacity for the system they're on?
Besides component quality, things like OCP (Overcurrent Circuit Protection) is very important for both power supply and system life if a rare short circuit occurs. (Or not-so-rare, in the case of USB ports). My most recent system loss was an old, cheap but pretty group-regulated supply that was supposed to have OCP, but didn't, and died when a USB port shorted. It died, completely, along with the USB functionality of the M/B.
As previously stated, it's all about quality. More specifically, capacitor quality. It's rare to have any other component in a PSU fail, unless a capacitor fails causing another component to also fail. The only exception would be if you're running a very high load (90% or above). High loads can generate high amounts of heat which generally will cause components to fail prematurely.