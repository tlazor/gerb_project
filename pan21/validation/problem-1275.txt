However, that greatness depends on the fact that RAM can be trusted. All this validation, correction, rewriting and so on happens primarily in RAM. On high-end servers, you don't find anything but ECC RAM.
A major portion of what makes ZFS so great for storing data that you care about is that you can set it up in ways that can both detect and correct errors in storage. This can be trivial errors like a single bit flip somewhere, or catastrophic errors like several disks crashing at once. As long as you stay above your storage layout's redundancy threshold (for example, no more than two disks simultaneously experiencing problems in a raidz2 vdev) ZFS can correct any error using redundant data. Further errors, depending on where and how they occur, can lead to a (semi-) graceful system panic, or a simple I/O error.
If your storage server which runs ZFS experiences bad RAM, whether a bit flip or a stuck (one or more) bits, and you have ECC RAM in the storage server, this will be detected, and the event will be logged or the system will be halted (if the error cannot be corrected for). Either way, the integrity of the data that is stored on the server is preserved. If your ZFS storage server has non-ECC RAM, then an error can propagate throughout all your data and metadata as ZFS attempts to "correct" the errors that really are only figments of the computer's imagination. As a worst case scenario, which actually happens to people, your entire pool will be wrecked because of this and all your data will be gone. Storage-level/vdev-level redundancy doesn't help here, either. With most other file systems (without the auto-correcting behavior) only the one place which was directly affected by the bit flip will be corrupted, and if this happens to file system metadata is likely to be easily fixed by traditional file system checkers and recovery tools. ZFS does not have this escape hatch; there is no fsck.zfs. (There is zpool scrub, but that doesn't work if the pool is broken beyond repair.)
If your workstation system experiences a RAM bit flip, then when you write the bit-flipped data out to ZFS, the bit-flipped data will be the basis for what ZFS eventually writes out to disk. This is obviously bad, because it means your file will be corrupted. However, the bit-flipped data will be correct as far as ZFS is concerned. This is actually good, because it means that all the normal ZFS recovery methods will work. Yes, the most recent copy of the file in question will be corrupt, but it would be corrupt anyway, no matter what file system you were using. You can leverage ZFS's snapshots to at least be able to go back in time to an uncorrupted copy. Set up something like zfs-auto-snap to snapshot your file systems at regular, close intervals, keep a coarser history going backwards, and forget about it until you need them. (For example, keep ten snapshots spaced ten minutes apart; 50 snapshots one hour apart; 30 snapshots six hours apart; and so on.) Snapshots are practically free in ZFS; if you use ZFS, use snapshots as well.
Not in the sense that you have to have exactly the right chipset, graphics card, disk firmware version and so on, but in the sense of capabilities provided by the hardware. Remember, ZFS was designed as a high-end server solution, and certain assumptions it makes reflects that.
It means you have a trusted data repository. You know that once data has made it to your NAS, it's safe from corruption. Any corruption will either be repaired automatically, or you will be informed about the problem (in the case of ZFS, via an I/O error). The data might still be corrupted while it's being worked on using less reliable systems, but you will have some place to go for a known non-corrupted copy. This is an advantage even if only the NAS system has ECC RAM, ZFS and high-quality storage monitoring and alerts set up.
If you do it right, you will also set up your system to scrub the ZFS pool(s) at regular intervals. This will catch degredation before it becomes a problem, and will notify you to it so you can consider replacing the storage devices that are having trouble holding on to your data before this becomes a problem.
You can then, if desired, add (particularly) ECC RAM to your other system(s) as your budget permits, to plug the last hole.
Second, ZFS likes RAM, but mainly for caching. With most workloads, 8-16 GB of RAM should be quite enough, and 24-32 GB (easily attainable even with "consumer" motherboards) is still reasonably priced even when buying high-quality brand-name ECC RAM. ZFS isn't terribly CPU hungry; you can make it need lots of CPU (like with ZoL, by setting up sha256, gzip-9 compression and possibly deduplication in combination), but you don't have to. My own system runs ZFS, isn't terribly high-powered (FX-6100 CPU clocked down), I use sha256 everywhere, and even in purely sequential I/O the disks are the limiting factor: once it gets past the initial small-random-reads portion of the scrub, I get about the same throughput on scrubs as I do on a raw dd from the underlying storage device, with CPU to spare.
First, you don't really need server grade hardware. What you need is primarily ECC RAM (and a CPU and memory controller/chipset that supports ECC RAM), reasonably reliable permanent storage, and ideally a case that makes it easy to add and remove disks while the system is running. This doesn't have to be very expensive, and certainly does not need to cost "thousands of dollars".
ZFS protects (and handles) pool metadata, file system metadata and user data the same way. There is no real difference here.