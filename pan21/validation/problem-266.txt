NCQ is a technology that lets drives re-order the order in which read and write requests are serviced. 
SSDs save you the seek times hard drives are plagued by, but actually reading from and writing to a NAND die is not especially fast. SSDs get around this by reading and writing to multiple NAND dies in parallel. 
For small IO reads, or mixed workloads, the SSD will service the request in the command queue out of order trying to keep as many NAND dies working in parallel as possible. The SSD can only do this if NCQ is enabled. This can make a huge difference in IO heavy work-loads. For AHCI I've seen up to 10x difference, and for NVMe over 100x. 
For small IO write loads SSDs usually cache a bunch of them in on board memory and the write the whole slew of them out to different NAND dies in parallel. This is why SSDs can have such high random write performance. 
In order to achieve this SSDs rely on three kinds of strategies: For large IO request the split the request across multiple dies, by splitting it up and writing parts of the data to separate dies in parallel. For reads the data is, hopefully, also split across dies and can be read back in parallel. 
If you've ever seen benchmarks of an SSD from a benchmarking application like CrystalDiskMark or similar you can see that they usually provide 4k random read results both with and without queue depth. If NCQ is disabled the difference between these two numbers is small, with NCQ enable it is huge. For example, this Bit-tech review, put the QD1 4k random read results for the Samsung 950 PRO 512GB (a NVMe drive) at 60MB/s, but the QD32 4k random read results for the same drive are 1261 MB/s. 