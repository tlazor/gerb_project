It doesn't feel right that this is a network capacity problem (unless of course something else is eating the bandwidth). When all is said and done your total data transfer for the 100 transactions is 2.2MB which is nothing really.
The actual throughput of the network shouldn't be a factor here, as you won't even come close to saturating a 1Gbps link. 
But to be honest, there's so many other factors at play here, and running 100 instances of your application at once is only making things more complicated. How long does it actually take when you run a single instance?
However, that being said - 150 milliseconds is quite a while for such a small amount of data (20KB burst with 2KB return), so unless your network is congested, or has some strict QoS, then there's no reason that the addition of the network should cause it to take that long. You can test this yourself if you like - send an ICMP packet 20KB in size, and see how long it takes to get a response. (ping X.X.X.X -l 20480).
Now that your application must now travel down through layers 1-6 of the OSI model, and then back up to the application layer at the receiving end, each step along the way will be adding a very small amount of latency to the connection. 