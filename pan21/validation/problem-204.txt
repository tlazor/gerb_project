Macs support running 64-bit apps on top of a 32-bit kernel because a multi-stage plan to do exactly that:
BTW, OS X does not use the ELF binary format, it uses Mach-O binaries.  The Mach-O format allows multiarchitecture ("universal") binaries, so programs (and for that matter the kernel) can be supplied in both 32- and 64-bit (and PPC and PPC64 and...), and the OS can choose which version to load (and hence which mode to run it in) at load time.  You can use the file command on a binary to see what format(s) it's in.  For example, here's the Chess application shipped with OS X v10.5:
The real question would be why some other operating systems can't run 64-bit binaries on a 32-bit kernel. There is no fundamental reason why it wouldn't be possible. The underlying processor architecture supports both a 64-bit instruction set (amd64 a.k.a. x86-64) and a 32-bit instruction set (i386), and there is no restriction on the two being used together (in particular, there isn't a “64-bit mode” that's separate from a “32-bit mode”; there's a single long mode, which allows instructions from both the i386 and the “native” amd64 set).
According to the Wikipedia article that you cite, OSX had the ability to run amd64 processes on amd64 processors before it had a 64-bit kernel. Solaris also indifferently mixes i386 and amd64 executables on amd64 processors, regardless of whether the kernel is 32-bit or 64-bit (both are available).
You're missing an important part. Apps make API calls out to functions and services provided by the operating system. If a 64bit app sends a 64bit pointer to a 32bit operating system, things should blow up.
There's lots of background info on the 64-bit transition on both the Mac side and the Windows side. (Those links are to the last of each series of articles; be sure to go back to the beginning of each.)
The real question then is why Windows and Linux did not do the same thing. For Windows, consider that their first attempt at Win64 was with Itanium, which was completely different. But the final answer might boil down to what it usually has for the last few decades: compatibility with a bunch of third party programs that didn't do things quite the right way:
I suspect that to make things work acceptably either way, the OS must overload the function and provide both a 64bit and 32bit version of each function. For each kernel, the "off" function (64bit function on 32bit kernels, 32bit function on 64bit kernels) will just be a stub that translates the call to be 32-bit safe and then re-calls the native function.
Other operating systems can run i386 processes on a (64-bit) amd64 kernel, but not amd64 processes on a 32-bit kernel, for example Linux, FreeBSD, NetBSD and Windows. Yet other operating systems treat amd64 and i386 as completely different architectures, for example OpenBSD.
I'm not familiar enough with the x86_64 architecture to give the details, but essentially what happens is that the CPU is switched between 64-bit mode and compatibility (32-bit) mode as part of the context switch between the kernel and a userspace program.  This is pretty much the same thing that'd be done to run a 32-bit program under a 64-bit kernel, just happening in reverse.
And a note for those doubting that this is possible: OS X supported 64-bit programs starting in v10.4 (with limited API support), but didn't include a 64-bit kernel until v10.6 (and even then, the kernel ran in 32-bit mode by default on most models).  See Apple's 64-bit transition guide for details.  I'm posting this from a MacBook Pro running 10.6 with a 32-bit kernel (64-bit isn't supported for this particular model), but according to Activity Monitor the only process not running in 64-bit mode is kernel_task.
So OS X supported 64-bit apps as soon as possible, and continue to run the 32-bit kernel as long as possible because of the driver situation. (The bit-ness of the kernel only becomes a factor when trying manage huge amounts of RAM -- page tables take memory too -- and switching to a 64-bit kernel offers some performance benefits.) But Apple is certainly not shy about dropping stuff.
Running 64-bit applications on a 32-bit kernel does require a little more work inside the kernel, because it must manage 64-bit pointers to user space together with 32-bit pointers to kernel space. Most if not all pointers passed around in the kernel are either known to be to kernel space or known to be to user space, so it isn't a problem if they're different size. The main difficulty is foregoing the possibility of having a universal pointer type that has separate ranges of values for process memory, kernel memory and memory used by various pieces of hardware (including RAM), but this isn't possible in recent 32-bit kernels on PC-class hardware anyway (if you have 4GB or more of RAM, or want to map 2GB of RAM plus 2GB of process space plus kernel memory and more, you need to be able to map more than 32 bits' worth of addresses anyway).