One historical origin of automata theory is the subject of compiler construction. For the reason mentioned above, only regular languages and CFGs are useful for constructing compilers (notwithstanding the fact that attributive grammars are not really CFGs, and that CFG parsing algorithms don't really parse the entire class of CFGs). LBAs might have been invented by Chomsky as some intermediate level of complexity between the mundane and "English". So perhaps the proper place to teach them is in linguistics courses rather than computer science ones!
It should now be quite clear why we are interested in the first two more than LBA. The first two naturally fit into the usual definition of feasible computation. But PSPACE does not.
Regular expressions and CFGs are used in practice for parsing code (that is, programming languages). The reason is that there are very efficient algorithms for parsing them. LBAs, on the other hand, are too powerful to actually use in that context.
With "appropriate" modifications we can turn these classes into complexity classes; Finite Automata into $NC^1$, CFL into LogCFL, and LBA into PSPACE. 