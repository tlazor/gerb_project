Thank You for Your input, as it turns out the right answer (and the key in my question) turned out to be that I am using a virtual dedicated server. The server had 0.6 of a processor unit (so 1.2Ghz out of 2Ghz Xeon). This caused weird readings in my top and server health monitoring software (new relic rpm called this time 'stolen' in cpu usage graph).
I usually see this when a process or two enter "D" state. This means they're waiting on I/O from something. It's possible that this could be an NFS share that's timing out or similar. If they are the only two processes waiting on this storage device, your %CPU in IOWAIT state won't go up much.
To be clear, a load average of 2.44 can be high or low depending on how many CPU threads your system has. If you have a dual-core Xeon with hyperthreading, you have 4 CPU threads. A load average of up to 4.0 would mean the system is at or under full capacity. A load average of over 4.0 on such a system would mean there are more processes in the run queue than there are CPU threads.