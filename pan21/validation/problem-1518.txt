To me this sounds like a classification problem? You are trying to classify patterns based on some of your 'variables' (39 of them?)
Having said that I personally have never had any nice experiences with neural networks implemented in SciKit learn, if you want to definitely use neural networks Id look into something like Keras, a fairly simple neural network library.
However, from what I see this seems to be fairly structured data, that could just as well be analyzed with something like Gradient Boosted Trees or else. You might want to look at those as well, could give better results.  
Another, more time consuming method is to run the model multiple timesa and substitute each variable, in alternation, with random noise with the same mean and standard deviation of the original variable. This perturbation method will tell you how much performance decreases when one variable is replaces by noise. This is accurate but very time consuming.
As a general rule with a neural network you wouldnt need to actually create all the combinations of predictors, technically this job (given enough hidden layers) will be done by the network. For your task, as far as I can tell a simple MLP could do. 
A very quick way is to run some Tree-based ML model on your data, such as Random Forest or XGBoost. Tree-based models can return importance coefficients, estimating the relative explanatory power of each variable. You can implement a very large and deep ensemble of trees (we don't really care about overfitting at this point) so they return you the three strongest predictors. You can then take them and feed them into a Neural Network.
If that is the case first of all $R^2$ really is not the right measure. Depending on Distributions of your classes you might want to look at measure such as Accuracy, $\mathrm{AUROC}$ or an $F_1$-score.