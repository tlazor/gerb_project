Flushing the dirty OS file system buffers caused by exceeding dirty_bytes or dirty_ratio is a foreground blocking operation!
I noticed that sometimes our database is very slow - you can see a very large number of normally short queries stuck for much longer than now. It happens regularly without a clear culprit.
Tuning dirty_background_bytes or dirty_background_ratio to start flushing dirty buffers in the background is tricky.  Fortunately you can tune these settings without having to stop either PostgreSQL or the host by echoing new values to the appropriate files:
The kernel tunables dirty_bytes, dirty_background_bytes,  dirty_ratio, dirty_background_ratio and dirty_centisecs control flushing of dirty OS file system buffers to disk.  dirty_bytes is the threshold in bytes, dirty_ratio is the threshold as a ratio of total memory.  dirty_background_bytes and dirty_background_ratio are similar thresholds, but flushing happens in the background and does not block other read/write operations until it completes.  dirty_centisecs is how many centiseconds can pass before a flush is initiated. 
Recently the defaults for these tunables was lowered in Linux, as memory size for modern machines has increased dramatically.  Even ratios of 5 and 10% for dirty_background_ratio and dirty_ratio on a 256GB machine can flood an I/O system.
for example to set the number of dirtied bytes to trigger a background flush.  If you are using a battery-backed, capacitor-backed, or flash memory RAID card (you do want to keep your data in case of a crash, don't you?) start by tuning dirty_background_bytes to 1/2 the write cache buffer size and dirty_bytes to 3/4 that size.  Monitor your I/O profile with iostats and if you are still seeing latency issues that means your database write load is still overwhelming the file buffer cache flushes. Turn the values down until latency improves or consider upgrading your I/O subsystem.  FusionIO cards and SSDs are two possibilities for extreme I/O throughput. 