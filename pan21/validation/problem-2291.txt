Robots.txt is a strictly voluntary convention amongst search engines; they're free to ignore it, or implement it in any way they choose.  That said, barring the occasional spider looking for email addresses or the like, they pretty much all respect it.  Its format and logic are very, very simple, and the default rule is allow (since you can only disallow).  A site without a robots.txt will be fully-indexed.
(I could not find a way to add a comment but) Also, I would like to add that not having a robots.txt is also a problem in the sense that you will not be able to provide a Sitemap for it. Remember that Sitemap's are only located by either them being specified in the Robots.txt file or through direct submission to search engines, but of course the latter means you have to do it one-by-one, rather than just simply having all quickly find it.
I haven't had robots.txt on dozens of domains I've had registered, some as far back as 1994, and have never had a problem with them getting placed in google/yahoo, etc.
robots.txt is completely optional. If you have one, standards-compliant crawlers will respect it, if you have none, everything not disallowed in HTML-META elements (Wikipedia) is crawlable.
(Love the three minute pause requirement between answering questions.  Next I'll get the robot captcha.  Sometimes it just isn't worth trying to be helpful.)