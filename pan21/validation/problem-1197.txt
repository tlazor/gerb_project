Developed library utilizes beamtracing to provide user with realistic audio auralization. All audio effects are computed based on the actual geometry of a given game level as well as its acoustic properties (acoustic materials, air attenuation). The sound changes dynamically along with movement of the game character and sound sources. Sound path creation algorithm supports phenomena like specular reflections, diffuse reflections and edge diffraction, whilst audio processing supports signal filtering (modelling air dumping,
World of Goo: simulates mass, tensile strength, and elasticity.  The rest is faked because it doesn't add the feel of the game.  For instance it doesn't simulate gravity.  All objects accelerate down with constant force.  Boyancy is faked.  Ballons pull up with a constant force and goo balls under water experience a constant upward force as well.  This all works great for the game.  It would however break down if you tried to make a space elevator using World of Goo's physics engine.
Phya is a "physical sampling" based collision audio synthesis library which can be driven by a game physics engine.  (Bullet was used in the examples) 
I would suggest having a repeating sound effect of a spinning flute. Input the player position and the flute's position/velocity.  Skip the directional stuff for now.
I think this does not need to be an impossibly cpu-expensive undertaking,  The problem stated is entirely deterministic and should be achievable on modern hardware. (at least to a level suitable for an entertainment/learning product.)
You could record the sound that comes from each end of a flute as the air flows by and have the flute use two sound sources.  But I doubt it would be worth the effort unless the whole game mechanic revolved around thrown and spinning flutes.
Lets imagine a near perfect physics based sound engine.  What about environmental effects?  Is the flute in a cave or in a field.  Does the engine provide a predefined set of environments(how many?) or does it figure it out by calculating the actual physical topography(yeah right)?  Does the player have directional ears (ala human) or just ear holes (ala dolphin or alien) or multidirectional like an animal?  Is the air hot?  How humid is it.  This list can quickly get out of control.  
reflection/diffraction impact and so on), Doppler effect modelling and spatial effects. Finally directional sound is implemented using HRTF per each soundpath.
You are asking the wrong question.  You're making the mistake many new game programmers make.  Games are not perfect simulations, they aren't even close.  Games simulate just enough to be fun/interesting.  Everything else is faked.
Now assume for a moment such true physics sound engine existed.  Would you really want to use it to make a game?  How long would it take you to define the sound of flute flying through the air.  How many parameter do you have to get just right (100's?).
It is not so much geared to modeling resonance of air in a volume, but could perhaps be a good example of how to drive real-time audio synthesis from physics.
The question to answer is how fully do you need to simulate, and how much can you fake?  For audio just having some kind of realtime modulation of sound in a reasonably convincing manner gets you a lot without having to model acoustic vibrations down to the molecule.
What you're asking for hasn't really been invented yet.  We're getting close though- check this out, I saw it the other day: