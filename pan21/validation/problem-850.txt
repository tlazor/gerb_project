What sort of granularity are you looking for? There's a huge difference between checking a server is running every 5 minutes with a ping, and every second logging of a thousand metrics to a persisted datawarehouse for analysis, graphing, charting, trending etc.
The simplest way I know of is through SSH. You can install an SSH server on to Windows machines and most Unix servers come with it pre-installed. it's not beautiful, but it's fast, light, and gets the job done.
I think the most important question here is to work out your budget. You'll find software that more or less does the same thing across a huge range of costs, including custom work for you if you have in-house apps, support to setup and maintain the environment, and support for less common hardware or specialist software. ZenOS, Nagios, Ganglia etc are free, and have a wide range of custom scripts from opensource contributors, but you'll still pay a company if you need support. IBM's Tivoli suite, Nimsoft's NIMBUS, ITRS's Geneos, Optier, etc will cost you anywhere up to several million dollars, but come with guaranteed support, fixes, on-site consultants, global account management, etc.
For just a handful of servers, PRTG works nicely for network monitoring and the following work ok for Internet servers: