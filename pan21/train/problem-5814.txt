I posted a similar question on the cogsci SE and answered it myself after playing with the RPi a bit... that text is below. 
But for now it seems just fine for basic no-video psychophysics. And it's very, very cheap... even factoring in the cost of a small DVI monitor you should be able to get a data collection system up and running for less than 100 euro.
So I've had a chance to try out the RPi for this purpose. Short answer: it works great (with some limitations).
The RPi does not support OpenGL. I approached this system with the idea of using a python environment to create and present experiments. There are two good options for this that I know of, opensesame and psychopy. Psychopy requires an OpenGL python backend (pyglet), so it won't run on the Rpi. Opensesame gives you the option of using the same backend as PsychoPy uses but has other options, one of which does not rely on openGL (based on pygames). This 'legacy' backend works just fine. But the absence of openGL means that graphics rely solely on the 700 mHz CPU, which quickly gets overloaded with any sort of rapidly changing visual stimuli (ie. flowing gabors, video, etc.).
And it will get better, probably pretty quickly. OpenGL ES support in xwindows should come pretty quick, and once this is available it will be possible to use OpenGL ES python bindings currently under development to make backends for PsychoPy and OpenSesame. These will support fluid moving stimuli and video, and free up the CPU for other tasks. My personal hope is that this will free enough resources to allow the RPi to interface with other systems... like an eye-tracker computer or an eeg amp.
The RPi does have a very good video card (for a $25 computer) that supports OpenGL ES. Riverbank software provides python bindings for OpenGL ES (pogles), so there is the possibility for hardware acceleration in python. This has not currently been implemented on PsychoPy or Opensesame. It probably won't happen anytime soon, because there is currently an additional limitation on this system: there's no way to use OpenGL ES in the linux windowing environment (xwindows). This will probably be developed in the medium-term. But currently even a lightweight version of xwindows on the RPi is noticeably clunky and slow (overclocking the CPU helps with this). OpenGL can be used on the Pi through CPU emulation (via Mesa)... but this so heavily overloads the CPU that it's effectively useless.
So the RPi is not well suited for displaying rapidly changing visual stimuli (ie. flowing gabors, video). And PsychoPy effectively doesn't run. But Opensesame runs fine with the non-openGL 'legacy' backend. For a manual RT experiment involving the presentation of static images, this setup running on the Pi will have much the same timing resolution as the same setup running on any other computer.