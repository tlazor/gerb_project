Distributing data across a number of locations (be they partitions, machines, data centres) based on a hash is a dangerous undertaking, for two reasons:
Despite your impossible requirements, I'll scribble down my thoughts for other people in the future who aren't so hamstrung, based on my experiences doing this for Github.
A flat file pickle (in python) would work, but it won't scale as well as a DB for large amounts of data..
Ultimately, though, if you go ahead with the "all hashes, all the time" system and then hack around the problems inherent in it (there are solutions, just not real awesome ones) all you will end up with, at the end of the day, is a half-assed, botchy, non-feature-complete version of GlusterFS.  If you need a large amount of storage, growable over time, distributed across multiple physical machines, in a single namespace, I really would recommend it over anything you can build yourself.
Perhaps look at a distributed filesystem like GlusterFS.  It sounds like it will meet all your requirements and will probably be more reliable than something that you hack up yourself.
On the other hand, having a lookup table for all your files makes these problems go away.  When you say "no database", I'm betting you insert an implicit "SQL" before "database".  However, there is a whole other world of databases out there that have nothing to do with SQL, and they are perfect for this situation.  They're known as "key-value stores", and if you're dead keen on going ahead with building this boondoggle yourself, then I'd highly recommend using one (I've got experience with Redis, but they all seem pretty reasonable).