As for 'optimal performance' - there's no set in stone rule of how many files you should have for tempdb. Start with 1/4-number of cores, test your workloads, increase if need be. If you have too many files for tempdb, you might end up getting a bottleneck on your IO subsystem if it can't keep up.
Yes, you can put tempdb data and log files on SAN. You don't necessarily have to. You could (and emphasis on be CAREFUL here) have tempdb on direct attached storage (DAS) on each node, however the drive letter and the sizes must match, and you'll run into problems. Pros and Cons would be pretty much the same as regular DB files on SAN, and same HA concepts apply. IO performance might be a concern, so place it wherever you get better performance. 
Your only option is to put TempDB on a shared disk resource, meaning the SAN. Standard disk I/O contention is what you're concerned about, moreso for TempDB since it's a central bottleneck for the entire instance. 
As for how many files for TempDB, see Paul Randal's post on this subject. He's responsible for the storage engine, so he is THE expert on the subject: http://www.sqlskills.com/BLOGS/PAUL/post/A-SQL-Server-DBA-myth-a-day-(1230)-tempdb-should-always-have-one-data-file-per-processor-core.aspx
If you're using MS SQL clustering, my understanding is that all volumes must be on the shared storage, which will typically be a SAN.