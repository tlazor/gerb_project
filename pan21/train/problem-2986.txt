How is this done in the industry?  I'm sure that there are racks and racks of servers out there that all need to be managed and updated from a single source. I can't be the only one who wants to do this, right?  I want all of "user" data that is unique to a single server to be on the local hard disks, and all of the OS files (that need regular updates, etc.) to come from the PXE boot and NFS image.
I am thinking about leavings /tmp, /home and anything else that needs persistent unique storage off of the NFS image and instead mount those from local hard disks.  Would this work?  If so, how would I do it in the init script?  
I need to boot multiple servers via PXE boot.  They are all going to run the same ramdisk (i.e. "default" in the pxelinux.cfg directory), and then they all mount a root filesystem over NFS.  Then they do a switch_root command to that NFS root image.  I would like to make this NFS image read-only and use the same one for all of the servers, but then my servers are pretty much worthless as even /tmp is read-only.  
Linux live CDs employ a similar strategy; you can study how their init scripts work.  An even better example to study is FAI, which PXE boots to an aufs root filesystem consisting of a read-only NFS share and a tmpfs image.
What you want is some kind of union filesystem, where the NFS export serves as a read-only base, and a read-write overlay represents the delta.  The delta can be stored in any other filesystem, whether on disk, USB stick, volatile memory, or a writable NFS export.