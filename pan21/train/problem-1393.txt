If you knew that all the quantities were measured with perfect accuracy (no errors), you could solve using linear algebra; the system amounts to solving $Ax=y$, where $A$ is a matrix where each row corresponds to the number of each task for one person, and $x$ is a vector that reflects the time of each task, and $y$ is a vector that records the number of days each person worked.
If you have a different error model, the optimal procedure might be something other than linear regression.  For instance, if you have errors in both the measurements of $y$ and $x$, PCA (also called orthogonal regression) might be more suitable.  If you have a more complex error model, you might want to ask on Stats.SE for the most appropriate inference procedure, or consider using stochastic gradient descent to minimize an appropriate loss function chosen based on your error model.
If you suspect there might be small errors in the measurement of $y$, then using linear regression is appropriate.
I have one equation per person in the group (there are 100k people). Does it make sense to use regression to find time (task i)?
I'm working on a problem which is a multiple equation. I have a group of people and each person in the group is working on different tasks (e.g. n tasks in total). Each person in this group is working on multiple tasks and complete them. I'd like to find an estimation for the time each type of task takes.