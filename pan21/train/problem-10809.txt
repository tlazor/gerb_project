I'm confused as well as to what kinds of shaders I should be using for these different things. I hear of people using a pixel shader for gathering densities and then using a geometry shader for dealing with the terrain generation from the vertices and then somehow incorporating a vertex shader to do the dynamic deformations.
So the question is: how can I get a subset of the vertices back to the CPU for dealing with collisions among other things?
Essentially I want to remove the need for generating coherent noise from the CPU to the GPU. From there, I also want to generate the terrain for a three dimensional world using this noise as densities in voxel points. After this, I want to take those densities and polygonize (generate vertices) them representing the world's terrain.
And one more question: is there an easy way to take a set of vertices and generate indices from them on the GPU?
This is fine and all. But, I also want to dynamically deform the world in real-time. Once I get to this point, I have a problem trying to get the vertices back to the CPU to do things like collision detection and all of the game computations that I want to involve on the CPU and not the GPU.