The only correct answer here is "It Depends". There are so many factors that come into play that you will just have do many runs with different parameters try to find what are the optimal settings for your system, and you can also play with locking hints if your table has indexes that are optimal for the search condition. 
This will give you average number of rows in the clustered index. You are safe to lock on a single page which will be fast and give you good concurrency. That number times 8 will most likely give you an EXTENT lock with the same benefits and after that you'll have to play with the numbers to see when you will start to lock the table. Also it helps to have READ_COMMITED_SNAPSHOT active.
There are some rules of thumb.. if you have a clustered index on an identity column, which is not fragmented and you are deleting records from a range thats old you can safely ask the engine to lock the extends that the old records are using and delete ~64Kb at a time without fearing of blocking readers. This can help you but is not exact science and offrow data will make this different: