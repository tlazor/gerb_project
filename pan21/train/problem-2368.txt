The reason for this is that I have uncovered a major problem with our apache config, and tested my config on the dev box, and saw a drastic improvement in memory and CPU consumption.  We now want to create scripts against parts of the application which are performing poorly, such that after we change the config for production, we can re-measure them and find out how much of an improvement this new config truly is.
As for what to test, I would focus on the endpoints which normally has the highest load and/or the heaviest ones. These are the ones where you will see the difference most clearly.
I have been given access to our newrelic dashboard for the production servers running a django app on an AWS account, and tasked to come up with some gatling.io (performance testing software) scripts.  
When later on doing the comparison in New Relic, compare response times on transactions, cpu, memory etc.
My question is where should I narrow my focus?  I can't create scripts for everything, so where can/should I begin in order to provide an accurate display of the new config working properly?  How do I choose the number of users of each request, as well as the scaling of those users based on the information in newrelic?  Any and all information is very much appreciated.
Since you're running your environment on AWS, I'm hoping that you're environment is setup using CloudFormation templates or any of the services built upon it (e.g. Elastic Beanstalk). With that assumption, I'm gonna propose the following: