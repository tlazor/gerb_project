That can be achieved by using a rsync daemon on the fileserver (remember to open its rsyncd port in the firewall), or by using ssh as a transport medium between the two machines. The latter of course requires you to have local login rights to the remote machine.
... I think that affects only transfers where just one single rsync works, eg. copying between a share and a local disk. Here, that one-and-only rsync of course needs to "fetch" the whole file from the share to the client to do its comparing/copying.
If you have to transmit your files thru a "reasonable speed" network, no algorithm can speedup the process, because rsync (for example) have to read the entire file on client and on server to find duplicate contents. So if your network is Gigabit, or if you do a local copy, you just copy the files and voila. You can't get something better, execpted if supported by the filesystem (ala ZFS, but only works on the same partition).
However, if you use two different rsyncs on both the source and the target machine, you will in fact get a huge speed up! Both separated rsyncs build their checksums of the file in question locally (without transferring any bit of it!), compare these checksums over the network and then decide which (changed) parts of the huge file to transfer.
I use robocopy to copy VM files backuped to external hard drive. I would like to know if Robocopy use something like rsync to copy only changed 'blocks' of data instead the entirely file . 