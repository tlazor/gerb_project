It probably goes without saying that I'm not a web programmer; I know enough to be dangerous, but am willing to dig in & learn what needs to be done. We were planning to revamp the website at some point this year, and if using a content manager would help in this I'm totally open to that.
Step 1 Securely configure the hosting web server to have a "staging" directory, which will hold the clients' uploaded files until you can retrieve them. 
I need to set something up on our company website so that customers can log in and upload art files (we're a printing company). What I'd like to see is something that after logging in the customer would be directed to a page that shows other files they have uploaded and files that we have available for them to download. 
Not exactly what you're after, but you might consider using JungleDisk hooked up to Amazon S3.  Amazon S3 is a cloud-based file storage system, and Jungle Disk is a Windows/Mac program that you use to access the files.  Amazon S3 charges by the transfer and by storage volume, and Jungle Disk is a flat $20 one-time fee.  The S3 pricing is really reasonable, downright cheap.
I assume that you've got somewhat limited space on the web server, so I would recommend deleting them from there after you've verified that you successfully downloaded the files. If you have shell access on the web server, you can use the md5 hashes to verify correctness. If not, you may just have to go with size. 
Step 2 Write a cron job on the internal FTP server that goes to the web server and retrieves the downloaded messages. 
Every other viable solution requires your company to spend money. With your current host you are going to be limited on the file sizes you can accept. Search their forums for file size and/or execution timeout.
My company uses a technique like this. We have a process that runs every 5 minutes of every day that retrieves files, verifies them, then deletes them from the source. It works quite well for us. 
The tricky part is that the website is hosted commercially (powweb.com), but the art files need to end up on our ftp server, which is inside our firewall (with outside access.) The site is strictly static html with no content management system in use; very basic. What's the best/easiest way to accomplish this without the process getting too expensive? Anybody know of any open source or commercial packages that would allow this to happen? 
You can set up one bucket (similar to a folder) per client, and each client can get access to just their own files in their bucket.  There's no programming involved.
Your best bet is to use your ftp server. This isn't the most user friendly solution but put up an FAQ and tutorial showing people how to zip and ftp their files. Every OS under the sun has a built-in ftp client. There are even some good open source FTP clients a la Filezilla.
You can install Jungle Disk as a service on a machine inside your office network, and it will automatically sync content with your S3 bucket.  When clients upload to S3, you'll fetch those files automatically to your local server, and vice versa - when you put files in that synchronized folder structure, they go up to S3 also.