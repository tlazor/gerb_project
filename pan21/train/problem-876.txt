In this scheme the idea is to encode the feature using a single float column in which the value is the average of the target variable over all rows that share the category. This is especially useful for tree based models since it imposes an order relationship within the feature (ie values to the right of the category have higher mean response than values to the left) and it makes it easier divide the predictor space.
And here's a link to the paper that originally proposed the encoding: http://helios.mm.di.uoa.gr/~rouvas/ssi/sigkdd/sigkdd.vol3.1/barreca.pdf 
There's another approach to dealing with categorical variables that is called target/impact encoding.
There's some more details to avoid estimating the mean in categories with low counts and also there's another model, CatBoost, proposing a solution to the biasing introduced by this encoding, but in my experience it's a simple and very useful way to encode high cardinality categorical variables.
Here's a nice explanation of the subject:  https://towardsdatascience.com/why-you-should-try-mean-encoding-17057262cd0 