Your concurrency limit is definitely on the MySQL side, although I'm not sure this is necessarily a bad thing for real-world performance.  You've got MySQL to accept 100 simultaneous connections, so at most you can have only 100 Apache instances talking to it at once.  Since your test script is so simple, it's going to spend the majority of the time it's active connected to or at least connecting to MySQL.  Add a bit more for Apache processes that are in other states, and you get your concurrency in siege of 100.  I'm not sure exactly why ab gets a higher concurrency level of 200, but perhaps it counts things differently.
And another thing: have you already checked that maximum connection limits are equal between your weaker (but working) and this faster (and not working) server? Maybe the default value of 100 simultaneous MySQL connections fills up.
Perhaps there's something strange going on at MySQL's side. One thing that can easily happen during that kind of rapid "create a db connection - close it" test is that mysql_max_connection_errors fills up, by default it's only 10. 
If you want to get your benchmark numbers higher, just set your connection limits higher for MySQL.  The MySQL conn limit should probably be at least equal to the # of Apache processes for something that spends the vast majority of the time talking to the DB.  
Unfortunately with ab you are benchmarking your client performance really. You need some better performance tool like httperf which is not killing the client host. If you would like to run real testing you should use more than 1 host for it or at some case siege also a good tool. Just check what the ab is doing in fact, it might struggle with open file limits. Also good to check you server configuration.