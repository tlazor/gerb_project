In your case, it is MUCH more efficient to read whole table data from disk as single block into memory (probably in just one disk read operation or seek), and then sort it in RAM to satisfy ORDER BY, which is instant compared to disk read operation. If server read your data according to the index, it would have to issue up to 126 (oops!) read operations, seeking back and forth within same data file many times.
Now, if server needs to retrieve your data to fulfill your query, most expensive operation is to read it from disk. But, reading it according to the index order is NOT always fastest way to do it, especially when amount of data is so small.
In other words, sequential scan is NOT always a bad thing, and mysql is not necessarily stupid. If you try to force mysql to use that index, it will most likely work slower than sequential scan you currently have.
When you included your 5KB field, now query has to read 99% of data, and it is cheaper to read the whole thing and sort it in memory afterwards.
Since you don't have a WHERE clause in either query, you're returning all rows in both cases, so I'd think the use or non-use of the index would have very little impact on performance in these examples.
This suggests that max_length_for_sort_data is a limit on the total size of the columns that one is selecting, above which a filesort will be used instead of an index-based sort.
In your case, selecting entry_id (5002 bytes) takes the total size over this variable's 1KiB default value and therefore filesort is used.  To raise the limit to 8KiB, you could do:
And the reason why it WAS using index when 5KB field was not included is because then retrieved data did not constitute 99% of data in table.
You only have 126 rows in your table. Even if every row is sized to the max of about 5KB, that would mean that total size to read from disk is only about 600KB - this is not a whole lot. To be frank, it is very small amount, probably less than cache size of most modern disk drives.