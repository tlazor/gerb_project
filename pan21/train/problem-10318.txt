The current tool used to do migrations essentially uses netcat to send over the disk image file(s) and runs the appropriate virsh commands to bring the guest up on the new host (in addition to some config management tweaking).
You can wait a little longer, for oVirt to support hyperconverged virtualization, and migrate over. You will have a free opensource KVM based virtualization system, with local storage as gluster volumes, and central management for all. A bit of yum-updatesd or puppet/ansible/whatever, and the version control over the hosts is also established.
We're open to having different methods/tools that only support newer versions of kvm/qemu/libvirt but would like to be able to move the older stuff in the best way possible as well.
We're trying to find ways to reduce guest downtime and/or speed up the transfer itself by any creative means necessary.  We've spent several days gobbling up information from various corners of the interwebs, but are curious if the fine denizens of Serverfault can share some knowledge.  We can use shared storage temporarily as a middle man if need be, but aside from changing hypervisors or implementing shared storage for all hosts anything is fair game.
My team has recently been tasked with improving the virtualization infrastructure at the company and one thing we're looking into doing is speeding up migrations.  We use local storage only on all VM Hosts.  One challenge is that we have thousands of hosts running different versions (sad face) of CentOS, KVM, libvirt, and qemu.  All guests are CentOS as well.  The lowest versions we're running are: