Database replication doesn't really improve performance, since both servers still need to process and store all changes.
There are lots of ways to do this, and I don't think you've told us enough to give prescriptive advice, but basically you can do this in the application, the database, or the VM level.
Transactional Replication is great for provising near-real time read-only copies of your live database. It permits you to select individual tables, sub-sets of all columns and even row filtering in the publication, resilience to connectivity issues, multiple subscribers and a nice management interface. There are some tricks you can use to enable limited write capability at the subscribers, but they're complicated.
Performance wise PTP synchronization is relatively instant for us, which this will obvious depend on the link between data center and how much traffic there is between sites. PTP also gives us the ability to have our server act independently of one another if needed. 
This can be solved by either setting the identity seed for each table to a different value. For example server 1 will have the identity seed start at 1 and server 2 will have the identity seed start at 1,000,000. The other option would be to slightly stagger the identity seed and increment by the number of servers in your PTP replication scheme. So in the 2 server example, server 1 will start at seed 1 and server 2 will start at seed 2 with both incrementing by a value of 2.  
You might want to look into Red Gate Software's SQL Data Compare - which would allow you to synchronize the data between the databases.
One of the biggest gotchas though from experience is setting up the primary keys appropriately. If you use guid's as your primary key then there is no issue but incrementing identity columns become tricky as each database acts independently of one another. There fore you need to ensure that a key generated by the identity column on server 1 will not be generated on server 2 other wise the replication will encounter an error because you cannot insert that new record due to primary key violation. 
For background, Google for "Brewer's CAP Theorem" - it basically says you can't have your replicated highly-avaliable transactionally-consistent cake and eat it.
Peer-to-peer replication. This I've never used, but it's built on Transactional replication, so should be OK, but the strong recommendation is to only allow updates on a single node to prevent 
Merge replication gives multi-master replicas, but has onerous schema requirements, has conflicts as part of its design and has scalability and reliability issues in me experience. Avoid.
Database mirroring is only applicable in well-connected situations - i.e. same data centre. In the standard implementation if one member of the mirror fails, transactions stop for both. Synchronous transaction mirroring also slows down your production server. Avoid.
How we deal with this scenario is that we use Peer-To-Peer (PTP) replication. This allows us to not only sync databases across two separate data centers but we also have the flexibility to only sync the tables that we care about aka user data and not logging data. 
Your question doesn't say why you want replication - whether it's for performance or fault-tolerance or what, but I would recommend you consider whether e.g. a SQL Azure instance will meet your needs.
It may be worth looking into federated partitioning across geographically separate servers, but this is not a beginner subject.