We run an Apache2 web server which has somewhere in the vicinity of 2-3 million pages served every day (only HTML+CSS+Javascript, images and other content is served with Lighttpd). Our daily logwatch e-mail outputs somewhere between 3-5 "400 Bad Request" items a day. It is mostly for the same URLs every day, but rarely more than 1 time per URL. The URLs listed are mostly for standard page views on our website (URLs that almost every user will visit).
Kudos for actually reviewing your logs! I'd ignore the 400 errors. 99.999% of the time, they're client-side, and completely outside your purview; network flakeyness or a spyware-ridden browser, in my experience. 
Is the number of errors we are seeing here produced by dropped connections, or something similar? What should I examine to figure it out? Should I just leave it alone?
Just to expand on MrTuttle's answer, the 400 errors I've investigated in the wild are typically someone trying (unsuccessfully) to exploit your webserver, typically because they haven't noticed that you're not running a vulnerable version, or they just don't care.  A fair proportion of the 404 errors I get on my sites are in the same boat -- attempts to exploit vulnerable webapps I don't have installed (phpmyadmin, I'm glaring at you).
When grepping the error.log for the IPs listed in the access.log as having received the error, the result is always [error] [client xxx.xxx.xxx.xxx] request failed: error reading the headers, referer: xxx.
Based on what you are seeing, if the same IPs logging the errors can later successfully access the site, then it is probably very safe to ignore the infrequent errors for the rational that you have presented.