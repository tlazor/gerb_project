An alternative is to maintain two production environments, update the passive one, and cut over to it. This is sometimes called blue green deployment. The next version can be freshly cloned VMs with an updated OS if you want. Or newly deployed containers. Which brings us to...
Regarding sandboxing, containers are good at isolating processes on a shared OS kernel and hardware resources. One light weight container does not have access to another's resources, and you can run many of them. Although, being shared means that one hardware fault or kernel panic can bring down all the containers.  You haven't specified which OS, but the concept is implemented in many isolation technologies: Solaris zones, BSD jails, AIX WPARs, Windows containers, Linux containers.  
Often, a host is updated in place after it is deployed from a golden image template. You may have a generic web server disk, but say web2 has installed a certain release of the web site. Refreshing from the template has to preserve that customization. Maybe you can keep data on separate disks, or get very good at redeploying your application, or whatever.
Example: https://www.starwindsoftware.com/blog/automate-the-hyper-v-virtual-machine-deployment-with-powershell
There might be some OS components to maintain in a container, depending on technology. But generally not, they are usually light weight and just the userspace programs for the application. 
Answer to your first question: You can create VMs instantly through maintaining templates. It's possible on any hyper-visor.