Look at MTU. Are you  using a value large enough to cause fragmentation which in turn could be resulting in delays. Imagine that your packet size is 5 bytes too big. So two fragments are sent and the small one, only 5 bytes, gets there first. Then it has to wait until the bugger one catches up before reassembly. And if buffers overflow, then you have the classic ATM situation where small numbers of fragments lost cause many packet retransmissions.
Get a report of packet size distribution to get an idea of your mean packet size and what shape of distribution you have.
Due in part by cost and in part for additional reliability the Metro Ethernet was replaced by a T3 circuit tied into the company MPLS at the sub-site. The main site was already on MPLS with the rest of the company.
Really overall, the more data points and logs you can gather from various angles, the easier it will be to put the puzzle together.
I don’t control the company LAN or WAN, just the PCN, so I have to work through another group to find the root cause but don’t know the right questions to ask.
One of the uses for the VPN is scheduled file transfers between sites, and since the switch to MPLS at the sub-site we will have intermittent time outs for the transfers.
I support one end of a Site to Site VPN that is used to connect two ends of a Process Control Network (PCN). The PCN is separated from the Business/Corporate network by Juniper SRX/SSG firewalls that also provide the VPN endpoints.
How do I troubleshoot slow performance of a site to site VPN tunnel over a MPLS circuit? What are the relevant reports/stats I should be looking at?
Originally the business network between the sites was connected with an AT&T GigaMAN connection, which as I understand it is a brand name for Metro Ethernet Service. One site was a sub-site of the main site (mine) and any traffic that needed to go to a different company site other than mine from the sub-site passed though the main site before routing to the other sites in the company.
Do some ping tests with specific packet sizes, in particular use the MTU size and something like MTU + 5. Also calculate the encapsulation overhead (OVH) and use MTU - OVH and MTU - OVH + 5