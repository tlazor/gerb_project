All real-world implementations have their limitations, however. Even 128 cores and 1TB RAM will struggle with petabytes of data. The trick, then, is to do the best with what you've got.
There are engines that specialise in the kind of rollup queries you need called OLAP. Some are updated in batch, some synchronously. Most need a separate query language. Not sure if this is overkill for homework.
By denormalizing data you hold a value more than once. The problem is to keep the copies synchronised. This task can be delegated to the application, which is OK for small, short projects. Better to have it in the DBMS, though. Triggers are one approach. A write to a low-level value will be duplicated to the next higher level and so on. Be aware that the top-level Tables get very "hot" and may become a bottlneck.
Start with the queries. Are they returning the minimum amount of data? Doing more work than required is slower.
Have you got indexes in place? Do they match the query predicates? Is the optimizer using them? Some DBMS allow WHERE clauses on index definitions. This limits both the work on write and on read. Is clustering defined appropriately?
Generaty speaking, view results are not cached separately. When a query referencing a view is parsed and compiled the view's definition is substituted into the query's SQL and that is executed. Materialized views, as mentioned in another answer, do store the results separately.
There are different technologies for storing data. Traditional engines are optimised for disk. Recently memory-optimized engines have become common. Without the IO and with different concurrency techniques they run much faster. Traditionally data has been stored row-wise. Now column stores are available. They are especially good for aggregate queries.
It is heartening to see that you are concerned about normalization. That will serve you well through your career. Stick with it.
If a small amount of variance is acceptable caching values in the client helps performance greatly. Perhaps only do the nation-wide query every 30s, say, and perform it asynchronously so the app's latency is not affected. 