If you are working with the same data set, it would be more typical to have a single sharded deployment with appropriate zone sharding and read preferences to achieve the desired workload isolation.
What you are describing is sync between two deployments. MongoDB's built-in replication only supports replication between members of the same deployment, where all members share a common data history via the replication oplog. With independent deployments that each allow write access, there is no guarantee the deployments will be (or remain) in sync.
Unless there are strong reasons not to use the built-in replication, I would consider doing so in order to avoid the administrative overhead of syncing and maintaining two deployments.
If you do want to maintain separate deployments you could consider writing a monitoring script using change streams to watch individual collections (MongoDB 3.6+) or all non-system collections (MongoDB 4.0+). There are also third party tools like Mongo Connector, or you could roll your own solution with message queues (as you have done).
Sharding is also more typically used for horizontal write scaling, with each shard backed by a replica set for redundancy and read scaling.