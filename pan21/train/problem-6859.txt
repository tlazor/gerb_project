Yes, the whole point of multiple CPUs or CPU cores is that all of them can do different things at the same time; otherwise, why would anyone make a multi-core system if all other cores had to wait for the first one to finish its slice?
For Windows you can demonstrate this easily with the "cpustres" app. You can find this in the "Windows Internals book tools", a package distributed by Mark Russinovich at the sysinternals tools site. Get your system as quiet as possible, then use cpustres to create two threads and set their "activity level" to maximum.  Then check your CPU time graphs in Task Manager. Or use Process Explorer to watch the CPU time of the two threads. 
It's also why synchronization primitives like spinlocks, mutexes, barriers &c. exist and are necessary in the first place, which is proven by the hundreds of bugs found in real software (kernels and regular multi-threaded programs) that were caused by multiple threads accessing the same data structures at once after forgetting to "lock" them.
The Windows Internals book includes complete information on how the scheduler (not the "task scheduler", the thread scheduler) does its job. It's a long read, but worth it. The latest version of that book covers Windows 7 but there haven't been any large changes in this area since then. 
Yes, they can. In most operating system I'm aware of, and certainly under Windows and Linux, there is nothing that says that only one of a process's threads can run at a time. In fact the Windows scheduler pays very little attention to "which process did a thread come from?" in making its decisions. On a system with n cores, n threads can run at literally the same time. It doesn't matter if they're all from one process, from four different processes, or any combination. 
Therefore, yes! The threads from a single process will be distributed among the many cores and will run in parallel.