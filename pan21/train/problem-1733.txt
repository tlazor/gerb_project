My first thoughts are to reduce the number of transactions and reduce the amount of blocking.  Can you break apart some of the transactions into multiple bits?  Can you pull some of the queries out of the transactions?  As Alex_l mentioned--the smallest possible transaction is ideal here.
I have a 2-CPU system which supports about 750 user connections and a running average of 4K Batch Requests a second.  Several items are important for me: Design, Management, and Tuning.  If you start with a poor design of your application and database then you will fail at load (think scaling).
As for solution, first you should e sure that your main problem is CPU. Try to read this issue to find the source of your problems and to get appropriate solution.
Locks/blocking come from poor indexing because of all the time spent scanning tables end to end. CPU is irrelevant here.
As a quick fix, check for missing indexes using the information in this article: http://blogs.msdn.com/b/bartd/archive/2007/07/19/are-you-using-sql-s-missing-index-dmvs.aspx
Finally, I would take a look at your tables that you're using.  If everyone is blocking on a particular table, can you move the logic for that table to the end of your transaction?  If you can reduce the time that you hold a lock on that high-demand table, it could help.
Another thought is that I would also take a look at your locks.  Are you taking out table-level locks when you are only updating a single row?  You might consider suggesting a row-level lock to SQL Server.  That would solve a lot of problems.  (Granted, if you've got 5 tables, that's probably not the case, but just a thought.)
Also, using the Missing Index DMVs requires using what you know of your application and database and not just implementing each recommended index.  I would checkout Kimberly Tripp's blog entries regarding indexes here.  After the Index section, looking at the other categories might be helpful to you situation.
The rest will require work in order to get your application to scale.  You might also consider memory, but that should come after a design and performance review is done and the needed changes implemented as adding memory right away will mask your issues. 
High CPU may indicate memory pressure.  You mention there is only 7GB of memory available to SQL Server.  If you have poorly performing indexes (Too many indexes, incorrect indexes, or no indexes) then this will cause the system to page more of the database into memory for various requests then if there are appropriate indexes. I would caution going hog-wild creating indexes as the wrong ones will also hurt you as each has the potential to require an update in the course of a row update (Create-Update-Delete) operation.
Reducing the number of database round-trips within the context of a single transaction would be a very good thing to pursue.  Perhaps a stored procedure would help.
If your Java/Hibernate update of 5 tables in a single transaction is doing the updates via multiple round-trips to the database, then you are leaving yourself open to contention (Blocked CRUD requests).  The issue worsens if the application is not able to return to the database in a timely manner.  While in the application, the associated active transaction could block other requests from processing and cause request time-outs.  