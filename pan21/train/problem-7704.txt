The primary advantage of the binary reducing method is that the divisions it uses are both by fixed powers of two (specifically, divisions by 2 and 4). On a binary computer with a halfway decent compiler, you can pretty well count on these being implemented as bit shifts.
Bottom line: this produces good results fairly quickly for integers. Conversion to floating point is possible, but somewhat non-trivial. Doing so in a way that retains much (if any) speed advantage starts to move into the decidedly non-trivial range.
Newton-Raphson will usually require fewer iterations, but each iteration is slower because its divisions are by numbers generated from the input, so they need to be executed as real division operations. For integers this gains speed because although it needs more iterations, each iteration is quite fast. In floating point, you end up using a real divide instruction for each of those division operations, losing most of the potential speed gain. If you're willing to do like @Keith did and directly manipulate the bits of the floating point representation, you might be able to gain this back, because the divisions can actually be simple subtractions from the exponent part of the floating point number.
You obviously can compute that value in floating point, but doing so is somewhat non-trivial compared to doing it for an integer.
There are a couple of possible ways to optimize the code. @Keith has already done what I'd consider quite a good job of covering the micro-optimizations within this algorithm by improving your initial guess and your loop exit criteria.
...part of this algorithm must be correct to produce correct results at all. Specifically, it needs to be the largest power of 4 that's less than or equal to the input. 
The other obvious possibility would be to use a different algorithm. For one example, the binary reducing algorithm can compute square roots to the nearest integer quite a bit faster than the code you posted, and still somewhat faster than the code @keith posted.
Translation to floating point isn't quite so straightforward though. In a Newton-Raphson implementation, a better initial guess improves speed, but (at least for square root) basically can't ever result in incorrect results. By contrast, the: