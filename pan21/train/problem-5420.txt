Because each transformation is a matrix, you can combine them: you can create a "model-view" matrix or a "view-projection" matrix or even a single combined "model-view-projection" matrix. They're all perfectly reasonable and are in fact used fairly commonly, when appropriate.
If you have a good reason to have your geometry in world space for some intermediate computations during the pipeline, but have no reason to have your geometry in view space, then it is perfectly acceptable to use a combined view-projection matrix. 
The use of a concatenated "modelview" in OpenGL (which corresponds to D3D's "view" and "world") is therefore just an artefact of OpenGL's design but need not specifically refer to the way things are actually done.
There wasn't a particularly common reason to have geometry in world space, particularly since the pipeline was not programmable the way it is today. Consequently, there was not really a common need to go from world space directly to clip space, and thus a "viewprojection matrix" was not a common thing and did not gain a foothold in the vernacular of the industry.
The camera analogy is a lie because there is no camera.  Instead all that happens is a transformation of points in 3D space to points on a 2D screen, and the matrices define how that transformation happens.
Projection defines how those points are then projected onto the 2D display; i.e how perspective, foreshortening, etc happen.
Since you mention "modelview" I'm going to deduce that you're talking about OpenGL and with specific reference to the old fixed pipeline.  The fixed pipeline in other APIs, such as D3D need not have the same concepts.  In fact in the old D3D fixed pipeline there are 3 matrices used: projection, view and world.  In this case "view" is what you might call the "camera" and "world" is what you call "each model's model-matrix".
Modelview and projection are conceptually different although mathematically the same (it's all just matrix multiplication).
With the programmable pipeline all of this goes away, and you can use as many (or as few) matrices as you like, concatenating any you like in order to get the end result.
The graphics pipeline (typically) involves transformation from model space to world space, from world space to view space, and from view space to clip space. There is a transformation matrix associated with each of these (the world, view and projection transformations, respectively). There are of course stages of the pipeline after geometry reaches clip space, but they are not relevant to your question.
The reason that the term "modelview matrix" is so prevalent is because of classical graphics pipeline theory and OpenGL, where it was considered standard practice to combine the model-to-world and world-to-view transformations. This was done because there was a very common reason to have geometry in view space: it simplified the computation of lighting effects.
You answered your question well. This is exactly how it should be done for a 3D scene at least in OpenGL (not used other graphics APIs). You create your projection matrix using your FOV, aspect ratio, near and far planes and use it to render your entities, by multiplying it against each entities own model matrix. You should only need to set your projection matrix once when you start up your rendering system.