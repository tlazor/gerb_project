There is no true atomicity over the network without lots of engineering to provide it, and the more engineering required the more complicated it will be.
Nominate one server as a replicate code repository. You can then cron the updates to that repository at any interval. The rest of the servers can test if there is a local repository and then rsync the files from the nominated server. This information can be stored in the shared file server space. This will be pretty easy to automate and should be fairly robust.
There should never be two of these scripts running in parallel. This script however does not offer a solution where two scripts run one after another (which would be permitted in its current form). I guess the best means to do this would be to alter the 'done' file to be some timestamped named file which you look for the existence of before the process begins. Thus this assumes that its 'safe' to rely on the time as a medium to determine the safety of code criticality.
Another radical solution -> would be to use bittorrent sync. The repository server would be read/write while the others will have a readonly share. Might be quicker as the network load will be shared amongst the servers. btsync can be setup via a configuration file and the linux client works pretty well.
Given the set criteria the most important functional part is echo > acquire which will atomically open the acquire file. If this fails (because someone else has it, even if TWO opens at once are occurring, only one will win) the -e option of set ensures we quit the script.
To cover these problems one needs a 'fencing' mechanism (lots of changing of infrastructure) to truly guarantee re-acquiring the lock in another host is a safe operation.
There are serious tradeoffs to consider. This answer offers you no insight on what to do when the work is half done.
You will have to use some sort of lock file (before doing anything) that shows the owner of the first script and the time run. When someone else tries to execute the script it should look for the lock file then exit.  At the end of the script (if it ran) delete said lock file. 
I do mention that this isn't concrete. At the moment this offers you the guarantee that two processes cannot claim the file at the same time. As mentioned more modification to permit it not to start on the presence of a 'done' file is needed.
NFSv3 supports a atomic locking mechanism in newer kernels (well, pretty old to be frank) http://nfs.sourceforge.net/#faq_d10 . So some mechanism for a semaphore in theory can be acheived in the following way.