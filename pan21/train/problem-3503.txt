Unreliable data means that households tell lies to government. These households misstate their income and wealth in order to unfairly get more governmental services. Therefore, these fraudulent statements in original data will lead to incorrect results and patterns.
Is there any idea or application in Machine Learning which tries to improve the quality of collected data?
I have read @MaximHaytovich's answer and it is a good one. I would just like to suggest some further options, which were generalized in that answer as feature engineering. I would suggest trying to do the obvious first and analyze the data before transforming it to become ready for any machine learning algorithm. First look at the data and learn yourself and hypothesize about what patterns could be indicators of fraud. What is the nature of the data that you are 100% sure is reliable (it is mentioned in the question you posted that there is available data that is reliable) and how informative are they for the goal? The more familiar you are with the data, the better interpretation you can provide to any output you get from the methods you use. Try doing some outlier analysis on the incomes or any features that may be fraudulent that may make sense to do outlier detection on. Are there any suspicious missing values? Try doing clustering (one of the unsupervised algorithms you were talking about) to see if there are any in-betweens or irregularities. 
Local outlier factor tries to detect samples that behave like an outlier within a group. It can be useful for your case. 
Is there any way to figure out these misstatements and then report the top 10% rich people with better accuracy using Machine Learning algorithms? -How can we evaluate our errors in this study? Since we have unlabeled dataset, should I look for labeling techniques? Or, should I use unsupervised methods? Or, should I work with semi-supervised learning methods?
"According to the Survey on Household Income and Wealth, we need to find out the top 10% households with the most income and expenditures. However, we know that these collected data is not reliable due to many misstatements. Despite these misstatements, we have some features in the dataset which are certainly reliable. But these certain features are just a little part of information for each household wealth."
I don't know what are the survey questions but for example, let's say living in downtown with 3 children and going a cinema 4 times in a week form a group of people. Let's say average income of the group is 150k usdÂ per year. You saw a family in survey results in that group and said 65k usd per year, you can easily say that there might be a misstatement since families like that have higher income.
Local outlier factor provides you such anomalies. I hope its clear. You can find more information in Wiki and sklearn.