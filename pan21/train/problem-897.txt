We deal with our similar situation with SecondCopy (there are many other products that will do the same thing, e.g. rsync).  Although we use Exchange, many of our users have local PSTs with archived messages and/or have local documents that for whatever reason make sense to leave local.
Note that for PSTs, you have to have Outlook closed when you're copying them or you risk having the copy by unusable.  Also, even if a PST only holds old, archived messages, every time you run Outlook, the file is updated, so it has to be copied again even if nothing has actually changed.  For gigabyte+ PSTs, that's a lot of redundant data to be copying around.
Check out Druva for laptop clients if the PST files are NOT cache of existing data on the server. The laptop clients use at client deduplication to reduce transfer times. It is PST aware too so will only sync an email inside of a PST once back to the server.
I recently saw a presentation of avamar from emc that can do differential backups and also only store data blocks once (to simplify if an email was sent from somebody and received by somebody in your company it would be stored only once).
What is most critical for people is their Documents and PST files in Outlook.  PST files can be very large, and most people's are ~1-1.5 GB around here.  So with PST files alone that is 200-300 GB of data needing to be transferred daily to a sever for backup.  Or compressing first, then transferring, but many of the machines are VERY old and such a task would grind their computer to a halt.
My company wants to institute a backup plan for all of the clients on our network, which is about 200.  We back up our servers and SQL databases regularly, but its been our policy to not backup individuals.
Clients that are local can use roaming profiles/folder redirection, however if the user is not local, or is far away, these do not work. We have segments of our lan that are 60ms from the server and the users cry about the speed.
We have tasks set up in SecondCopy to copy any files stored locally to the user's private share on a server.  From there, it's backed up by our regular backup system.
Isn't this the reason networks use things like VMware -- to reduce network traffic and streamline backups?  Or is this only to reduce hardware costs?  Would this much network traffic everyday drastically slow down our network?  Enough to the point we'd have to mandate it to be done at night only?  Or could we stagger then through out the day?