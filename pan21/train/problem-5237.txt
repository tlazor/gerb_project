You should find an appropriate threshold of the LOF score, above which the point will be considered as an outlier. Typically, a point with score below 1 is considered as normal (non-outlier), but the threshold above 1 at which to consider a point as outlier depends on the dataset.
At run time, if new points are getting added to your dataset, then the local densities and LOF scores across points could change, and these should be recomputed. However, the threshold of LOF score that you determined as optimal should continue to apply, and requires revisiting only over a larger time period.
How does any clustering/anomaly detection( using clustering)  is even used at run time ?? Any guidance will help.
I am using LOF ( local Outlier factor) to detect outliers in my data. I get LOF score as outlier distance. this unsupervised learning doesnt help to detect outliers at run time. So I want to use my data points and LOF score to have a supervised model [regression /classification].     
 1) classification ( taking a cutoff of LOF score and after having binary variable , build classification model) and   use this classification model to predict outliers at run time.  
If you have a dataset with outlier points labeled, then you can use that to fine tune the value of the threshold, such that you get an acceptable tradeoff between false-positive rate (out of points labeled as outliers, fraction of normal points), and recall (out of all actual outliers, fraction which are labeled as outliers).