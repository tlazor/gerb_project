I currently have the data loaded in a DataFrame, and I have been able to create a new variable that shows whether or not the Run status has changed from the previous reading.  Next, I need to figure out how capture the amount of time since the last time the Run status changed.  If the readings where consistently every two minutes, I could maybe do some type of counter that resets when Run changes.  Instead, I took an approach where if the time changed, I hold onto that value and keep subtracting the next Datetime stamp from it, as long as Run didn't change. When Run changes, I start the processes over.
I have some sensor data that contains timestamps from when a machine is turned on and an indicator variable showing whether or not the machine is actively running.  The data is mostly recorded every two minutes, but they there could be more or less time between two sensor readings due to issues with the sensor.  
This approach seems to work fine on this small example, but I feel like it's not the most efficient use of resources, especially when trying to scale up to my 400,000 record dataset.  
I want to create a new feature that captures at a specific datetime, how long has the machine been in that Run status for. 