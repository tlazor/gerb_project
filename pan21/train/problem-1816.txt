Personally, in my project, I run background jobs on the same machine where database resides, but I can add more workers/machines later if there will be a need.
I don't know what kind of tasks you're going to run and which technologies will to use, but in Ruby/Rails world such task can be solved using delayed_job
It depends upon your budget, but the most desirable approach is to run jobs on separate machines from those serving web content.  It gives good separation of concerns and you don't have to worry about the web experience being affected by a heavy job being run.
IANAExpert, but I would imagine that option 1 would be preferable. The reasoning behind this is a simple separation of concerns. If jobs have their own dedicated machine, you can manage growth better. If you use option 2, you'll have an job processing potential that doesn't match its requirements. While the resources used should be the same whether one machine or many are running the jobs, I imagine whatever queuing system you're using has some overhead. Also, if something goes wrong with the queue or the webserver, you won't bring the other down. You've silo'd each part of your application, so you can grow as necessary, not as your architecture demands.
I have an architecture question. In a clustered web app environment, I can think of three ways to deal with background jobs:
Peldi, consider using an approach which would allow to have a single job queue (preferably in the database), and one or multiple job runners. This way, you can run either one or several job workers on one or different machines - and this will make your configuration flexible.
Some other information about background processing is available at http://en.wikipedia.org/wiki/Job_scheduler