But, the texture mapping algorithm you implemented is an affine texture mapping, meaning that the triangles are drawn using only plane affine transformations (thus, translation, rotation, scaling, flipping/mirroring), so when drawing you are considering the coordinates as they are, without information about their actual depth in their tridimensional counterparts. You are just drawing sprites.
By introducing information about depth, we are telling the engine that our triangle is not a flat shape on the screen, and this is achieved by editing the interpolation formula as follows:
Affine texture mapping directly interpolates between two values, and lerping twice lets the engine to draw every texel needed. This is a fast calculation to perform, but the result is not that realistic.
To draw textures correctly in a 3D space projection, we need to consider the vertices along with some information about their depth in the space in relation to the 3D camera position. To accomplish perspective correction for textures, we consider the linear interpolation formula:
where zi is the depth of vertex i in the interpolation. This way, when moving along the texture the computed texel will be in a different position compared to lerp, reflecting real perspective projection with much more fidelity. Usually this computation is harder to perform than lerping, and due to this complexity a dedicated GPU is preferable (and optimized) to calculate texture coordinates. Letting the CPU do all the work means forcing vertex processing, and is not good for your game performance.
When mapping texture to mesh polygons, you usually consider a 3-ple in the tridimensional space (three 3D vertices), and associate it to another 3-ple in a 2D plan (three 2D vertices inside a texture). When drawing, the three 3D vertices are projected on the screen ([x,y,z] to [x',y']); then the triangle considered on the texture (our three 2D vertices) is drawn on the screen, eventually transforming the 2D vertices to fit the previous projection. You know this because you actually did it.
Your code isn't wrong at all. You are dealing with matrices and vertices the right way (your 3D simulation actually works), and even texture mapping is fine. Matter is, your texture mapping algorithm uses just a linear interpolation to map a point in the 3D space to a point in the 2D plan of a given texture.
Drawing from texture to screen is achieved by screen sub division tecniques. These are methods to divide those area on the screen designated for drawing textures into pieces before performing texture drawing.
Here's a comparison between the original texture (chessboard), its affine texture mapping, and perspective-correct texture mapping.