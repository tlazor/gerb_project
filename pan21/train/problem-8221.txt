One reason I can think of in favor of virtualizing a single server into a VM on a single host is the ability it gives you to then mess with a test environment for that "server".
I'm helping out a fellow sysadmin that is replacing an older physical server running Windows 2003 and he's looking to not only replace the hardware but "upgrade" to 2012 R2 in the process.
He doesn't perceive any time in the next few years the need to move anything else to a VM or create additional VMs, so in the end this will either be new hardware running a normal install or new hardware running a single VM on ESXi.
So with the premise of hoping this can stay in the "good subjective" category to help others in the future, what experiences/facts/references/constructive answers do you have to help support either outcome (virtualizing or not a single "server")?
My own experience would lean towards a VM still, there isn't a truly compelling reason to do so other than possibilities that may arise to create additional VMs.  But there is the additional overhead and management aspect of the hypervisor now, albeit I have experienced better management capabilities and reporting capabilities with a VM.
I'm not going to provide as detailed an answer here as others have so I'll just say that I'm finding it harder and harder these days to justify installing the server OS on bare metal as opposed to installing a hypervisor (of your choice) and virtualizing the workloads. The advantages to doing this, in my mind, are:
There are a few questions that I've found on ServerFault that hint around this topic, and while it may be somewhat opinion-based, I think it can fall into that "good subjective" category based on the below:
I think the most important of those would be the snapshot capabilities. We use VMWare all over in our company, so for us it would make sense to have the server "ready" for when there's a need for more VMs.
The most compelling reason to use a hypervisor for a single server, especially with something like Windows Server is that you have total hardware abstraction for the production OS and can just move it to completely new server hardware without any problem, should the need arise. I consider this a real valuable feature that by far outweighs the drawbacks of having an practical unnecessary  hypervisor running in the background. 
If the hardware is more than capable, you could clone the server VM and remove its NIC/network abilities and isolate that clone as a "test platform" to mess with before trying the same out on the "production" server.  An example would be if the server is running an ERP software and you want to test what would happen if you ran a particular script against the ERP software/database.  You could do it on the cloned VM as a test first.  This could then be done in conjunction with a snapshot of the live VM before deployment on it, with the added benefit of knowing it should work fine.
In our discussions about his replacement hardware, we discussed the possibility of him installing ESXi and then making the 2012 "server" a VM and migrating the old apps/files/roles from the 2003 server to the VM instead of to a non-VM install on the new hardware.
Creating the same cloned "test" environment could be done with a P2V of an existing physical server, but you'd then require an additional physical host to place your new test VM on...in the above everything can reside on the same physical hardware (which nowadays is almost always overkill for a single VM)