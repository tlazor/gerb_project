When specifying data for genuine double-precision attributes, you have to use glVertexAttribLPointer (note the L) instead. The same holds for genuine integer attributes (ivecX/uvecX), which use glVertexAttribIPointer.
Using actual double-precision vertex attributes and performing double precision computations is a very modern hardware feature (GL4/DX12) and is different from specifying the type GL_DOUBLE in the good old glVertexAttribPointer call. This always worked and does nothing else than specify the input type, i.e. the type of your vertex data in memory. All it does is make the GL convert your doubles into singles and feeding them into a normal single-precision attribute (and failing when there is none), same with other input types like GL_SHORT or GL_UNSIGNED_BYTE.
Of course the answer isn't complete without some general advise, that you should really make sure you actually need double precision vertex attributes, or even double precision computation. Even on modern hardware that's still significantly slower and not what those GPUs are really made for, not to speak of the doubled memory consumption for the vertex data. More precision is not always better if it isn't actually necessary and you might be surprised what a lousy little float is able to accomplish when used well.