An MMORPG that keeps player data in memory and periodically checkpoints it has to implement this atomicity itself. One way to do this would be checkpoint every player's data at the same time, ensuring that new checkpoint is fully committed to disk before its considered the most recent checkpoint. The game would also have to ensure that player data can't change while it's being checkpointed. With a large amount of active players, the challenge becomes doing all this without causing a delay long enough that the players would notice.
Most MMOs (or projects using similar architecture) I've worked on or know of use the first method: the game servers work mainly with the RAM on the machines running the server processes, and only periodically serialize the relevant game data to a SQL database for archival (if one is used at all).
Maybe start by creating an agnostic "data broker mechanism", to handle various game data transactions? Since you are just testing anyways, create a mechanism that enables you to not need to care too much about the storage, from a standpoint of the game itself. Meaning, concentrate on how, from the host application, you are going to handle this. 
Don't underestimate how important consistency is.  When you're developing your game its going to crash a lot. You don't want have to track down why items are disappearing and/or duplicating, not when the problem is an unrelated bug is causing the game to crash at a bad time. Moreover when your game goes live, it'll crash way more than you expect it to.  Your server that was operating perfectly under testing, will suddenly expose numerous bugs under full load and players doings thing you didn't expect them to.
Further, it doesn't solve the problem. A power failure during the save process will still lose or corrupt data unless you do the work to implement the same kind of restartable save queue (which even then, that only severely reduces the likelihood of catastrophic data loss, it doesn't prevent it). 
Keep *online* players in ram, and push em to a database (SQLite? MySQL?) when they log out. if you're worried about IO stalling during logout, give each logout it's own thread, don't do it in the main/game thread (actually i keep a dedicated player thread for every online player, it made the networking code so much easier than doing the async network io approach)
On the other hand if you're not an SQL wizard you might find keeping all data in memory much simpler to get working reliably. SQL databases make consistency and reliability easier, but its not automatic. A badly designed database can perform poorly and lead to inconsistencies. Transactions won't be atomic unless you make them so.  If you don't use parameterized statements religiously you'll open yourself to SQL injection attacks. 
Storing data in itself is likely not going to be an issue, per se. Efficiently shipping data, to/from that store, between host and all the clients, could be trickier. Do I ship the entire player data set, or if I break it down into parts, what granularity do I choose to partition by, etc. Which one is more resource intensive in which situation, etc. 
Another way is binary, which is more efficient in terms of shipping, but can incur more cost in other situations.
Personally I think it would be a great asset if you could switch the actual store, without having to rewrite the game and the broker itself. Just switch to another module with the same interface for the broker to talk to. 
For example, consider the case when someone gives an item to another player. EVE's database guarantees that even in the event of a crash or power failure that the item ends up in only one player's inventory. That is, the database transaction that removes the the item from one player's inventory and adds it to the other player's is atomic. The transaction either fully completes or doesn't happen at all.  You can't end up in a state were the item exists in neither players' inventory or in both. 
One format to ship the data in, could be XML. That way you can more easily be dynamic in how it you can chunk it up. One character vs multiple characters, or one item vs a collection of items, etc. You could then either "store" the XML as XML (in SQL), and/or have SQL distribute it in a more transactional fashion from the XML, to how you want the data actually stored. 
The problems you note regarding power failure are valid, but less likely than issues like crashes in the process (uptime reliability is generally one of those things you'd pay the datacenter for). But still. You mitigate those issues through things like tuning the save interval (so a failure only costs at most a few minutes of progress), distributing the save queues across multiple machines, aggressively scoping the amount of data that needs to be saved, and implementing restartable save queues.
For your project you can probably go either way.  Having 1000 simultaneous users probably won't push the limits of what an SQL server can handle on a commodity PC these days, but a lot will depend on the nature of the transactions. If you're familiar with SQL and relational database design then this can work for you.  You'll want to minimize the transactions as much possible, for something like player current hitpoints you might only want to periodically save them to the database since stats like these don't necessarily need to be consistent.  (In PvP game they might though...) Don't store things like monster HP in the database at all, in most games only player related data is persistent.
With 1,000 clients, you could start with, and easily store 10 MB per client and only use 10 GB of effective RAM + add some system administrative RAM for managing that data, say another GB or two. You could keep that in RAM on the host already in data structure ready for use. And load/save dynamically, depending on who is online, in various frequencies depending on activity, etc. 
Generally speaking, using the SQL server itself as main memory is going to be unpleasantly slow (and cumbersome). I don't see enough detail in your proposal there to be able to say for sure if it would work for only about 1000 players -- it would probably be fine. But I don't believe you can make it aggressively scalable.
Both approaches are used with MMORPGs.  Keeping everything in memory and periodically check pointing it to disk seems to be the most popular option, at least for older games.  It has the advantage of being fairly simple to implement and scaling fairly well, but making it reliable is completely up the to the developer. SQL databases provide ACID properties that make reliability easier, but are overall more complicated to implement well and can have problems with scaling.
Various games store things in different ways. Often, game companies create some way to do this, and most of their games use the same way. Of course, different studios often use different ways. SQL is certainly used for games, e.g. CCP (EVE) has (or at least had) a network of SQL servers, I am not sure how they do it now. Others, just use lots of files. 
EVE Online is an example of an MMO where everything is stored in an SQL database.  I think it peaked at something around 60,000 simultaneous users, and has had to dedicate some expensive hardware to the database servers over the years in order keep up with the load.  However EVE stores a lot more data per user than than most MMORPGs and has a lot more frequent and varied transactions. The database's ACID properties allows the entire massive and complicated database to always be kept in a consistent state.
Note that most MMORPGs use SQL databases for account related information even if they don't for actual game data. Even more important than keeping the game state in consistent state is keeping the billing state consistent. Worst case for the game database getting corrupt is that you have to restore the database from a daily backup. Worst case for account database getting corrupt is that you go bankrupt because of all the chargebacks.