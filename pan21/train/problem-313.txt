An assumption of independence is usually made to deal with sparse situations. Naive Bayes for instance works pretty well for document classification tasks: Each word (token) in a document is taken as an individual observation governed by a probability distribution belonging to the document class
NOTE: That even though your rule sample is small, it is still quite complex Suppose we eyeball it and make a naive rule: If humidity < 83 roughly add around 55% That would emulate your rules quite well, and make it less complex, unless it happens to be a cold spring or summer day. Is that really a rule? Would that cause faulty predictions? Or did we just see little or no cold days that varied in humidity in that sample (200 data points)? I wouldn't start betting my bottom dollar that people react differently to humidity given the date on the calendar 
Well, are you content with a system that doesn't work on that one day in winter when the temperature actually reaches 40 degrees? And would you care, since you probably now got other things to worry about
Tree-based classifiers, on the other hand, generate composited rules and are thus geared toward exploiting conditional probabilities. Eg: If it is 12.2 degrees or below, and it is Winter, then the humidity is the discerning factor in bike use. 
You pose that the tree rules protect against probability mass leaking to impossible situations. Conversely you could pose that naive probability would help you make predictions about situations that were sparse in the dataset. Whether you'd want that is up to your reasonable judgement. It is machine learning, not machine wisdom