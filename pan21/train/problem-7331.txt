You may also wish to consider a reverse proxy - Squid, Apache, nginx, lighttpd can all provide this functionality - where a full web request is made to your reverse proxy, and that reverse proxy then forwards that request to one of the back end web servers. It's a heavier load approach than LVS but far easier to initially configure.
Linux Virtual Server provides for an intermediate server (load-balancer) which will simply forward incoming IP packets to other servers who send their responses directly back to the requesting client.
You can use haproxy. It can be used to implement load balancing and proxying for TCP and HTTP-based applications. It has many load balancing algorithms such as: round-robin and least-conn.
I have a web application currently running on a single LAMP server, and I'm planning 2 split it into two servers, such that the client requests reach one of the servers from where it will be forwarded to the second server in case the load on the first is high.
Sticky load balancer: Each client go and stick to one server (with a sticky session), it works with any application, but it's not "real" load balancing because your client stick on this server, and if your server stop working, the clients stick on this server won't be able to use your website (temporally)
Simple load balancer: Each client go randomly (or depending on parameters like server load, amounts of requests, etc) on a new server at each requests. It's the best, but your web application need to be configured for this, you need to synchronize the sessions and if possible the cache between the different servers (with memcached by example), and it can provide H.A (with HAProxy by example), it detects down servers and stop sending client to them automatically.