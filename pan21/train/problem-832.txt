Yes, thankfully the key here is "relevant to my renderer". This might be no more than adding an an old position and a timestamp for it into the mix. Given 2 positions you can interpolate to a position between them, and if you have a 3D animation system you can typically just request the pose at that precise point in time anyway.
Each game object would, at the end of it's update, set it's current state in to a set of these interpolatable vectors/matrices. This sort of thing could be extended to support threading, you'd need at least 3 sets of values - one that was being updated, and at least 2 previous values to interpolate between...
It seems generally more effort than a variable timestep system (assuming a sensible range of framerates, in the 25Hz-100Hz sort of range).
Note that some values can't be trivially interpolated (e.g. 'sprite animation frame', 'special effect active'). You may be able to skip interpolation entirely, or it may cause issues, depending on your game's needs.
In my setup, each RenderCommand has the 3d geometry/materials, a transformation matrix, and a list of lights that affect it (still doing forward rendering).
I started by having three copies of the game state of each node in my scene graph.  One is being written to by the scene graph thread, one is being read by the renderer, and a third is available for reading/writing as soon as one of those needs to swap.  This worked well, but was over complicated.
I did try the fixed timestep+interpolation approach once for a very small prototype - no threading, but fixed-timestep logic update, and as-fast-as-possible rendering when not updating that. My approach there was to have a few classes such as CInterpolatedVector and CInterpolatedMatrix - which stored previous/current values, and had an accessor used from the render code, to retrieve the value for the current render time (which would always be between the previous and current times) 
My render thread no longer has to do any culling or light distance calculations, and this sped things up considerably on large scenes.
It's quite simple really - imagine your renderer has to be able to render your game object. It used to ask the object what it looks like, but now it has to ask it what it looked like at a certain time. You just need to store whatever information is necessary to answer that question.
I've heard this approach to timesteps suggested quite frequently, but in 10 years in games, I've never worked on a real-world project that relied on a fixed timestep and interpolation. 
It just sounds like a recipe for added pain at this point. I haven't thought through the whole implications but I'm guessing you might gain a small bit of extra throughput at the cost of higher latency. Oh, and you may get some benefits from being able to use another core, but I dunno.
I then realized I only need to keep three states of what was going to be rendered.  My update thread now fills one of three much smaller buffers of "RenderCommands", and the Renderer reads from the newest buffer that's not currently being written to, which prevents the threads from ever waiting on one another.
IMHO, it's best to just go variable timestep - unless you're making an RTS, or other game where you have a huge number of objects, and have to keep 2 independent simulations in sync for network games (sending only orders/commands over the network, rather than object positions). In that situation, fixed-timestep is the only option.