In my mind it is more straight forward to make each unit responsible of it's own behavior and I think that it would be easier to give them a more "natural" look implementing it this way. However it's probably a lot more inefficient in memory and processing time that a centralized one. Again, I'm super new to games so any example of how is the AI implemented in some major games would be appreciated.
In this article the autor is talking about Group behavior. Still I guess it depends on your requirements whether you decide to implement a centralized AI or not.
The first decision has to come from what the gameplay requires. There are some behaviors that are going to require coordination, and will be easier and more efficient to implement in a centralized way.
Should I have a centralized AI module that looks for the position of each character and zombie and determines the best way to move each of them? Or should each instance of a zombie or human be responsible for its own behavior?
Finally, when you need some coordination, look up Blackboard architectures. Create a common place where individual characters can add pieces of data to communicate with each other (for instance, if you only allow one character to attack the player at once, you could put a reserve token there).
I'm very new to game development, but an experienced software engineer. As an introduction to game dev, I'm making a 2D zombie game in Python, using pygame. The game is almost done, but I still have to write the AI for the other humans and the different zombies in the game.
The downside of this is that if you have a lot of them around you are going to need to do a lot of processing on each decision cycle so if you have large levels you may want to have an overview AI for the area outside of the user's viewport, just controlling how many NPCs are in the area and occasionally posting some new ones into view, and then the agent-based approach for those that are currently visible. 
I understand this is probably a very subjective question, but I'm looking for an answer that covers something like pros vs cons, industry standard or known cases of each one.
In practice then, the only CPU benefit you're going to get from running all the behaviors in a centralized way is saving the instruction cache. Because you're coding in Python, I'd say that's not a prime concern :)
In terms of memory, the best way to store the information is to split it between shared data and instance data. Shared data will include definitions, tuning, etc. If you use behavior trees, the behavior tree can probably be shared. Instance data is what relates specifically to that character: their position, their state, which BT node is active, etc. This will give you most of the savings you'd get from centralizing the AI.
To look at it from a purely performance/architecture point of view, let's assume that you want individual behavior. It's unlikely that you can reuse a lot of computation, as AI is usually very context-aware. You have to pathfind and cast rays from the position of each character, so the results will be different. Besides, unless required by the game design, if all characters react in the same way at the same time you'll get a very poor result, with everybody moving in perfect sync.
If it were me I would give each NPC agency of their own - if each one has a simple goal ( get as far as possible from Zombies/get as close as possible to humans ) that they act on, you can get quite interesting behaviours from relatively simple inputs without too much processing. 
The best approach for your particular case will undoubtedly be to experiment with the options and find the simplest case that is fun. As a general rule, the more complexity you add the more frequently it will fail. Because AI tends to be non-deterministic it is way harder to validate its operation with automated tests, but fortunately manual tests are often either interesting or hilarious, so it has its merits.