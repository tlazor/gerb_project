We let our SANs manage the RAID.  Why spend money on all that battery backed NVRAM and those dedicated processors and then offload the work onto the server, whose CPUs I want doing something other than RAID checksums?
This makes sense on a computer with 2-16 or even more local disks, but what about in an environment with a large SAN?  
If you don't give ZFS redundant data to work with (e.g. mirrors, RAID-Z), then you lose many of the benefits of using it. The number of disks involved won't change that fact. However, whether that matters really depends on your environment. You have to determine what storage features you need (a potentially labor-intensive analysis) , and then go hunting for the least expensive solution (you can afford) that meets your needs. That may mean using ZFS everywhere along with specialized Oracle storage devices (some people do that and have many disks exposed to ZFS without problem, and use Oracle tools to do management), it may mean using only enterprise SAN products, or it may mean using some hybrid (in which case you'll probably have to develop some tools and processes on your own to manage the environment). Don't forget that your analysis needs to account for the human element as well (e.g. maybe you have a team of Storage people who have highly useful and specialized training with a SAN product which you would lose if you went to an all ZFS solution).
A device that presents the raw disks (over SAS or less likely over FC) is a DAS.  To run ZFS, typically you'd be telling the RAID controller to present the disks as a JBOD.
For example, the enterprise I work for has what I would consider to be a modest sized SAN with 2 full racks of disks, which is something like 400 spindles.  I've seen SAN shelves that are way more dense than ours, and SAN deployments way larger than ours.
Do people expose 100 disks directly to big ZFS servers?  300 disks?  3000 disks?  Do the SAN management tools facilitate automated management of this sort of thing?   
ZFS vs for instance EXT4, provides a few extra features such as scrubs that check checksums or for running snapshots.  A scrub probably can't auto heal in the same way that it can if it is doing the disk RAID, but it can still alert you to corruption, helping to prevent bitrot.  The snapshots you can create on, for example, a Linux SAMBA fileserver are vastly superior to what you can do with EXT, these can even be exposed in Windows as "Previous Versions).
To answer the first part of the question, I'm not aware of what we would call a "SAN" that would ever expose the raw disks to a server that could run ZFS.  A SAN by definition only presents block storage (LUNs) or perhaps with something like a Filer/FS presents a NFS or CIFS.  There are some "SANs" that actually run ZFS internally, but this is largely abstracted away - the disks are never exposed to a server, instead the "Filer" component of the SAN presents block or network file systems to servers.
Most discussions of ZFS suggest that the hardware RAID be turned off and that ZFS should directly talk to the disks and manage the RAID on the host (instead of the RAID controller).