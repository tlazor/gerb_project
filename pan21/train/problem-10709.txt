Let's take a really simple scheme -- one you'd never use in real life, but is simple enough for now -- and subtract those 3 units to the next pixel to the right. Say that pixel has a value of 67. You'd subtract 3 from 67 to get 64. 64*15/255 rounds to 4, 4*255/15=68, and now you've got an error of 4, which gets subtracted from the next pixel to the right, and so on.
Basically, the idea is to spread out the error to adjacent pixels. Let's take a grayscale image for simplicity (for RGB you'd just do the same thing for each channel), and say you had an 8-bit pixel value (255 max) of 116 that you want to scale to 4-bits. The closest 4-bit color (15 max) would be 116*15/255, which rounds to 7. This, expanded back to 8-bits would be 7*255/15, or 119. Therefore, your quantized pixel will be slightly brighter than the original by 3 units. To compensate, you spread 3 units out to adjacent pixels (there are several schemes for how the error gets distributed) and subtract them in before the quantization step on those pixels.
The error accumulation above is a good reason why you usually spread the error to more than one pixel. Floydâ€“Steinberg dithering adds 7/16 of the error to the pixel to the right, 5/16 of it to the pixel below, 3/16 to the one below and to the left, and 1/16 to the one below and to the right: