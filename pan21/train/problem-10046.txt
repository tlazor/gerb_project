Similarly, this was the motivation for my question about connectivity between VPC-2 and VPC-3.  VPC-2 can't transit VPC-1 on its way to accessing addresses in VPC-3. 
tl;dr: VPC peering doesn't enable any IP routing or connectivity beyond the EC2 instances in the directly-peered VPCs.
This is probably less clear than it could be to those who are unfamiliar with typical VPC configurations, but this limitation actually explains more precisely why the configuration proposed in the original question doesn't work.
You configure a subnet to use a NAT instance by creating a route in the subnet's route table to send a specific foreign prefix (typically 0.0.0.0/0, but it could be a subset) to the instance itself, or its Elastic Network Interface, by ID.
But within the region, if you try to route traffic to the ENI of an instance in a peered VPC via the route tables, that fails: 
You'd have the same issue if you had a VPC Hardware VPN between VPC-1 and an external corporate datacenter.  That VPN connection would not provide access from the external data center to anything outside the borders of VPC-1, regardless of any peering.  The same is true for AWS Direct Connect.
The cleanest configuration would be a full-mesh of tunnels among all your VPCs (or all your availability zones, except for availability zones within the same VPC or any that are directly peered).
The issue is not so much that VPC-1 can't reach VPC-4 via the tunnel to VPC-3 (the traffic may or may not arrive), but rather than VPC-4 has absolutely no way to send a reply.  VPC-4 can't transit VPC-3 on its way to something external to VPC-3 (VPC-1).
So, the above is not a perfect explanation, since in the documented example, all three VPCs are of course in the same region, but similar principles apply to your configuration.  
Traffic addressed to something other than an instance (or service running on an instance, like RDS) -- when it arrives at the peered VPC -- has nowhere to go, and is discarded.  
Consider this example from the documentation (with minor reformatting for clarity), which -- admittedly -- does not describe your situation precisely, but contributes to an understanding of the larger issue at hand.
At the bottom of the documentation page mentioned above, we find a one-sentence limitation on a practice like this:
The logical workaround would be to try to route traffic across a peering connection to an instance acting as a router... much the same as the way you route traffic to a NAT Instance -- by setting the destination in the route table to the instance-id or its associated Elastic Network Interface (ENI).
Analyzing this only from the perspective of the API/Console interface, consider how you send traffic across a peering connection:  You create a route sending the foreign IP prefix from one VPC to another by creating a route table entry using peering connection ID as the target.  
That's a trick question, because no exposed route table applies to traffic coming in over a VPC peering connection -- the only routes available to that incoming traffic is the implicit local route that makes instances accessible.
The incoming traffic bound for the remote network never makes it to the tunnel server, because there is no mechanism for transiting across VPCs, and traffic to the tunnel server -- though perhaps not clearly documented as such -- is still a case of transiting.
That's part of the design of VPC peering -- it is a feature affecting only the instances in the two VPCs -- they can access each other. Other resources in the VPCs, such as NAT and Internet Gateways, VPC Service Endpoints (for S3), Direct Connect, and Hardware VPN are not exposed via peering.  
A peering connection does not give you the same level of connectivity that you might expect from a VPN or other network-to-network interconnections you may be familiar with. 