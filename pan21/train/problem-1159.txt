Where theory (I/O separation is best-practice) runs smack into reality is in how some of these big SAN arrays are designed. While the sequential I/Ops of four 15K RPM disks is rather high, a lot of these arrays intentionally randomize block layout so you're not going to get that performance even if you create a 4-disk Disk Group dedicated solely for one SQL Log volume. They will probably run into some sequential benefits, as the block-size is usually larger than the 4K used by the disks themselves, but it won't be the screaming demon you'd expect from a pure-sequential load.
Where it comes into play is if I'm building dedicated storage for a database. This assumes that the I/O needs of this one service are so great, or the I/O SLA is strict enough, that having performance guarantees is a must. In that case I actually will create discrete disk-groups for things like Log, TempDb, and DB volumes. This kind of design doesn't happen very often, very rarely in fact.
I try to match the expected I/O demands to the architecture. For almost everything I've done, the SAN approach of if you you throw enough disks at it, total I/Ops exceeds all but specialist workloads ends up working pretty well. If I've got 96 spindles in use, the total I/Ops I have at my disposal is enough to keep the SQL-sever log-files fed even with an Exchange server running on the same disks.