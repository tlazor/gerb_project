Would this be effective at all? Is there a way to some how link the layers so that the layers with the larger window would not learn patterns from layers of the smaller windows? Or should I just make the original convolution layer larger with more filters?
PS The my original idea was to pair each individual convolution with an LSTM on top of it, and merge these into another convolution with an LSTM on top of that, but it seems to be prohibitively complex on my computer. 
My idea was that since these sequences have different types of features with at different sequence lengths I might try sending my input sequence to multiple 1dconv layers with different window sizes and then merging them back together.
I am rather new to neural networks, having used Tensorflow for a couple months now, and am looking for some advice I have on an idea to improve the accuracy of my model. I am looking at sequences using 1d convolution layer with spatial dropout, and an LSTM to look for spatial relatedness of these features. 