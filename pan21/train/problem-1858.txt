You haven't mentioned how you are adding these connections together, but I assume you are talking about Channel bonding or Link aggregation.  If that is what you plan on using, then please understand that the bandwidth is not cumulative.  What you actually get is more like load balancing, some connections go over one interface, some go over the other interfaces. 
If I add all the parallel connections there should be a maximum speed of nearly 400MBit/s possible, so I gather that the 100MBit/s per connection is some kind of throttling.
Gigabit ethernet does not do any throttling in the way that you are surmising. There are many factors that might limit the speed you are able to run iPerf at, including the type of test you are running (TCP or UDP, Window size, packet size, etc. see the iPerf manual for details), the resources available on the testing hosts (e.g. if you are limited by your CPU, a single test might consume a core, while parallel tests use additional cores), and the type of switch(es) you are connected to. Additionally, there may be intermediary devices that ARE throttling you in some way, but that is a policy configuration, not a feature of gigabit ethernet (e.g. are the two hosts under test directly connected via a single switch, or are there firewalls, routers, or other devices in between them?).
I need maximum speed between these two computers, is there any way to disable this throttling so the full throughput can be used by one single connection instead of being shared between more of them?
Also, check on the CPU usage - its generation of data may be saturating a core when there's a single process, while 4 processes can utilize 4 cores.
Bonding typically will select the interface based on some details about the hardware address of the destination, or some aspect of the network protocol in use.  The point being that for a single connection will be limited to a single interface, it will not use the combined bandwidth of all interfaces.
By default, iperf uses a TCP connection.  It may be backing down on rate due to TCP's congestion control or a window size issue; try a UDP test (-u).