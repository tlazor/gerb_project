We can equivalently think of this as finding a minimal vertex cover for $G$, given ability to query whether a particular set is a vertex cover or not.  The  algorithm is as follows:
Thus, we do a total of $O(k \log(k/n))$ iterations, i.e., a total of $O(k \log(k/n))$ queries.  When the algorithm terminates, we have found a minimal vertex cover.
$$\left(1 - {k \over |S|}\right)^{|T|} \approx \left(1 - {k \over |S|}\right)^{|S|/k} \approx 1/e.$$
Each time that we successfully reduce the size of $S$, we multiply its size by a factor of $1 - 1/k$.  We start with $n$ vertices, and end with about $k$ vertices, so the number of reductions $r$ satisfies
In other words, there is a constant probability in each iteration that $S \setminus T$ is a vertex cover.  Thus, the total number of iterations is proportional to the number of times that we succeed in reducing the size of $S$.
How many iterations does this take to converge?  Well, for $S \setminus T$ to be a vertex cover, $T$ must avoid all of the vertices in the final minimal vertex cover, so the probability that a $S \setminus T$ is a vertex cover is at least
What is the cost of testing the termination condition?  The algorithm terminates when we have already tried all possible subsets $T$ of $S$ and none of them can be removed from $S$ ($S \setminus T$ was not a vertex cover for any subset $T$ of size $\lceil |S|/k \rceil$).  Note that we'll end with a vertex cover of size $\le k$, so in the last iterations, $|T|=1$, so it'll only take $O(k \log k)$ iterations before we've tried all possibilities for $T$.  At that point the procedure terminates.  So, this doesn't increase the total asymptotic running time.