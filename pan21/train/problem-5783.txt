My current understanding is that anything done in a shader file is done on the GPU, and anything done in my (Java, in my case) code is done on the CPU.
But like he says, OpenGL driver could run stuff on the CPU, and it actually happens a lot. Especially with compatibility contexts, where some weird legacy functions cannot be implemented on the graphic cards. They require software emulation. For example, I've heard before that stippling is executed on the CPU. You can expect also surprises with picking.
Conversely, code that is executed through computing libraries like vexcl or boost compute, or microsoft's AMP, or nVidia thrust, CAN be executed on the GPU or the CPU depending on API setup flags.
These surprises can happen even more on MacOS using 2.1 contexts, because Apple has unified the view of OpenGL quite well accross their hardware range, and some smaller hardware lacks some stuff that has to be emulated. It goes so far as to actually be possible to execute the ENTIRE OpenGL 2.1 spec fully on CPU, if the context creation code specifies a software device explicitely.
In principle, the platform could, conceivably, do whatever it wants. One could imagine an advanced operating system doing just-in-time translation of compiled code from, say, x86 to GPU code. Similarly, OpenGL drivers could run whatever it wants on the host CPU.
And for the finish touch, inside the CPU you also have a DSP architecture with the part of it we call SIMD. Intel's ispc compiler provides help in generating code that is "ensured" to run on SIMD lanes with lots of performance diagnostics at compile time to help you make the most of it. Add OpenMP to that and you can get multithreaded SIMD, which approaches the concepts of GPUs. If you have a high end CPU and low end GPU, this can actually be more performant.