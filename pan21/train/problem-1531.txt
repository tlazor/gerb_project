The appropriate method to evaluate whether you have modeled a real signal or noise is completely dependent on the question you are asking and the modeling approach you've used to address it. Many very thick books have been written on this topic, often constraining their attention to one problem domain and/or type of model. The complexities associated with model evaluation are a big component of why data scientists generally have graduate degrees. Which brings us to the second part of your question:
Your tech illiterate superiors don't have that graduate degree that would inform them how to evaluate your analysis. They're trusting you to present honest and accurate results. It is extremely easy to mislead people who aren't stats-fluent into believing whatever narrative you want to present. It's your responsibility to make sure your results are air tight, or at least in synch with your client's risk tolerance. 
Your results are ready to be shared when you are satisfied that you are interpreting them correctly, and you have a plan for how to communicate them plainly. 