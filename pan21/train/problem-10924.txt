Column Compression such as Oracle's Hybrid Columnar Compression satisfies your goal of fewer bytes for faster lookups.  It also has the benefit of decreasing disk space, though not as much as the automatic enum you describe.  On the other hand, it can handle far more than 200 distinct values and requires no application side changes.
The industry standard way to handle this is with a separate table (often called a lookup table) and a foreign key reference to it.  Some database platforms support emun data types, but they seem inferior to lookup tables when it comes to maintenance. Changing enums requires altering the structure of a table; changing data in a lookup table is just changing a row. 
The strings could be mapped to IDs in a separate table, and that way you would not need to repeat these strings on every row of the primary table. Ideally the database would manage this internally for you. The unique strings would be stored as part of the table definition, invisibly, internally, and the system would work great, no need to modify the app, for all string fields that are below 255 distinct possibilities.
There are some tables that I manage which contain a string value (for example, a 4 word "Type" field).
Application code that needs to present the strings to a user queries the lookup table for the strings and their id numbers or their codes in sorted order, then loads the result set into a combo box, listbox, or whatever.  Any strings added to that table will automatically appear in subsequent queries, unless you're using a cache that doesn't update automatically.
Maybe I'm missing something but why wouldn't you just use a lookup table with a foreign key relationship for this sort of thing potentially with some views to provide a layer of abstraction?  That's a very common approach, it's supported by all databases, it's pretty easy to implement, and it solves other issues such as data consistency (i.e. what happens if you want to update an existing string without updating every row in the table that has that string).  If you know the maximum number of entries in the lookup table, you can pick the data type that minimizes data volumes for the primary key.  That's also much easier to handle in the future when someone decides that the number of distinct values needs to exceed whatever limit you specified initially-- you just need to increase the size of the column in both tables.
Famous last words. I'm always happy to bet against this kind of requirement, because I know I'll win a lot more often than I'll lose.
I have this idea that I doubt any database engines are supporting, but I wanted to check with the experts.
Is there anything like this on any database engine? I mostly use MySQL, but I am curious if this has ever been implemented, short of modifying the applications call a custom wrapper function. (like INET_ATON, except that it would transparently do an INSERT to an AUTO_INCREMENTing table to get the ID for the first time)