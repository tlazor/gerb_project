Unity uses a precalculated visibility matrix, composed with regular sectors of your world, and a quadratic ray cast test. Which has the same flaws but you don't need to implement anything, Unity has it built in. It takes a while to preprocess, you can even visualize the boxes getting computed and turning from red to white as it goes.
The correct geometry based techniques usually resort to some conservative convex hull shape creation, then determine visibility against potential occluders anti-conservative hulls. This is not easy to do, takes a lot of CPU time and usually brings no benefit.
Of course many of the aforemetnioned techniques does not let you know the visibility of one chosen object on the CPU side, but it depends of what you want to do with that information. Mostly its used as a render/not render flag so fed back to rendering. This is why the hardware occlusion queries can be kept on GPU side only and could perform OK in some situations.
You won't get away on this one with an easy answer. The raycast method is completely flawed. Its the same as calling the object "one pixel" wide and checking if this pixel is visible or not.