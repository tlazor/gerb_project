Running both tests consumes less watts than the CPU test alone. ????  Interestingly when I turn off either the GPU or CPU test the wattage goes back to the "base" wattages of each test; 84 watts for CPU only (when I turn off the GPU test) and 54 watts for GPU only (when I turn off the CPU test).
Running "full tilt", the CPU test does seem to max out the power supply, but if it ain't broke, don't fix it.
Because modern OS's use preemptive multitasking, giving slices of time to each running thread (depending on priority). If the CPU runs on its own it gets more time than if it has to share processing with the less-intensive GPU test, as shown by your own measurements.
The power supply is pretty wimpy and I wanted to see how much wattage it was drawing on full load so I connected my kill a watt meter and ran Prime95.  My watt meter showed 84 watts!  Whoa!  So at full load I was coming very close to going over my power brick limit and was actuall 4 watts over my converter limit.
Next I decided to do a GPU stress test.  This AMD APU has 384 cores so I wasn't expecting too much of a power draw.  I used Furmark from the GPUInfo test suite and my watt meter showed 54 watts.
So my question is; why is the wattage lower when a GPU and CPU stress test are running at the same time than the CPU test alone?
Now here is where it gets confusing to me.  I was curious what would happen if I ran a GPU and a CPU stress test at the same time.  Would my power supply take it?  Would it burst into flames?  I decided to wait for my wife to go out on an errand and while she was gone I ran Prime95 and Furmark at the same time.  I made sure I had some new fuses and, armed with a fire extinguisher cocked and ready, I hit the enter button on my keyboard and...  my watt meter showed 77 watts.  No sparks.  No fire.  No smoke.  No blown fuses.  No having to craft lame excuses to my wife about why the HTPC was no longer working and the house smelled like burnt electrical wiring. 