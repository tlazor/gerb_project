In something like 100K worth of data, it's not going to be the file access that's going to be the difference per se but the way the data is organized vs the way its used.  In your example the same type of code could be used on both the sql Ce and text files (w/ ado.net) but if each record had 15 fields the indexed table will retrieve the correct record faster than a text file can be parsed to locate the same record.  However as the number of fields gets smaller so does the performance gap.  The performance gap is usually even greater when considering updates to records.  Another benefit of an embedded database from a design standpoint is that unlike a general data services application, a local datastore application already knows what questions are possible to be asked.  Thisw means I can create views to speed up query execution even further. Also when designing a data service application, you have to worry about how expensive (in terms of iops and performance) a query is vs a local database that can get as expensive as the user is willing to put up with.
There are other trade offs as well, such as not having to reinvent the wheel and just general code maintenance. 
If you are going to be storing LOTS of records, then having an indexed table can definitely speed things up. A lot of super simple databases are in-process and generally not too keen on sharing connections, so if they are used in a web application (or just lots of concurrent threads) a lot of those databases can start having real issues.
For the volumes you mention, a database will probably be faster since you can index the tables.  It depends, though, on if and when you cache the .ini file.  If you have the luxury of caching the file once when the process starts, that method may be faster.  However, if you have to repeatedly reload the file, the indexed table in the database will probably be quite a bit faster since it doesn't have to load the entire file when it's accessed in order to pull out a single row.