This curve shows how the iterative process of computing our error, updating the weights and repeating, takes us down the gradient of the error/cost. We do this iteratively, in little steps. The weights of the model are stored between stages - the weights are persistent between iterations. Once the model is happy, measuring small/acceptable errors, we are finished training and can use that hold-out test dataset to validate the model's performance. 
Welcome to Data Science SE! As a short answer has been given, I'll give a longer overview of the problem, starting with a analogous human approach. But first, a formal definition of machine learning from Mitchell:
The weights we start with in a neural network are most commonly just random numbers. We ask the model to perform a task, then use gradient descent with the errors to slowly improve those random weights with tiny alterations. At the end, it is these weights that we save to disk on the computer. They are intellgient combinations of simply decimal numbers.
To get your head around machine learning and what it means, at the highest level, you might want to read an article like this.
Gradient descent (and e.g. backpropagation) are then really where learning happens. They're the methods by which we update the weights. They basically close the loop from (1) getting an error –how unhappy we are– to (2) being able to adjust those weights slightly in a way that would make us better at that task next time. This really equates to adding or subtracting a small amount from the existing weights. Exactly how much we add/subtract is controlled using the learning rate parameter. If it is big, we add/subtract big amounts - so learning fast. But that has its own problems - we cannot learn consistently and can get completely lost, so it is usually a small number ~ 0.001.
I would suggest reading Michael Nielsen's eBook as a nice intuitive introduction - is a great place to start.
We generally speak about gradient descent (more help) as a way to train the model - to help it learn. It is called gradient descent  because we imagine the errors/cost of the model are like a hill that we want to descend i.e. we want to get to the bottom of it:
In this example above, steps 1 and 2 sound like reinforcement learning.... iteratively learning how to complete a task, exploring possibilities. Steps 3 and 4 are most like image classification... classifying and labelling images (types of cookies).
Comparing the main steps of learning - first the human brain view, then the machine learning equivalent as the second point:
It doesn't detail the magic part... and I guess that is what you are interested in. Well, one main inspiration for that magic within machine learning (and artificial intelligence) is humans - and how we learn. We generally follow the phrase "learning by doing".  Let's use a stupid human example to begin with: