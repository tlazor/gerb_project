once you have it in place you can have few virtual machines - members of a test group - where you test new versions before making them available to all the users.
As for testing, I ususally push the update to my own machine and a small test lab first. Poke around for a few minutes, then push it to a select group within the IT department that know that they are part of my early release schedule. Then, if there are no problems I push it to everyone.
Between each "group" of upgrades, pause for some amount of time to see if errors crop up.  Whether this is a day or a week depends on many factors: is this a big change?  were the previous group upgrades successful?  Monitor your Helpdesk tickets for reports of problems related to the upgrade.  If you have full-time helpdesk attendants, keep them apprised of what upgrades are in progress so they are on the lookout for problems.
Microsoft's SCCM and various other product will do this.  However, they let you do the specific task: Install the software.  The big question is how do you coordinate this?
The most important thing is to take good notes.  If you had to do a good upgrade once, you'll have to do more upgrades in the future.  You want the process to become repeatable and keeping a list of tests performed is key for that.  The next time you do a similar upgrade there will be less thinking you have to do, which means fewer mistakes ("oops, I forgot to test blah-blah-blah") and it will go faster.  In fact, if you just keep basic documentation then you can delegate this to that new, junior, sysadmin you've hired.  He or she can repeat your process, add to it, and improve it.  You can focus on training them and checking their work.  Meanwhile you can work on other projects.
In "The Practice of System and Network Administration" there is a chapter that recommends the following methodologies:
After each "group" of upgrades, do a series of tests.  If any tests fail, or if problems are reported, stop doing upgrades.  Revert back to the previous release if possible (or safe).
sites like itninja [former appdeploy] or wpkg.org can be source of unattended installation recipes for different software.
There are tools to assist in this like Microsoft's SCCM, Active Directory Software Deployment, Altaris, LanDesk, etc. There are a million and one ways to push out updates, but business that follow best business practice and don't make their users admins use at least one of these.
I am working on creating a corporate network that will obviously have multiple servers and multiple workstations.
if you're looking for a lightweight tool for scripting system upgrades and managing different profiles - take a look at wpkg. it provides you just a framework but at the end you have to find out the upgrade/quiet install/uninstall syntax by yourself. 
The upgrades should not start until you have done your own tests.  For example, in a lab or on your own machine.  More structured tests would include trying the upgrade on one of each kind of machine, one of each release of the OS, and so on.  Tests should include starting and stopping the software, as well as running its major functions (since you mentioned Flash: try playing a video, running a flash game, and so on).  It is good to keep a wiki page that documents what combinations where tested and what tests you ran.  The next time you upgrade this package you have a good list of tests to use.  If a problem is reported during upgrades, add a test to the list to prevent that problem in the future.  Since you mentioned Flash, I recently found a problem with the Weight Watcher's food tracker app and a certain version of Flash.  We added the URL for that app to the list of tests and now we know that new Flash upgrades must be tested with that before we release it.
Whether you use "one, some, many" or other methodologies depends on many factors. "One, some, many" is good in smaller environments.  "Exponential" is good in a large desktop environment where hundreds of machines are centrally controlled.  "Risk-adveres last" is good when you can divide your users into specific groups that have different "personalities".  "Canary" is used on web farms and grid computing where you have hundreds or thousands of machines all with the same configuration.
How do you guys go about controlling, testing and then pushing the application updates out? (i am not talking about windows updates). Do you use a 3rd party sysadmin tool? Home grown software?
Let's say a new version of Adobe Flash comes out. I would think that you would want to test this update in a test environment before "pushing it out" to the servers and workstations.