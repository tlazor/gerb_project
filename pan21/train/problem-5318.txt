The file system is useful if you are looking for a particular file, as operating systems maintain a sort of index. However, the contents of a txt file won't be indexed, which is one of the main advantages of a database. Another is understanding the relational model, so that data doesn't need to be repeated over and over. Another is understanding types. If you have a txt file, you'll need to parse numbers, dates, etc.
Finally premature optimization is the root of all evil.  Choose useful tools now and figure out the rest later.
I always love coming to these forums and reading all the heavy database gurus pitching that the file System can't do it as quick as the Database. On quite the contrary a properly layed out tree, well designed hashtables and saving them as an object to a file will yield the same speeds as a database and from my tests. A properly designed hashtable and directory tree will win everytime. Way less overhead. Recently I have been moving away from database driven programming and more on the file tree for simplicity and program portability. No DB means easy backup just zip your tree up and go. It is very nice and a recomendation to program in this fashion for onetime clients with small applications. Look at the big pic do I have the time to design my own or just leverage what is already there like the db. I personally like saving my objects to file and using them later just keep an eye on your the size of your tables and look into using a RandomAccessFile in order to be able to seek quickly lay it out like a database and break it up into hashtable objects. Enjoy. Remember what ever data you store in the file will consume double the memmory usage at times depending on your code. The hash table itself and typically where you consume it to view.
Additionally you really need to figure out what you are doing.  What data are you storing?  How are you going to transform it?  If it is 100k image files your solution will look very different than if it is a directory for 100k people. (LDAP maybe?  Or an SQL database?  Depends on what you are doing, perhaps.)  The key here is to pick the tools that match what you are doing and which give you room to add more uses, rather than whatever seems fastest for some rather abstract use case.  Databases are wonderful tools, but you can't get a good answer to a question like this.
Read 10 lines out of this 1 billion line file and then search for matching lines in this other file.  I pity you if you have to do this.  A good database server however has strategies for doing this fast and well so you aren't reinventing the wheel.
It really depends on what you are doing.  In general the speed at which you can open a file for reading will be better than the speed at which you can establish a network connection.  So for very simple operations, the filesystem is definitely faster.  Filesystems will probably beat an RDBMS for raw read throughput too since there is less overhead.  In fact, if you think about it, the database can never be faster than the filesystem it sits on in terms of raw throughput. 