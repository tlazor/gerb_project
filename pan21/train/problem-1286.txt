You generally won't notice the difference between modern 2.5" 10k and 15k enterprise SAS disks on something like an HP MSA 2040 storage array... You'll run into other platform limitations before that becomes an issue. When people are concerned about that latency difference, it almost makes more sense to pursue SSDs (which are supported in the 2040 unit).
That is totally true if that is not a low end SAN. Caching - especially when some larger SSD buffer is insovled - can factually kill those differences. For example I am now regularly coping files with 600mb - 900mb / second. On a Raid 6 of 5400 RPM discs. Latencies are regularly in low single digit despite heavy random and write heavy workloads. The trick? A 20% SSD write back buffer.
Can you provide more detail on what you plan on doing with the array? I'll be able to clarify this answer.
With all storage, this comes down to your anticipated access patterns (read-biased/write-biased/mixed?), application performance requirements (database/application/virtualization?), transport (fibre/SAS/iSCSI), and array composition (RAID level, # of disks).
So, on a "proper" san with some heavy buffering you may not see that many differences. In fact, I would say you waste a ton of money.