One thing to watch out for regardless of which solution you use is handling (or ignoring) of resource fork data.  Your OSX server deals with resource forks transparently, but you may lose the resource forks if you are using applications and/or filesystems that are not aware of them and thus would discard them.  Maybe it doesn't matter in your environment, but it's worth pointing out that the data can get dropped pretty easily and without warning.
edit: You could implement a recovery front end by exporting the rsnapshot datastore over NFS or Samba (or a webserver/anything else) and let users pick up old copies of their files themselves.
Try rsnapshot (rsnapshot.org). It does exactly what you're after: it's in the RPMForge yum repos (so is packaged for CentOS), operates over rsync via SSH, and keeps a configurable number of incremental backups.
I use rsnapshot to handle approximately the same data volumes you're talking about and it works quite nicely.  As has already been pointed out it doesn't have a fancy front-end but it does a great job at snapshot retention and minimizing file storage space.
For GUI-based tools, consider looking into CrashPlan at http://www.crashplan.com.  There are several cost levels (Home, Pro, etc.), one of which may suit your needs.  I believe it's Java-based but IIRC it came with its own JRE.  I use it for home backups, and I briefly tested the Pro (server-based) version but other things distracted me from giving it a full evaluation.  But it looked promising.
Would just buying a bunch of cheapo =>1TB USB hard disks and treating them like tapes, but with the ability to rsync to/from them, do what you need?