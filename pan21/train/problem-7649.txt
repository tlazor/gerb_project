Under the assumption that $\mathsf{NC} \neq \mathsf{P}$. What is the 'hardest' natural kind of optimization problems with decision problems in $\mathsf{NC}$?
Are you aware of the work on positive LPs/SDPs? There are a bunch of results in the area, mostly along the lines of "if the constraints of the LP/SDP are positive, then the problem can be solved in NC."
When learning optimization problems, we usually consider linear programming (or more generally: convex optimization) as the simplest example. It is solvable in polynomial time, and has relatively easy to understand algorithms. However, the decision version of LP is $\mathsf{P}$-complete. This suggests that it is one of the hardest problems we can solve in polynomial time.
To a large extent, this is idle curiosity. However, it was brought about by Cosma Shalizi's "In Soviet Union, Optimization Problem Solves You". In particular, if LP is too difficult to solve to have a centralized economy (i.e. optimizing in $\mathsf{P}$ is asking too much), then any decentralized system must be doing some sort of parallel processing faster than poly-time (for me: $\mathsf{NC}$).
If this is too vague, then we can restrict to restrictions. What is the minimal set of restrictions we need to place on linear programs (or more generally: convex programs) to allow the decision problem associated with the restricted programs to be solvable in $\mathsf{NC}$?
Some important references in this line of work are Luby-Nisan 93 and Jain-Yao 11. Another excellent resource is this slide of Rahul Jain's talk at the "Recent Progress in Quantum Algorithms" conference at IQC. The entire talk is available on youtube.