Alternatively, you can get the probability distribution function for each variable and get the overlapping area between two groups. 
For example assume a simple coin flip experiment where we want to determine if a coin is fair. The baseline distribution should be uniform 50 heads, 50 tails. We will conduct a chi-squared test to see if our coin is fair. When flipping the coin we observed 30 heads and 70 tails. 
Now we can look at our trusty chi-squared table. The rows is usually for the degrees of freedom $\nu$, which is 1 in our example. And the columns is for the level of significance, for a significant result look under $p<0.05$ for a highly significant result look under $p<0.01$. We can see that our calculated $\chi^2$ result is much higher than the value for a $p<0.01$ thus we can say witth certainty that the distribution of our Group 2 is not the same as that of Group 1. They are statistically different. 
where $i$ is each bin you have for a feature, $O_i$ is the number of observations you have for the $i^{th}$ bin, $E_i$ is the expected number of observations. $E_i = Np_i$, where $N$ is your number of observations and $p_i$ is the probability of obtaining bin $i$.
This seems to me like a hypothesis testing problem where the null hypothesis can be formulated as "two data sets are drawn from the same population distribution function". If we can disprove this statement with sufficient certainty then we can assume that they were in fact drawn from different populations. 