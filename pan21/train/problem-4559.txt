When rendering triangles as in OGL you basically take discrete object data and transform them onto the screen. When you take these other more abstract graphics representations you don't have a discreet object at all. When you do ray tracing this doesn't really matter. When you do rendering like in OGL first you have to transform all of these into discrete objects (which generally look terrible compared to the "real" object). Or else use some kind of ray tracing with compute shaders or something and somehow put those results in among the results of your discreet rendering.
Graphics accelerator cards are not equipped to deal with them. Polygon-related operations like rasterization itself are taken care of quickly and automatically. The other operations require discrete points to operate on, like frustrum culling or even view projections.
These operations don't work at all with this kind of pipeline. They only work properly with a ray-tracing-like render algorithm. I say like to stave off any super pedantic people out there that might correct me and talk about other algorithms like photon-tracing that are basically the same thing.
So while you can do it, it's mostly not practical to do so in OGL at least for a gaming application. Maybe it can be used here and there for certain things like allowing users to create content, but you won't see it used for data representation as the norm any time soon.