Default Z buffer is impractical for huge distances because it wastes A LOT of prescision for what is very close to the camera. A tiny increase in zNear kills prescision for distant objects. 
Also, it is possible to render geometry closer than zNear and farther than zFar by enabling Depth Clamp but of course z buffer becomes useless outside of the frustum.
Logarithmic Z buffer solves this problem by offering a more sensible distribution of prescision. It ensures there is enough prescision at almost any distance (at least enough to render a GTA city without resorting to rendering different parts or world with different Z buffers). There is too much details about implementing logarithmic Z to discuss here but I find this article great. The best trick from the article: if you are using Direct3D you can simply swap zNear and zFar in the code and you get an almost logarithmic z buffer!
Then it comes to zFar and zNear their values does not really matter. It's the difference between them that decides the precision when comes to depth testing. You only got a few bytes to save the depth. Bad precision results in a lot of z-fighting and thats's usually bad thing. 
Combining camera outputs is used by FPS games as a solution too the lack of precision you get from needing a near clip very close to the camera (e.g. to see the gun) and the need to see very far (e.g being able to see a mountain). So what you can do is to render the stuff that need to be close and detailed first and then the more distant surrounding. Combine the  two images and there you go. 