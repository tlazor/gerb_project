In the former case, consider combining a hashmap generated from a DB, managed by either your CMS or a CRUD tool if, like Alex, most of your rules actually come from things like content moves and marketing campaigns.  They can be tested by your content people and then migrated into production with little effort for your server teams.
Obviously everyone is going to have a significantly different number of rules to manage depending on individual situations.  I would guess that dozens of rules are not uncommon.  We typically use rewrites to deal with things like content moves, technology changes.  Our marketing department is constantly coming at us with search engine optimization requests for things like expired content which we typically handle with a rewriterule.  We also end up handling things like marketing campaigns that get printed specifying a URL that doesn't exist, so we make it valid by adding a rewriterule.
If the problems is performance, well, that's a "how long is a piece of string" question, but I've certainly worked on sites with literally hundreds of rewrite rules to support things like content migrations where there's been no measurable impact on the response times for the servers.
For a comparison, at my organization, we have 140 rewriterules spanning 19 subdomains in our production environment. 