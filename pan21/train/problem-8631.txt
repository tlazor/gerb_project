The loss for the train as well as test  seem to decreasing simultaneously. The test curve flattens a bit earlier. It could be treated if the learning rate is decreased.
In case of overfitting, the validation accuracy stops increasing and the validation loss also does not decrease.
It means that the model can no more generalise itself to get a validation accuracy above a certain threshold.
The model should stop its training when the accuracy and loss seem to be constant or they only revolve around a certain value.
I am trying to train a LSTM network, over a total of 200 epochs, with hidden layer size of 100 and 1 dense layer after the LSTM layer. I have used a batch size of 10 for the same. Basically, I am confused as to why the loss curve which I get (with MAE as loss criteria and Adam Optimiser) is looking very different from what a good model generally gives. I believe that the likely reason may be that the training is occurring over more number of epochs than should be ideal, and it is underfitting/overfitting, but I am not sure that how to recognise the same.
I would like to be sure of whether the model is overfitting or undercutting, and if I need to reduce the training epochs (say from 200 to 20?).Being new to this, is there any specific point to identify when to stop the training process (such as based on this loss curve). Any help in this regard is appreciated. 