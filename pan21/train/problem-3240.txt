It's important to understand the difference between the spacial coordinates being passed in for the vertex, and the texture coordinates being passed in as the second argument.
I'm using SharpDX Toolkit and load a png file with SharpDX.Toolkit.Graphics.Texture.Load(GraphicsDevice, Stream)
The spacial coordiantes work as expected, like any plot you've ever seen.  However, for textures, the most common scheme is to put (0,0) in the upper left corner, and (1,1) or (Xres,Yres) in the lower right corner.
Try drawing a plot of where you have applied which coordinate, and you'll see that you put (0,1) and (1,1) at the top of the quad, and not the bottom.
Turn your quad upside down (by changing the order of vertices in the vertex buffer declaration), or change your camera position.
I think you are probably misunderstanding the coordinate system in which you are working. Higher numbers for X and Y are not necessarily up and right on the screen. So you're most likely seeing an upside down quad, or your camera is behind the thing you're looking at and you're seeing its back (a double-sided quad will show the mirror image of your texture if you look at it from the back).