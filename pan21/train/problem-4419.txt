Now, if the host only has 4 threads, then you'd be silly to allocate all of them. If it has two processors and 4 threads per processor, then you might not want to allocate all of the contents of a single processor, as your hypervisor should try to keep vCPUs on the same NUMA node to make memory access faster, and you're making this job more difficult by allocating a whole socket to a single VM (See page 12 of that PDF above).
Our IT created a VM with 2 CPUs allocated rather than the 4 I requested.  Their reason is that the VM performs better with 2 CPUs rather than 4 (according to them).  The rationale is that the VM hypervisor (VMWare in this case) waits for all the CPUs to be available before engaging any of them. Thus, it takes longer to wait for 4 rather than 2 CPUs.
I've reduced the vCPUs on a number of our VMs and have seen an improve on throughput on the majority.  A handful got worse and needed to be bumped up on vCPU count.
Yes, the statement makes sense in general.  However, it's something you should test for your exact configuration and workload though.  Sometimes more CPUs is better if you can actually take advantage of them.  However, if you don't actually have that much parallelism, a VM configured with less CPUs will often perform slightly better as it avoids slowdowns due to CPU Ready State pauses.
All that said and done, I very rarely allocate more than 3 vCPUs per guest. Everyone gets 2 by default, 3 if it's a heavy workload, and 4 for things like SQL Servers or really heavy batch processing VMs, or a terminal server with a lot of users.
So there are scenarios where fewer vCPUs can perform better than more, but it's not true  100% of the time. 