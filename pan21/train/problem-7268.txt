I started reviewing this last night, and got way off track from what you need. You've been clear that this is hobbyist code that already works; the only reason you're hear asking how to improve it is (I guess) so it'll be easier for you to resume work on a year from now.
The log file looks like it is made up of bunch of sections separated by blank lines.  So, an approach is to code functions to parse each section. The main driver can scan the log file to find the sections and then pass the parsing off to the parsing functions.  The parsing functions have a common interface, to make it easy to add new parsing functions.
This is the driver.  It iterates over the lines in the log file, trying to identify what kind of section it's reading.  For example, if a line starts with '.step' it is in the 'step' section, etc.
But I also kept much of my code, which follows along very much the data as it is presented in the log file. For me, everything I take from the log file is a kind of "observation", so storing them as a list of dictionaries makes perfect sense to me and using pandas to transform all those observation in a usable shape also seems straightforward to me.
The contributed answers each had some valuable contributions, but they did not really achieve the clarity (as perceived by me) I was hoping for. I guess this was mainly due to the fact that the answers were focused very much on how to express code elegantly, but in contrast my thinking is focused on the data.
So in summary, I implemented the advice above and cleaned up my existing code a bit to make it more uniform: