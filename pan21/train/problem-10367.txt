Also, you don't remove the leading whitespace from the first element on each line - remember that python """ quotes will leave indentation spaces in the string (even though they get removed from docstrings).
build_array uses a global variable, which I don't see any good reason for. Why not just pass the data in as a parameter?
Over and above all these, Python emphasises on readability because developer time is more expensive than CPU time today!
I've knocked together a few lines of python to read in stats for a service (haproxy), and store them in an array (to do some analysis on later). It basically takes a multiline output, and splits it into multiple subarrays. This is how I've done it - can anyone offer improvements for me?
Also, I tried executing your code and genfromtxt code and it looks like for the given data genfromtxt is slower than your code by almost an order of magnitude, but I think specifying the datatype of the columns in the data will improve the performance of genfromtxt a bit. 
Also, if you can give the nature of the analysis you are trying to perform, what columns you want specifically for this analysis, the code can be made much faster.
Very concise and more readable. Much easier to maintain since fewer lines of code and hence fewer bugs :)
It might be better just to remove leading and trailing whitespace from every string immediately after you split it, unless whitespace is ever significant in your application:
I think NumPy library exists exactly for use cases like this. It is a pretty well known, established Python library which provides numerical capabilities in Python. It has a very active community with frequent releases. In numpy I would just do this: