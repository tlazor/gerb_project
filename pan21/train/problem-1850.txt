Third, you are creating one-row dataframes to append values, and then resetting the index of your dataframe. You can just store to a new index!  df[new_name] = new_info
You wrote a lot of code to handle the management of names in your dataframe. But you overlooked the fact that Python has data structures other than dataframes that are easier to work with.
But you're really either updating an existing record, or accumulating new records. Why not capture all the new records into a python data structure and do one single dataframe update at the end? 
First of all, you claim that names only appear once in any given quarter's data, if they appear at all. So your logic is about checking to see if a name appears in the dataframe because of some previous quarter.
It's better if you have only one source of truth for things like this. In this case, let's use the filenames as the source of truth. Then we can use glob to match them:
Python has raw strings which make it much easier to use backslashes. The documentation is a bit scattered, but the upshot is that a raw string looks like r'foo' and backslashes don't need to be escaped. This makes raw strings the format of choice for writing Windows paths and regular expressions.
First, you are storing Nan and 'Y' values in your columns: floating point and string data? The Nan means false and the 'Y' means true. But there's already a True/False data type, and it is neither floating point nor string. Why not make your table a table of boolean values?
Pandas is great at dealing with tables of data of known, basic types. It supports indexing, lookup, boolean, and database type operations. Try to see how you could use that.
This is a good use for Python's set data type. You can test for containment and compute intersections and differences quite easily.
What's the difference? The difference is that after the with version, the infile is closed. Why does it matter? Two reasons: First, with handles success, failure, exceptions, and always makes sure to close the file. Second, file handles are a surprisingly limited resource, especially if you're debugging code in a REPL. Using with is a good way to never run out.
That is called a set comprehension, and it works similar to a list comprehension. (And yes, it rocks!) Sets are O(1) for lookup, so you can just use the in operator.
There's an example right in the Python documentation for Reading and Writing Files that shows how to use with for file I/O. It's built-in RAII support, if that means anything to you, and it's absolutely the correct way to do file I/O in most cases. Certainly in this one. Plus if you don't use it, every suggestion you get from anyone that (1) reads your code; and (2) knows how to code in Python is going to include "use with for file I/O!". So let's make this quick change:
It seems easy to write something like filenames = [ 'Q1.txt', 'Q2.txt' , 'Q3.txt' , 'Q4.txt'] and it is, until your boss says, "Hey, could you add the last two calendar years to that report?" and you're suddenly stuck trying to move files around and change your code and change the field names in your dataframe and change your HTML and change your spreadsheets and ...
But the fact is that Python file operations will honor windows paths spelled using forward slashes (/) instead of backslashes (\). So you could just as easily define that like this:
An even better question might be to ask if you need to use the dataframe for this at all? You are building what amounts to a boolean table. You could store the boolean values in a data structure built from collections.defaultdict and only convert it into a dataframe for the purpose of generating the HTML at the end.
Second, you are treating your names as a column. But they are really the index! So why not make them the index? If you do so, you can use name in df and not have to maintain a separate Python set object.
Writing code like this lets you make one change - renaming Q[1-4].txt to 2019Q[1-4].txt - and you still get the list of paths you need. 
Finally, the df.to_html() function takes a large number of parameters. Including formatting parameters that you can use to translate boolean values into 'X' or 'Y'. 
Probably the most important thing you could do, however, is to start using pathlib. Don't bother with os.path for this, go directly to the good stuff! The pathlib module is part of the standard library, and does many things that "just work." Including, of course, overloading the operator / to do concatenation:
Use the features of pandas as they were intended, and your code will get simpler, shorter, and faster.