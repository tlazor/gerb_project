The problem you seem to be having is that most such models output a one-hot vector, i.e., categorical distribution, corresponding to a single label: $p=(p_1,\ldots,p_n)$, where $\sum_i p_i = 1$ and $p_i$ is the probability of assigning label $i$ (and only label $i$) to the input. Usually this is computed via $p = \text{SoftMax}(f_\theta(x))$ for some input image $x$ and neural network $f_\theta$.
I want to make a new dataset containg thousands of (different-sized) images. Now I need to assign multiple labels to each image.
Do you know a simple way of assigning multiple labels to images and saving them in a dedicated file?
To change this to handle multiple labels, let $q=(q_1,\ldots,q_m)$, where $q_i\in[0,1]$ is the probability of assigning label $i$ to the input. You can think of each $q_\ell$ as parameterizing a Bernoulli distribution over a single label. You can compute $q$ via, for instance, $q = \sigma_E(f_\theta(x))$, where $\sigma_E$ is the elementwise sigmoid function. You can then assign labels to $x$ by, for example, thresholding each $q_j$, i.e., assign label $k$ to $x$ if $x_k \geq T$, where $T$ is a hyper-parameter that can be, say, 0.5.
Of course I already looked at github etc. and there are good labelling programs there. The problem is it seems like you can always only assign one label to an image.
In other words, take the classifiers on Github and replace the softmax with an elementwise sigmoid, change $n$ to $m$, and use your training data; that's it. 
Your question is relatively devoid of details, so all I can really suggest is to use a standard convolutional network classifier.