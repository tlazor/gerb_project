Is this a new frontier in Computer Science for computer languages - or are we just going back to LISP?
Now throw in types into the mix. The size of a list would be its length. Now what's the size of a list of lists of atoms? If you consider this data structure as a list (whose elements happen to be lists of atoms), the answer is the length of the list. If you consider this data structure as containing atoms that happen to be stored in a list of lists, the answer is the sum of the lengths of the element lists.
I'm not familiar with Barry Jay's recent work, but his older work includes things that you cannot do in Lisp, because the types give additional information.
For example, suppose you want to define the size of a Lisp data structure. It's 1 for an atom, and n for a list of n atoms, and more generally size(x)+size(y) for (cons x y).
Types allow you to distinguish between these two views (shapes) of the raw data. You need a type system that lets you discriminate between (List) (List Atom) and (List List) (Atom). The most common implementation of this distinction is with type classes (as in Haskell).
Barry Jay in his book makes some bold claims - basically by saying that, at the core of a program, everything is either atomic or composed. Then things can be easily iterated, filtered, updated, just by 
One of the main benefits of Jay's recent work is that it reduces the boilerplate code one needs to write in order to traverse data structures to perform operations such as map. The pattern calculus enables one to write the traversal code once for all data structures and have it applicable to your own data structure. This certainly reduces the amount of code required, but does not enable you to write any programs that you couldn't otherwise write. Certainly there are many interesting ideas in the work, but it remains to be demonstrated that it actually works. 