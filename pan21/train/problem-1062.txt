Even if enrollment is closed it may still be worth your time to e-mail the professor and let him know how eager you are to learn. This would most likely not be a class about the systems of AI but more about how to create AI that is lifelike and convincing.
Most side-scrollers are deterministic as to when enemies come on screen, their on-screen path and the bullets they produce. Players tend to learn how to play a level through muscle memory, which is strengthened by repetition, but at an immediate level they're reacting to what's on-screen now.
A simple steering-behaviour system could keep the AI away from bullets, maybe peeking at the type of bullet to figure out its future positions for predictive avoidance. For lots of bullets on small systems this may become expensive.
Of course we could just record human input and replay it (with several different recordings for different play-styles), but that's extremely sensitive to level design changes. 
With this data, you could replace the steering behaviours with a kind of 4-dimensional flood-fill that tried to find the largest safest place on the screen, with each step looking at the future frames to work out a safe path. 
I picked up a copy of Game Coding Complete and was able to implement the various systems that are key in having working AI. It did a great job of explaining that the AI used to control computer players is simply an extension of the class used to control your own player. It also showed how to implement an event handler.
No, it won't detail an award winning AI language but it shows you what you need to create one. As far as libraries, I am not sure about them but again if you are just learning, try and shy away from libraries controlling things you are really interested in. For example, I love graphics rendering so I used no libraries at all when learning. Sound control is not something I am too interested in so I ended up going with a third party library.
If we could get our AI to repeatedly play each level, recording some kind of data as it goes, it could pipe this data into the steering behaviours to avoid dead-ends. Each play-through improves the data and lets our AI make better decisions. But what form does this data take?
I haven't done anything like this before, but it's an interesting intellectual exercise so here's my first thoughts. For simplicity I've talked about only avoiding bullets, not shooting at enemies.
However with this approach the AI could very quickly get stuck in a dead end, with no chance of escape. So we need something above the on-screen reactions, something to replicate the muscle-memory humans use.
The personalities come from the real-time processing of the threat movie. With steering behaviours, you could have scardy-cat AI that prefer large distances to any threat, or bravado AI that look for pickups despite the danger. Slow AI, that flood-fill the threat movie assuming a lower top speed, which may find different routes to a faster AI, etc.
Let's assume you have to write something yourself. I don't know of any middleware targeted towards 2D side-scrollers but someone may correct me.
One immediate idea is a heat or threat map covering the whole screen, for every frame of the level. Sort of a threat movie. You could imagine it as a movie of the level, with each pixel coloured as to its danger to the AI. Spaces completely enveloped by bullets would be coloured in as very dangerous. Then you could do some post-processing to bleed danger back though time, so the AI could see the problem coming before the area is enveloped. 
I assume these are AI bots that would be utilizing a game/engine you wrote. If not, then you would need to consult specific material related to the engine you use. 
If it sounds like a lot of work, that's because it probably is, but it also sounds like a lot of fun. :)
Finally, Stanford is hosting an online AI class. I am not sure if you can still enroll but if you can it would definitely be worth your time. http://www.ai-class.com/
If a pixel for every frame for every level sounds data-intensive, you could make the pixels quite blocky - I imagine you don't need resolution below the size of the hitbox of the AI's avatar, and could probably get away with blocks a bit bigger than that. You could also record only two or three frames a second to further reduce data size.