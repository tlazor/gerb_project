I suspect that here, like in most algorithms work, the cost of reading and writing $O(\log n)$ bit numbers is assumed to be a constant. It's a minor sin, as long as you don't get carried away and collapse P and PSPACE by accident. 
For instance, hash tables (storing any kind of values) are not O(1) time to access if the hash function must read the whole value to compute its hash.  n unique elements require log n bits each on average to represent, no matter how clever your representation, and any hash function that reads its whole input will therefore take at least as much time to compute. In practice they are faster than red-black trees, but asymptotically they are no better.
In each iteration i, a random integer is chosen between 1 and i. Simply writing the integer in memory is O(log i), and since there are n iterations, the total is
The brouhaha referenced by randomwalker was about a POPL 2008 paper ( http://portal.acm.org/citation.cfm?doid=1328438.1328460), discussed here: http://blog.computationalcomplexity.org/2009/05/shaving-logs-with-unit-cost.html
This question is in regard to the Fisher-Yates algorithm for returning a random shuffle of a given array. The Wikipedia page says that its complexity is O(n), but I think that it is O(n log n).
In TCS, we consider -- if not stated otherwise explicitly -- complexity on a Turing Machine. While this is fine for theoretical purposes, results are not very helpful in practice since we do implement different machine models (that is, finite approximations) in hardware. It is therefore a feasible question to ask for complexity on those models. For example, we typically assume that register machines (similar to real CPUs) can perform atomic operations on two registers in constant time -- this is what might have been employed here.
In that post Lance Fortnow describes how as a student he complained that sorting really requires n log^2 n time if we must read all log n bits of two elements in order to compare them, which seems a reasonable objection.
Note: The naive algorithm is to assign each element a random number in the interval (0,1) , then sort the array with regard to the assigned numbers.