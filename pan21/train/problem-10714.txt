Approach 2: If the above does not work well, then firth's bias reduced logistic regression approach with penalized profile likelihood based confidence intervals for parameter estimates will suit your case. You can try L1 (Lasso) regularization on logistic regression from Python scikit library. Alternatively you can try R's 'logistf' package example.
There is a python module to perform under and over sampling with various techniques here. This package includes SMOTE implementation as well. Using this package try to balance event data in your sample before running RandomForest or any other classification algorithms.
if you have very severe data imbalance + very few number of samples + wide variation within the majority class and similarities between different classes. regular oversampling or down sampling techniques will not help you as well as most of the synthetic oversampling techniques designed specifically to deal with the data imbalance but the assumption is to have enough number of samples.