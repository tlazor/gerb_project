You're missing a case for n < 0.  Either return 1.0 / power(x, -n); or delegate to Math.pow() in that case.
Using the power algorithm that reduces the steps by half each time, actually doubles the amount of work that it must do.  Raising the same 10 bit number to the 8th power will yield: 10 shifts and adds to get X*X.  But now X is a 20 bit number needing to be raised to the 4th power.  Next time through takes 20 shifts and adds, with X resulting in a 40 bit number that needs to be squared.  The last pass takes 40 shifts and adds and X is the result.  Adding the passes up, 10 + 20 + 40, is 70 shifts and adds.  
When you multiply two 10 bit numbers, the algorithm used is a shift and add which must cycle across all 10 bits.  If I were to raise a 10 bit number to the 8th power, it would take 70 shifts and adds using a short loop which multiplies the result by the number 7 times.
These answers are correct if your result stays within the precision limit of the processor.  The fallacy is assuming that a multiplication is O(1).  It is not when your precision needs to exceed the built in precision.