My personal liking is always to leave about 300MB of RAM when I'm intensively multi-tasking. That will allow me to open up a few webpages for quick reference and not slow down the system.
Be careful how you measure. In my experience, simply running free -t will almost always show that all the Mem is used, and all the Swap is not used. That doesn't really give the whole picture. 
Flipped around, and actually answering your question, don't let the buffers/cache get too small... actual numbers will vary on your system and with your load. Two samples on nearby machines show this cache between 700 MB and 1 GB, and 40-50% of total ram. 
Pay attention to the "-/+ buffers/cache" line, which shows where the kernel is using memory for various stuff. This will show some of the "flex" available on the system. Don't plan on using all that cache space, though, as going to disk rather than that cache will also hurt performance. 
EDIT oh just remembered you were actually asking about a server... well in that case how much RAM you should leave free depends on the type of jobs you are submitting. If you have full control over memory usage, i'd recommend you just submit as much jobs as the RAM will hold (since you are in total control anyway, no sense in leaving RAM unused eh?)
Most hard-core techs I've seen prefer size values, simply because it's far more accurate. A 90% usage in a 1GB system means you only got 100MB left - time to watch out for disk thrashing! A 90% usage in a 8GB system means you still got a good 800MB left.
It really depends on your preference between percentage and size values for memory usage measurements.
You can probably effectively increase the memory in the box until the OS can't use all the memory for buffers/cache and see continued performance improvement.
Based on the index you chose, what's the threshold for it when you consider better wait and not to submit more jobs? Compared to CPU usage, somebody says it is 70% used and somebody says it is 100%.
When trying to evaluate the usage of memory and get the free memory size, which one is considered more proper, percentage or size value? Compared to CPU usage, I know people use load average divided by number of cores instead of load average alone.
In theory, memory should be 100% saturated, that means that all instructions and data are buffered in RAM (the fastest path), and not sitting on the hard disk.