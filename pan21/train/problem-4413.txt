For the quick solution, I would bounce the Cassandra process on both 10.0.10.8 and 10.0.9.8.  As it comes back, tail the system.log file and make sure that it properly connects with all other nodes.
If it still doesn't come back, wipe the node's data and re-bootstrap it.  Note, that when you do get your cluster back to full "UN," that you should run a repair on the node that was seen as "DN."
Yes!  The nodes which see 10.0.10.8 as "DN" will not replicate data to it.  And assuming that it has been this way longer than 3 hours, they will have stopped logging hints for it as well.
And I would upgrade this immediately.  If you're stuck on the 2.1 version, you should at least be on the latest patch release (for bug fixes) of 2.1.18.  But there's been a lot of fixes an improvements since 2.1.1, which could be contributing to this issue.
The gossip protocol is responsible for keeping nodes informed of the states of all the other nodes.  I have seen it in the past where one node (for whatever reason) sees a node as "DN" while others do not.  Typically this happens in cloud environments, and is usually caused by network events or inconsistencies.
If that doesn't do it, try setting your phi_convict (cassandra.yaml) to 10 or 12 if you're in the cloud (on all nodes).  That will give your nodes a little more tolerance to being marked as "DN" due to network latency.
Another thing to look at, is to double-check your cloud availability zone for the problem node(s).  It's possible that nodes in one cloud AZ might behave differently network-wise.  So if you find that these issues are a particular to an AZ, you may want to contact your cloud provider about that.
The D in the start of the line indicates the node being down. How can it be that 10.0.9.8 is seeing the node as down while the other nodes are seeing it just fine? Does this lead to inconsistencies?