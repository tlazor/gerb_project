Thus the only time that I usually get to do validate a filesystem is when the system crashes and it basically is an automatic process.
The linux world suffers far too much from macho attitudes to time between reboots. Most systems can and should be rebooted far more often than is absolutely necessary. Reboots aren't a bad thing. Reboots that you don't know will succeed... that's an entirely different story. Responsible administrators will schedule a trial reboot after various kinds of upgrade. This isn't failure, it's professionalism. So yes - you should schedule reboots.
I have never seen filesystem integrity problems if you don't have a storage problem or underlying disk problem. That doesn't mean that fs is immune to panic or problem, but core fs panics/problems, are much lesser than other subsystems. Eric Sandeen recently wrote a blog post about the no of patches committed in various subsystems over a merge window or a year but the link is not opening now. I will post it when it is online.
Most of the companies that I have worked for see Linux/UNIX systems as an "always up" resource.  Thus they are hesitant to allow any reboot that might in any way cause any UNavailability for the user community.  
Interestingly, most companies I see out there pursue basically immediate Windows patching, yet  do not see the need on the Linux/UNIX side.  Their concern is that the upgrades and patching breaks things too much that the user community relies on.  Yet, in many cases, Windows patches cause significant problems. Thus a problem in perception here between the two OSen.
I have tried, generally w/o success, to get a known one day a month where Linux maintenance could be performed.  Users/management still bulk even if this is downgraded to once every three months.
Filesystem, by nature, is quite stable. And in distros like rhel/centos, the e4fs-progs package which comes, have been valiantly tested by lots of other users when they were in vanilla kernel. Therefore, it comes with implied stability. 