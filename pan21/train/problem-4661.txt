Another non-parametric way to do anomaly detection would be to use a specialized K-NN method which makes use of the $p$-statistic test in a very clever way. I have found a lot of success on very limited datasets using their methods. The paper you should start with is: 
https://papers.nips.cc/paper/3723-anomaly-detection-with-score-functions-based-on-nearest-neighbor-graphs.pdf
Ok, this is a very exciting problem. Quite different than the ones we usually see on this site. And, even more exciting is that I think that one of the oldest methods in the book is what you are truly looking for. 
This is often called anomaly detection. You are trying to detect when a behavior from a specific user is anomalous (different) than their normal. So how is this done?
Now, if you see that a user logs on at a time $X$, you can use the probability density function to get the probability of the event having been drawn from that distribution. In other words, what is the likelihood that the user would be online at a time $X$. If this likelihood is below a threshold $\alpha$ then you are safe to assume that it is anomalous. This is more commonly known as the generalized likelihood ratio test (GLRT).
To get the baseline distribution in your case it is very easy which makes it quite exciting! All you need to do is collect information about the user during a burn-in period. Here you need to make a choice. Do you want to track the users activity daily, or throughout the week, the month? etc... If we are talking about activity in a server that is used for work, weekly would likely be better. However, if it's a gaming server then maybe daily is better. You need to think about the regularity of the users schedule in regards to the kind of server you are hosting. Let's assume you are interested in their daily activity. Then you can have a burn-in period of a few weeks.
So from what I gather, you have the time that a user is active per day as your data and you want to determine times when they log on that deviates away from their usual activity. 
And then you can go onto their simplest implementation, which you can then expand on by reading their other papers (bagging, ranking, etc...)
The disadvantage of this technique is that you need to train the hyper-parameter $\alpha$, your threshold. Which is easy to do given you have labeled data. You know what behavior is normal/anomalous. If you don't have this information. You can just set an arbitrary threshold and fix it as you see fit based on the resulting false positive or false negative rates you will encounter. 
I am suggesting this because you can easily get the parametrization of your probability distribution. So if you do not use it you are missing out on a lot of information. 
Anomaly detection algorithms are capable of learning the distribution a single set of labels (normal activity) and then it will be able to flag when an anomaly occurs (anomalous activity). This is when an instance is sufficiently different than the learned distribution. 
So set up a probability graph which will be your probability distribution function. The $x$-axis is going to be the hours of the day, and the $y$-axis will be the frequency (you will need this to be normalized afterwards for the math to work out). So, each time the user logs on, you will add onto the plot a box unit 1 ($y$-axis) for that time slot. This is essentially a histogram!! At the end you will end up with a curve that shows the likelihood of the user being active for any given hour of the day.     