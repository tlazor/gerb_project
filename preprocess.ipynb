{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 18:35:13.477213: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-04 18:35:13.521109: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 18:35:14.185143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(random_seed)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(random_seed)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(random_seed)\n",
    " \n",
    "# Set a random seed for PyTorch (for GPU as well)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pan21_functions import *\n",
    "import datetime\n",
    "from keras.callbacks import CSVLogger\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pan21PyDataset(\"pan21/train\", \"pan21/train\", \"train_ds_uncompressed\").to_file()\n",
    "# Pan21PyDataset(\"pan21/validation\", \"pan21/validation\", \"val_ds_uncompressed\").to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the files are good\n",
    "def test_load(path, name):\n",
    "    np.load(path)[name]\n",
    "\n",
    "# _ = Parallel(n_jobs=-1)(delayed(test_load)(Path(\"train_ds\") / f\"{i}.npz\", \"batch_x\") for i in tqdm(range(350)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pan21FourierDataset(\"pan21/train\", \"pan21/train\", \"train_ds_uncompressed\", num_fourier_features=512).to_file()\n",
    "# Pan21FourierDataset(\"pan21/validation\", \"pan21/validation\", \"val_ds_uncompressed\", num_fourier_features=512).to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = Parallel(n_jobs=-1)(delayed(test_load)(Path(\"train_ds\") / \"fourier\" / f\"{i}.npz\", \"fourier_batch_x\") for i in tqdm(range(350)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start_idx = 0\n",
    "# limit = 5\n",
    "# # limit = len(train_ds)\n",
    "\n",
    "# before = time.time()\n",
    "# for i in range(start_idx, start_idx+limit):\n",
    "#     batch_x, batch_y = train_ds.__getitem__(i, force_compute=True)\n",
    "# after = time.time()\n",
    "# for i in range(start_idx, start_idx+limit):\n",
    "#     batch_x, batch_y = train_ds.__getitem__(i, force_compute=False)\n",
    "# after_after = time.time()\n",
    "\n",
    "# print(f\"Compute: {round((after - before)/limit, 2)}s vs File read: {round((after_after - after)/limit, 2)}s\")\n",
    "# # Compute: 8.95s per batch\n",
    "# # Compute with compression: ~17s\n",
    "# # Uncompressed read: .7s per batch\n",
    "# # Compressed read: 1.6s per batch\n",
    "# # Compressed is 1/10 the size of uncompressed, but takes ~twice as long to precompute and save\n",
    "# # Compressed 512D Fourier takes ~30s per batch\n",
    "# # Compressed 512D Fourier is about 500-700MB per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Input, Flatten\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "\n",
    "# Code implementation of the RNN for sequence labeling\n",
    "def create_rnn_model(num_labels, embedding_dim, max_input_length):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(max_input_length*2, embedding_dim)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_labels, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.RMSprop(),  # Optimizer\n",
    "        # Loss function to minimize\n",
    "        loss=losses.BinaryCrossentropy(),\n",
    "        # List of metrics to monitor\n",
    "        metrics=[metrics.BinaryAccuracy(), metrics.AUC()],\n",
    "        jit_compile=True\n",
    "    )\n",
    "\n",
    "    return model\n",
    " \n",
    "num_labels = 1\n",
    "embedding_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_num_ff(train_ds, val_ds, model_name, epochs=5):\n",
    "    max_input_length = train_ds.max_input_length\n",
    "    # print(f\"{max_input_length=}\")\n",
    "\n",
    "    print(model_name)\n",
    "    model = create_rnn_model(num_labels, embedding_dim, max_input_length)\n",
    "    csv_logger = CSVLogger(f'{model_name}.log', separator=',', append=False)\n",
    "\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_ds,\n",
    "            verbose=1,\n",
    "            callbacks=[csv_logger]\n",
    "        )\n",
    "\n",
    "    model.save(f\"{model_name}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does using the frequency domain spectra provide usefule information?\n",
    "model_dir = Path(f\"models/num_fourier_features\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "num_fourier_features = [0, 512//4, 512//2, 512]\n",
    "for num_ff in tqdm(num_fourier_features):\n",
    "    free_memory()\n",
    "\n",
    "    fourier_train_ds = Pan21FourierDataset(\"pan21/train\", \"pan21/train\", \"train_ds_uncompressed\", num_fourier_features=num_ff)\n",
    "    fourier_val_ds = Pan21FourierDataset(\"pan21/validation\", \"pan21/validation\", \"val_ds_uncompressed\", num_fourier_features=num_ff)\n",
    "\n",
    "    model_name = model_dir / f\"{num_ff}_{datetime.datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')}\"\n",
    "\n",
    "    train_model_num_ff(fourier_train_ds, fourier_val_ds, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many epochs should be trained?\n",
    "model_dir = Path(f\"models/num_epochs\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "num_fourier_features = [0, 512//4]\n",
    "for num_ff in tqdm(num_fourier_features):\n",
    "    train_model_num_ff(num_ff, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1996dcc2e71d4cf487ceffb63f2bfa5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/cutoffs/1_64_2024_06_04-06_36_43_PM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 18:36:43.231621: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.234811: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.236240: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.239907: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.241513: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.242894: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.244277: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.245683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.247084: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 18:36:43.248458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18229 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 18:37:11.360466: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 2 of 8\n",
      "2024-06-04 18:37:21.510301: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 3 of 8\n",
      "2024-06-04 18:37:45.400298: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-06-04 18:37:58.897153: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717526279.070201  988027 service.cc:145] XLA service 0x7fea1c003e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1717526279.070239  988027 service.cc:153]   StreamExecutor device (0): NVIDIA A10, Compute Capability 8.6\n",
      "2024-06-04 18:37:59.106894: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-04 18:37:59.249166: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717526280.286221  988577 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:19:07\u001b[0m 65s/step - auc: 0.5667 - binary_accuracy: 0.5514 - loss: 1.4266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526281.461939  988027 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1717526288.782944  988704 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51:31\u001b[0m 9s/step - auc: 0.5677 - binary_accuracy: 0.5500 - loss: 8.6166   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526294.623585  988814 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  3/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41:57\u001b[0m 7s/step - auc: 0.5666 - binary_accuracy: 0.5425 - loss: 9.3758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526302.157187  988939 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  4/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42:34\u001b[0m 7s/step - auc: 0.5617 - binary_accuracy: 0.5397 - loss: 9.1171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526310.590384  989025 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:32\u001b[0m 8s/step - auc: 0.5571 - binary_accuracy: 0.5354 - loss: 8.8079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526319.387845  989147 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 12 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1717526319.693567  989154 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  6/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:11\u001b[0m 8s/step - auc: 0.5527 - binary_accuracy: 0.5325 - loss: 8.4487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526325.792860  989263 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:34\u001b[0m 8s/step - auc: 0.5483 - binary_accuracy: 0.5276 - loss: 8.0866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526335.182611  989365 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  8/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:40\u001b[0m 8s/step - auc: 0.5465 - binary_accuracy: 0.5260 - loss: 7.7525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526346.098141  989539 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  9/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:56\u001b[0m 8s/step - auc: 0.5452 - binary_accuracy: 0.5254 - loss: 7.4268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526351.960639  989631 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 10/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:12\u001b[0m 8s/step - auc: 0.5438 - binary_accuracy: 0.5243 - loss: 7.1252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526358.557385  989735 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 11/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:19\u001b[0m 8s/step - auc: 0.5420 - binary_accuracy: 0.5229 - loss: 6.8510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526368.477281  989857 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 12/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:17\u001b[0m 8s/step - auc: 0.5405 - binary_accuracy: 0.5217 - loss: 6.5962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717526378.543890  989998 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_12', 412 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 13/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:00\u001b[0m 8s/step - auc: 0.5393 - binary_accuracy: 0.5209 - loss: 6.3646"
     ]
    }
   ],
   "source": [
    "# Does filtering help?\n",
    "model_dir = Path(f\"models/cutoffs\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "cutoff_frequencies = [[1, 64], # High pass \n",
    "                    [192, 512/2], # Low Pass\n",
    "                    [128, 192],\n",
    "                    [64, 128],\n",
    "                    ]\n",
    "for cutoff in tqdm(cutoff_frequencies):\n",
    "    free_memory()\n",
    "    filter_train_ds = Pan21FourierFilterDataset(\"pan21/train\", \"pan21/train\", \"train_ds_uncompressed\", cutoff)\n",
    "    filter_val_ds = Pan21FourierFilterDataset(\"pan21/validation\", \"pan21/validation\", \"val_ds_uncompressed\", cutoff)\n",
    "\n",
    "    model_name = model_dir / f\"{cutoff[0]}_{cutoff[1]}_{datetime.datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')}\"\n",
    "\n",
    "    train_model_num_ff(filter_train_ds, filter_val_ds, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
