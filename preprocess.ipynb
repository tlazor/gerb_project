{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:54:14.530553: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-05 19:54:14.591177: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 19:54:15.437045: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(random_seed)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(random_seed)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(random_seed)\n",
    " \n",
    "# Set a random seed for PyTorch (for GPU as well)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pan21_functions import *\n",
    "import datetime\n",
    "from keras.callbacks import CSVLogger\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pan21PyDataset(\"pan21/train\", \"pan21/train\", \"train_ds_uncompressed\").to_file()\n",
    "# Pan21PyDataset(\"pan21/validation\", \"pan21/validation\", \"val_ds_uncompressed\").to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the files are good\n",
    "def test_load(path, name):\n",
    "    np.load(path)[name]\n",
    "\n",
    "# _ = Parallel(n_jobs=-1)(delayed(test_load)(Path(\"train_ds\") / f\"{i}.npz\", \"batch_x\") for i in tqdm(range(350)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pan21FourierDataset(\"pan21/train\", \"pan21/train\", \"train_ds_uncompressed\", num_fourier_features=512).to_file()\n",
    "# Pan21FourierDataset(\"pan21/validation\", \"pan21/validation\", \"val_ds_uncompressed\", num_fourier_features=512).to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = Parallel(n_jobs=-1)(delayed(test_load)(Path(\"train_ds\") / \"fourier\" / f\"{i}.npz\", \"fourier_batch_x\") for i in tqdm(range(350)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start_idx = 0\n",
    "# limit = 5\n",
    "# # limit = len(train_ds)\n",
    "\n",
    "# before = time.time()\n",
    "# for i in range(start_idx, start_idx+limit):\n",
    "#     batch_x, batch_y = train_ds.__getitem__(i, force_compute=True)\n",
    "# after = time.time()\n",
    "# for i in range(start_idx, start_idx+limit):\n",
    "#     batch_x, batch_y = train_ds.__getitem__(i, force_compute=False)\n",
    "# after_after = time.time()\n",
    "\n",
    "# print(f\"Compute: {round((after - before)/limit, 2)}s vs File read: {round((after_after - after)/limit, 2)}s\")\n",
    "# # Compute: 8.95s per batch\n",
    "# # Compute with compression: ~17s\n",
    "# # Uncompressed read: .7s per batch\n",
    "# # Compressed read: 1.6s per batch\n",
    "# # Compressed is 1/10 the size of uncompressed, but takes ~twice as long to precompute and save\n",
    "# # Compressed 512D Fourier takes ~30s per batch\n",
    "# # Compressed 512D Fourier is about 500-700MB per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Input, Flatten\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "\n",
    "# Code implementation of the RNN for sequence labeling\n",
    "def create_rnn_model(num_labels, embedding_dim, max_input_length):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(max_input_length*2, embedding_dim)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_labels, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.RMSprop(),  # Optimizer\n",
    "        # Loss function to minimize\n",
    "        loss=losses.BinaryCrossentropy(),\n",
    "        # List of metrics to monitor\n",
    "        metrics=[metrics.BinaryAccuracy(), metrics.AUC()],\n",
    "        jit_compile=True\n",
    "    )\n",
    "\n",
    "    return model\n",
    " \n",
    "num_labels = 1\n",
    "embedding_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_num_ff(train_ds, val_ds, model_name, epochs=5):\n",
    "    max_input_length = train_ds.max_input_length\n",
    "    # print(f\"{max_input_length=}\")\n",
    "\n",
    "    print(model_name)\n",
    "    model_name.mkdir(exist_ok=True)\n",
    "    checkpoint_name_format = f\"{datetime.datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')}_\" + \"cp-{epoch:02d}.weights.h5\"\n",
    "    checkpoint_path = model_name / checkpoint_name_format\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path, \n",
    "        verbose=1, \n",
    "        save_weights_only=True,\n",
    "        # Save weights, every epoch.\n",
    "        save_freq='epoch')\n",
    "\n",
    "    model = create_rnn_model(num_labels, embedding_dim, max_input_length)\n",
    "    csv_logger = CSVLogger(f'{model_name}.log', separator=',', append=False)\n",
    "\n",
    "    already_trained_epochs = 0\n",
    "    if model_name.exists():\n",
    "        checkpoints = list(Path(model_name).glob('*.weights.h5'))\n",
    "        if checkpoints:\n",
    "            already_trained_epochs = len(checkpoints)\n",
    "            model.load_weights(checkpoints[-1])\n",
    "\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs - already_trained_epochs,\n",
    "            validation_data=val_ds,\n",
    "            verbose=1,\n",
    "            callbacks=[csv_logger, cp_callback]\n",
    "        )\n",
    "\n",
    "    model.save(f\"{model_name}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does using the frequency domain spectra provide usefule information?\n",
    "model_dir = Path(f\"models/num_fourier_features\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "num_fourier_features = [0, 512//4, 512//2, 512]\n",
    "for num_ff in tqdm(num_fourier_features):\n",
    "    fourier_train_ds = Pan21FourierDataset(\"pan21/train\", \"pan21/train\", \"train_ds_uncompressed\", num_fourier_features=num_ff)\n",
    "    fourier_val_ds = Pan21FourierDataset(\"pan21/validation\", \"pan21/validation\", \"val_ds_uncompressed\", num_fourier_features=num_ff)\n",
    "\n",
    "    model_name = model_dir / f\"{num_ff}_{datetime.datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')}\"\n",
    "\n",
    "    train_model_num_ff(fourier_train_ds, fourier_val_ds, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many epochs should be trained?\n",
    "model_dir = Path(f\"models/num_epochs\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "num_fourier_features = [0, 512//4]\n",
    "for num_ff in tqdm(num_fourier_features):\n",
    "    train_model_num_ff(num_ff, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c02e742299d443cadb1b1a474ba01b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/cutoffs/0.0_0.25\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'PosixPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m filter_val_ds \u001b[38;5;241m=\u001b[39m Pan21FourierFilterDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpan21/validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpan21/validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, cutoff)\n\u001b[1;32m     13\u001b[0m model_name \u001b[38;5;241m=\u001b[39m model_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcutoff[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcutoff[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain_model_num_ff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_train_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_val_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m, in \u001b[0;36mtrain_model_num_ff\u001b[0;34m(train_ds, val_ds, model_name, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[1;32m      6\u001b[0m model_name\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY_\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mI_\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM_\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS_\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcp-\u001b[39;49m\u001b[38;5;132;43;01m{epoch:02d}\u001b[39;49;00m\u001b[38;5;124;43m.weights.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m cp_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      9\u001b[0m     checkpoint_path, \n\u001b[1;32m     10\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     11\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Save weights, every epoch.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m create_rnn_model(num_labels, embedding_dim, max_input_length)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'PosixPath' and 'str'"
     ]
    }
   ],
   "source": [
    "# Does filtering help?\n",
    "model_dir = Path(f\"models/cutoffs\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "N = 4 # High pass, band stop, band stop, low pass\n",
    "# Frequencies respresented as percent of Nyquist frequency\n",
    "cutoff_frequencies = [(i / N, (i + 1) / N) for i in range(N)]\n",
    "for cutoff in tqdm(cutoff_frequencies):\n",
    "    filter_train_ds = Pan21FourierFilterDataset(\"pan21/train\", \"pan21/train\", cutoff)\n",
    "    filter_val_ds = Pan21FourierFilterDataset(\"pan21/validation\", \"pan21/validation\", cutoff)\n",
    "\n",
    "    model_name = model_dir / f\"{cutoff[0]}_{cutoff[1]}\"\n",
    "\n",
    "    train_model_num_ff(filter_train_ds, filter_val_ds, model_name, epochs = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
