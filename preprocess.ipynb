{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(\".cache\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "@memory.cache\n",
    "def get_tokenizer_model():\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-cased')\n",
    "    sbert_model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "    return bert_tokenizer, bert_model, sbert_model\n",
    "\n",
    "bert_tokenizer, bert_model, sbert_model = get_tokenizer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import itertools\n",
    "from natsort import natsorted\n",
    "\n",
    "@memory.cache\n",
    "def read_problem_files(problem_folder, n=None):\n",
    "    \"\"\"\n",
    "    reads ground truth files into dict\n",
    "    :param truth_folder: path to folder holding ground truth files\n",
    "    :return: dict of ground truth files with problem-id as key and file content as value\n",
    "    \"\"\"\n",
    "    problems = []\n",
    "    files = itertools.islice(natsorted(Path(problem_folder).glob('problem-*.txt')), n)\n",
    "    for problem_file in files:\n",
    "        # number = problem_file.name[len(\"problem-\") : -len(\".txt\")]\n",
    "        with open(problem_file, 'r', encoding=\"utf8\") as fh:\n",
    "            problems.append(fh.readlines())\n",
    "    return problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluator import read_ground_truth_files\n",
    "\n",
    "@memory.cache\n",
    "def cached_read_ground_truth(x):\n",
    "    return read_ground_truth_files(x)\n",
    "\n",
    "ground_truth = cached_read_ground_truth(\"pan21/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(paragraph):\n",
    "    # Tokenize the sentence\n",
    "    tokens = bert_tokenizer.tokenize(paragraph)\n",
    "    token_ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # Convert token IDs to tensor\n",
    "    token_tensor = torch.tensor([token_ids])\n",
    "    segment_ids = [0] * len(token_ids)\n",
    "    segment_tensor = torch.tensor([segment_ids])\n",
    "\n",
    "    # Get BERT model output\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(token_tensor, segment_tensor)\n",
    "\n",
    "    # Extract word embeddings from BERT model output\n",
    "    return outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"As stephelton said in the comments to your question, vector math is extremely important for pretty much any 2D or 3D game. However, physics knowledge isn't necessary for a lot of simple games. There are physics-like concepts you should understand a bit about, like collision, but you won't need calculus or physics classes for that as long as you keep it simple. A lot of things you may want to do can be simulated simply enough that players won't care much, like friction, or sliding, or gravity. A decent grasp of physics will likely help in many situations though.\\n\",\n",
       " 'It is probably not required to know physics in details when you\\'re doing a game, but it definitely helps, especially if there are some \\'virtual reality\\' features in your game. A game like \"From Dust\" (Eric Chahi) is essentially physics simulation gamified, while \"Another World\" only need high-precision capture of real-life motion (so and requires little to no actual understanding of what happens).\\n',\n",
       " \"It is very likely that inertia and the other bodies motion related fields will be quite helpful to produce something that is pleasant to the eye, even if you're just moving items on a chessboard. Knowing that friction exists helps using it as a game mechanic, even if you don't exactly use their academic version. Same for energy conservation. In fact, I believe we could very much use game development as a way to teach physics.\\n\",\n",
       " 'Having something that behaves close to our real world makes the rules of your game easier to learn for your player, feel more natural, and brings the player to the fun/challenging part more rapidly.\\n',\n",
       " 'The good approach is much simpler and simply require that the speed is increased at every frame by a constant (gravity acceleration) as stated in Newton Laws. Knowing physics makes you find the right solution faster.\\n',\n",
       " \"Physics isn't really necessary unless you want to have physics in your game. While a good general knowledge of physics is recommended, it's not necessary if you're using someone else's physics engine (which I would recommend). Also, calc based physics will get you farther. And, you really only need to know mechanics but the other things don't hurt. All in all though, it depends on what you're doing.\\n\",\n",
       " \"I'd be very surprised if you ever use Maxwell or Einstein theories, though. But who knows ? Ludum dare could prove me wrong.\\n\",\n",
       " \"The first time I wanted to have a character jumping in a game, I started using sin(x). The result was kinda akwards: as soon as you jumped off a cliff, you'd end up travelling up and down, as if you'd be riding a curious deltaplane.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = read_problem_files(\"pan21/train\", n=5)\n",
    "problems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@memory.cache\n",
    "# def get_max_length(n=None):\n",
    "#     max_train = max([len(x) for y in read_problem_files(\"pan21/train\", n=n) for x in y])\n",
    "#     max_val = max([len(x) for y in read_problem_files(\"pan21/validation\", n=n) for x in y])\n",
    "#     return max([max_train, max_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "max_input_length = 512\n",
    "\n",
    "def pad_paragraph(paragraph_embedding, desired_length):\n",
    "    d1, d2, d3 = paragraph_embedding.shape\n",
    "    # print(f\"{paragraph_embedding.shape=}\")\n",
    "\n",
    "    target = torch.zeros(d1, desired_length, d3)\n",
    "    # print(f\"{target.shape=}\")\n",
    "    target[:, :d2, :] = paragraph_embedding\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "def get_paragraph_pairs(problem_text):\n",
    "    # print(problem_text)\n",
    "    paragraph_embeddings = [pad_paragraph(get_embeddings(para), max_input_length) for para in problem_text]\n",
    "    # print(f\"{[paras.shape for paras in paragraph_embeddings]=}\")\n",
    "    # print(f\"{[x.shape for x in paragraph_embeddings]}\")\n",
    "    pairs = itertools.combinations(paragraph_embeddings, 2)\n",
    "    return [torch.flatten(torch.stack(pair, dim=2), start_dim=1, end_dim=2) for pair in pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# #@memory.cache\n",
    "def get_problem_embeddings(problems):\n",
    "    return [get_paragraph_pairs(problem_text) for problem_text in tqdm(problems)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad2d75ad6e6489fb3606715ddba1993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 768])\n",
      "torch.Size([1024, 768])\n",
      "torch.Size([1024, 768])\n",
      "torch.Size([1024, 768])\n",
      "torch.Size([1024, 768])\n",
      "problems_embed[0][0].shape=torch.Size([1, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "problems_embed = get_problem_embeddings(problems)\n",
    "for i in range(5):\n",
    "    print(problems_embed[i][0][0].shape)\n",
    "print(f\"{problems_embed[0][0].shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_ground_truth(ground_truth, problem_numbers):\n",
    "    simple_ground_truth = []\n",
    "    for num in problem_numbers:\n",
    "        task_3_ground_truth = ground_truth[f\"problem-{num}\"][\"paragraph-authors\"]\n",
    "        simple_ground_truth.append(task_3_ground_truth)\n",
    "    return simple_ground_truth\n",
    "\n",
    "\n",
    "simple_ground_truth = get_simple_ground_truth(ground_truth, range(1, len(problems_embed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_3_ground_truth(simple_ground_truth):\n",
    "    task_gt = []\n",
    "    for problem in simple_ground_truth:\n",
    "        problem_gt = []\n",
    "        for author1, author2 in itertools.combinations(problem, 2):\n",
    "            problem_gt.append(int(author1 != author2))\n",
    "        task_gt.append(problem_gt)\n",
    "    return task_gt\n",
    "\n",
    "task_3_ground_truth = get_task_3_ground_truth(simple_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Invert the function get_task_3_ground_truth. Our model will output a bunch of binary labels which need to be converted to the task 3 ground truth format\n",
    "# Ground truth format (gtf): [1, 2, 2, 2, 2, 3, 2, 2]\n",
    "# Binary labels for comparisons (bl): [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
    "# Each binary label is the result of comparing two paragraphs. 1 means there was an author change, 0 means there was no author change\n",
    "# For example, bl[0], is the result of comparing gtf[0]=1 and gtf[1]=2. 1 != 2, therefore bl[0] = 1. bl[1]=1 is the result of gtf[0] == gtf[2] (1 == 2)\n",
    "def get_simple_ground_truth_from_task_3(task_3_ground_truth):\n",
    "    pass\n",
    "\n",
    "simple_ground_truth == get_simple_ground_truth_from_task_3(task_3_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 2, 3, 2, 2]\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "[1, 2, 2, 2, 1, 2]\n",
      "[1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n",
      "[1, 2, 2, 3, 3, 2]\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for s, t in zip(simple_ground_truth, task_3_ground_truth):\n",
    "    print(f\"{s}\")\n",
    "    print(f\"{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code to write out the embeddings (X) and ground truths (y) so we can train without having to rerun the preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ae1127d9d64100b00b6df6ad6fca8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flatten_problems(problems_list, squeeze=False):\n",
    "    # [print(f\"{pair=}\") for problem in problems_list for pair in problem]\n",
    "    return [pair.squeeze(0) if squeeze else pair for problem in problems_list for pair in problem]\n",
    "\n",
    "\n",
    "def get_data(data_path, num_problems):\n",
    "    x = flatten_problems(get_problem_embeddings(read_problem_files(data_path, n=num_problems)), squeeze=True)\n",
    "    y = flatten_problems(get_task_3_ground_truth(get_simple_ground_truth(cached_read_ground_truth(data_path), range(1, num_problems+1))))\n",
    "    return x, y\n",
    "\n",
    "num_problems_train, num_problems_val = 500, 150\n",
    "# num_problems_train, num_problems_val = None, None\n",
    "x_train, y_train = get_data(\"pan21/train\", num_problems_train)\n",
    "x_val, y_val = get_data(\"pan21/validation\", num_problems_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training examples: len(x_train)=991 len(y_train)=991\n",
      "Num training examples: len(x_val)=279 len(y_val)=279\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num training examples: {len(x_train)=} {len(y_train)=}\")\n",
    "print(f\"Num training examples: {len(x_val)=} {len(y_val)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "# x_test, y_test = x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,769</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m49,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m32,769\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,065</span> (328.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,065\u001b[0m (328.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,065</span> (328.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,065\u001b[0m (328.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Input, Flatten\n",
    " \n",
    "# Code implementation of the RNN for sequence labeling\n",
    "def create_rnn_model(vocab_size, num_labels, embedding_dim, lstm_units):\n",
    "    model = Sequential()\n",
    "    # model.add(Embedding(vocab_size, embedding_dim))\n",
    "    model.add(Input(shape=(512*2, embedding_dim)))\n",
    "    # model.add(Input(shape=(embedding_dim,)))\n",
    "    # model.add(LSTM(lstm_units, return_sequences=True))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_labels, activation='sigmoid'))\n",
    "    return model\n",
    " \n",
    "# Example usage of the RNN model\n",
    "vocab_size = 30000  # Replace with the actual size of the vocabulary\n",
    "num_labels = 1  # Replace with the actual number of entity labels\n",
    "embedding_dim = 768\n",
    "lstm_units = 64\n",
    "max_sequence_length = 35\n",
    "\n",
    "max_input_length = 512*2\n",
    " \n",
    "model = create_rnn_model(vocab_size, num_labels, embedding_dim, lstm_units)\n",
    "# model.build((1, max_input_length))\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[metrics.BinaryAccuracy(), metrics.AUC()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.7802 - sparse_categorical_accuracy: 0.4812 - val_loss: 0.9494 - val_sparse_categorical_accuracy: 0.5161\n",
      "Epoch 2/2\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.6593 - sparse_categorical_accuracy: 0.5109 - val_loss: 0.8609 - val_sparse_categorical_accuracy: 0.5161\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=250,\n",
    "    epochs=3,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9028 - sparse_categorical_accuracy: 0.5237\n",
      "test loss, test acc: [0.86086505651474, 0.5161290168762207]\n",
      "Generate predictions for 3 samples\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "predictions shape: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
