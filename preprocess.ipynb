{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(\".cache\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "@memory.cache\n",
    "def get_tokenizer_model():\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-cased')\n",
    "    sbert_model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "    return bert_tokenizer, bert_model, sbert_model\n",
    "\n",
    "bert_tokenizer, bert_model, sbert_model = get_tokenizer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import itertools\n",
    "from natsort import natsorted\n",
    "\n",
    "@memory.cache\n",
    "def read_problem_files(problem_folder, n=None):\n",
    "    \"\"\"\n",
    "    reads ground truth files into dict\n",
    "    :param truth_folder: path to folder holding ground truth files\n",
    "    :return: dict of ground truth files with problem-id as key and file content as value\n",
    "    \"\"\"\n",
    "    problems = []\n",
    "    files = itertools.islice(natsorted(Path(problem_folder).glob('problem-*.txt')), n)\n",
    "    for problem_file in files:\n",
    "        # number = problem_file.name[len(\"problem-\") : -len(\".txt\")]\n",
    "        with open(problem_file, 'r', encoding=\"utf8\") as fh:\n",
    "            problems.append(fh.readlines())\n",
    "    return problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluator import read_ground_truth_files\n",
    "\n",
    "@memory.cache\n",
    "def cached_read_ground_truth(x):\n",
    "    return read_ground_truth_files(x)\n",
    "\n",
    "ground_truth = cached_read_ground_truth(\"pan21/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(paragraph):\n",
    "    # Tokenize the sentence\n",
    "    tokens = bert_tokenizer.tokenize(paragraph)\n",
    "    token_ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # Convert token IDs to tensor\n",
    "    token_tensor = torch.tensor([token_ids])\n",
    "    segment_ids = [0] * len(token_ids)\n",
    "    segment_tensor = torch.tensor([segment_ids])\n",
    "\n",
    "    # Get BERT model output\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(token_tensor, segment_tensor)\n",
    "\n",
    "    # Extract word embeddings from BERT model output\n",
    "    return outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = read_problem_files(\"pan21/train\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"As stephelton said in the comments to your question, vector math is extremely important for pretty much any 2D or 3D game. However, physics knowledge isn't necessary for a lot of simple games. There are physics-like concepts you should understand a bit about, like collision, but you won't need calculus or physics classes for that as long as you keep it simple. A lot of things you may want to do can be simulated simply enough that players won't care much, like friction, or sliding, or gravity. A decent grasp of physics will likely help in many situations though.\\n\",\n",
       " 'It is probably not required to know physics in details when you\\'re doing a game, but it definitely helps, especially if there are some \\'virtual reality\\' features in your game. A game like \"From Dust\" (Eric Chahi) is essentially physics simulation gamified, while \"Another World\" only need high-precision capture of real-life motion (so and requires little to no actual understanding of what happens).\\n',\n",
       " \"It is very likely that inertia and the other bodies motion related fields will be quite helpful to produce something that is pleasant to the eye, even if you're just moving items on a chessboard. Knowing that friction exists helps using it as a game mechanic, even if you don't exactly use their academic version. Same for energy conservation. In fact, I believe we could very much use game development as a way to teach physics.\\n\",\n",
       " 'Having something that behaves close to our real world makes the rules of your game easier to learn for your player, feel more natural, and brings the player to the fun/challenging part more rapidly.\\n',\n",
       " 'The good approach is much simpler and simply require that the speed is increased at every frame by a constant (gravity acceleration) as stated in Newton Laws. Knowing physics makes you find the right solution faster.\\n',\n",
       " \"Physics isn't really necessary unless you want to have physics in your game. While a good general knowledge of physics is recommended, it's not necessary if you're using someone else's physics engine (which I would recommend). Also, calc based physics will get you farther. And, you really only need to know mechanics but the other things don't hurt. All in all though, it depends on what you're doing.\\n\",\n",
       " \"I'd be very surprised if you ever use Maxwell or Einstein theories, though. But who knows ? Ludum dare could prove me wrong.\\n\",\n",
       " \"The first time I wanted to have a character jumping in a game, I started using sin(x). The result was kinda akwards: as soon as you jumped off a cliff, you'd end up travelling up and down, as if you'd be riding a curious deltaplane.\"]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraph_pairs(problem_text):\n",
    "    # print(problem_text)\n",
    "    paragraph_embeddings = [get_embeddings(para) for para in problem_text]\n",
    "    # print(f\"{[x.shape for x in paragraph_embeddings]}\")\n",
    "    return list(itertools.combinations(paragraph_embeddings, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "@memory.cache\n",
    "def get_problem_embeddings(problems):\n",
    "    return [get_paragraph_pairs(problem_text) for problem_text in tqdm(problems)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_embed = get_problem_embeddings(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_ground_truth(ground_truth, problem_numbers):\n",
    "    simple_ground_truth = []\n",
    "    for num in problem_numbers:\n",
    "        task_3_ground_truth = ground_truth[f\"problem-{num}\"][\"paragraph-authors\"]\n",
    "        simple_ground_truth.append(task_3_ground_truth)\n",
    "    return simple_ground_truth\n",
    "\n",
    "\n",
    "simple_ground_truth = get_simple_ground_truth(ground_truth, range(1, len(problems_embed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 2, 2, 2, 3, 2, 2],\n",
       " [1, 2, 2, 2, 1, 2],\n",
       " [1, 2, 2, 3, 3, 2],\n",
       " [1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_3_ground_truth(simple_ground_truth):\n",
    "    task_gt = []\n",
    "    for problem in simple_ground_truth:\n",
    "        problem_gt = []\n",
    "        for author1, author2 in itertools.combinations(problem, 2):\n",
    "            problem_gt.append(int(author1 != author2))\n",
    "        task_gt.append(problem_gt)\n",
    "    return task_gt\n",
    "\n",
    "task_3_ground_truth = get_task_3_ground_truth(simple_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Invert the function get_task_3_ground_truth. Our model will output a bunch of binary labels which need to be converted to the task 3 ground truth format\n",
    "# Ground truth format (gtf): [1, 2, 2, 2, 2, 3, 2, 2]\n",
    "# Binary labels for comparisons (bl): [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
    "# Each binary label is the result of comparing two paragraphs. 1 means there was an author change, 0 means there was no author change\n",
    "# For example, bl[0], is the result of comparing gtf[0]=1 and gtf[1]=2. 1 != 2, therefore bl[0] = 1. bl[1]=1 is the result of gtf[0] == gtf[2] (1 == 2)\n",
    "def get_simple_ground_truth_from_task_3(task_3_ground_truth):\n",
    "    pass\n",
    "\n",
    "simple_ground_truth == get_simple_ground_truth_from_task_3(task_3_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 2, 3, 2, 2]\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "[1, 2, 2, 2, 1, 2]\n",
      "[1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n",
      "[1, 2, 2, 3, 3, 2]\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for s, t in zip(simple_ground_truth, task_3_ground_truth):\n",
    "    print(f\"{s}\")\n",
    "    print(f\"{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code to write out the embeddings (X) and ground truths (y) so we can train without having to rerun the preprocessing step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
